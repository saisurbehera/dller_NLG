{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-ad7b2808eebbeac2.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-13b56d373270ca93.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-a75db0b3528888c1.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-e2062bde0f8c5658.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-09f64d49b81279aa.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-dae32e8759c00613.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-0126c44654c702c8.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-75017d55dfc375e7.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-88a0461c445716e9.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-859b248f89e6dbc9.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-721f6f5fe0b3ccfa.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-3532c19071671122.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-942c66ee9a57e21e.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-9883daff1f5d8566.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-9027b7052c3d40bb.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-5b818ea4b98118de.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-0ca50b3073e32516.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-6f1417647a68b073.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-a4220fb6d876ffe7.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-11eb99a5dca7e220.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-78d90203cf5f3b81.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-5f356aa747b629f1.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-84c46f636e99dc81.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-3183fc5bd72c4419.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-e4b209d7a2553fd7.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-279216f3d25c0b92.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-c0b6a2592217037f.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-64599b91c3c7d307.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-8d0a3637426f9ab7.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-5edae9456d5bf7d1.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-6bf4bdac5b721be1.arrow\n",
      "Loading cached processed dataset at /workspace/data/filtered_small_embeddings/train/cache-240af1785560dad2.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['date', 'sentence_split', 'non_split', 'hash', 'embeddings', 'title'],\n",
       "    num_rows: 177300\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "ds = load_from_disk(\"/workspace/data/filtered_small_embeddings\")[\"train\"]\n",
    "def get_title_examples(examples):\n",
    "    split_title = [ i.split(\"\\n\")[0] for i in examples[\"sentence_split\"]]\n",
    "    examples[\"title\"] = split_title\n",
    "    return examples\n",
    "ds = ds.map(get_title_examples, batched=True, num_proc=32)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 176989, True: 311})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([ i==j for i,j in zip(df[\"sentence_split\"], df[\"non_split\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radiohead - Music - New York Times\n",
      "\n",
      "LOS ANGELES - \"In Rainbows,\" the latest album from the British rock band Radiohead, has been readily available to music fans for almost three months, first as a digital download in an unconventional tip-jar offering in which fans decided for themselves what to pay for it, and then, like most pop music today, as digital files circulating on free, unlicensed file-swapping networks. One matter remains: Will anyone buy the CD?\n",
      "\n",
      "Starting on Tuesday, the album, in plastic disc form, is on sale in record shops (this time with a list price, $13.98, that is not subject to consumer whims). Though hard-core fans almost surely have acquired the album, one way or another, Radiohead had plans to promote the CD release with a \"prerecording\" of the band performing songs from \"In Rainbows\" on the www.radiohead.tv Web site starting on Monday, according to the band's Web site, radiohead.com. It is also to be shown on satellite and cable systems that carry the Current TV channel.\n",
      "\n",
      "Though hailed by critics, the album is seen as an uncertain prospect commercially. That is because the band has declined to say how many copies have been distributed since October, when it diverged from industry custom and offered a digital download of \"In Rainbows\" for however much fans chose to pay - even nothing. Since then the band's representatives have described the offering as, among other things, a way of testing whether digital downloads eat into sales of CDs.\n",
      "\n",
      "Radiohead chose to release the CD through the independent label ATO Records and its imprint TBD. (The band's 2003 album \"Hail to the Thief\" was the last one under its recording contract with the music giant EMI.) ATO is shipping an estimated 400,000 copies of the album to record shops, said executives briefed on the label's plans. It is not uncommon for shops to sell half of the shipment of a big album in its first week on sale. But Radiohead's performance may differ; not only has the album been widely available online, but it is also hitting record shops in the traditionally slow post-holiday sales period.\n",
      "\n",
      "As a result, it is seen as a long shot that the band could match the performance of \"Hail to the Thief,\" which sold 300,000 copies in its first week after going on sale in June 2003, and went on to sell a total of roughly 1 million copies, according to Nielsen SoundScan data.\n",
      "\n",
      "Will Botwin, the president of ATO, said that in spite of the availability of Radiohead's music online, many fans might still have reason to pay for the CD version. \"You've still got hard-core Radiohead fans that are very inclined to own anything they can from the band,\" he said.\n",
      "\n",
      "He added that the critical praise and international headlines generated by the band's release plan may have drawn new fans. \"I think you're going to find a new buyer that might be more curious, that might've gotten turned on by all the attention,\" he said. Still, he acknowledged, \"it's faith on our part.\"\n",
      "\n",
      "He continued: \"There's nothing normal here. There are not normal business principles.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(df[\"sentence_split\"], df[\"non_split\"]):\n",
    "    if i!=j:\n",
    "        print(j)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentence_split_list\"] = [ [i for i in i.split(\"\\n\")[1:] if len(i)>0] for i in df[\"non_split\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentence_split</th>\n",
       "      <th>non_split</th>\n",
       "      <th>hash</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>title</th>\n",
       "      <th>sentence_split_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20080101</td>\n",
       "      <td>Radiohead - Music - New York Times\\nLOS ANGELE...</td>\n",
       "      <td>Radiohead - Music - New York Times\\n\\nLOS ANGE...</td>\n",
       "      <td>3d6943d8ea557c6b60bd9b88474c2f68751e72d7993ff5...</td>\n",
       "      <td>[0.36299476, -0.06389122, 0.35738632, 0.122280...</td>\n",
       "      <td>Radiohead - Music - New York Times</td>\n",
       "      <td>[LOS ANGELES - \"In Rainbows,\" the latest album...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20080101</td>\n",
       "      <td>Huckabee Shows Negative Spot After Pulling It ...</td>\n",
       "      <td>Huckabee Shows Negative Spot After Pulling It ...</td>\n",
       "      <td>88b7a7e093e77a3e401519a2563016e1284954b3e7bc40...</td>\n",
       "      <td>[0.24303254, 0.3653328, 0.056599963, 0.0806784...</td>\n",
       "      <td>Huckabee Shows Negative Spot After Pulling It ...</td>\n",
       "      <td>[DES MOINES - In a bizarre bit of political th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20080101</td>\n",
       "      <td>Gumbel Is Precisely the Problem for the NFL Ne...</td>\n",
       "      <td>Gumbel Is Precisely the Problem for the NFL Ne...</td>\n",
       "      <td>96fc64e2c3e274d3326079683aba277d7a366e0a72d55f...</td>\n",
       "      <td>[0.08627419, 0.2024003, -0.013621029, -0.34191...</td>\n",
       "      <td>Gumbel Is Precisely the Problem for the NFL Ne...</td>\n",
       "      <td>[One of the risks the NFL Network faced by hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20080101</td>\n",
       "      <td>Scoring Four in Second, Isles Beat the Hurrica...</td>\n",
       "      <td>Scoring Four in Second, Isles Beat the Hurrica...</td>\n",
       "      <td>9ef800f229069d1e8a8eb7f46883d47ba31fd1bc26b009...</td>\n",
       "      <td>[-0.16298355, -0.04860712, 0.37003276, 0.09193...</td>\n",
       "      <td>Scoring Four in Second, Isles Beat the Hurricanes</td>\n",
       "      <td>[Marc-Andre Bergeron had two goals and an assi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20080101</td>\n",
       "      <td>Pat Kirkwood, Star of British Musical Theater,...</td>\n",
       "      <td>Pat Kirkwood, Star of British Musical Theater,...</td>\n",
       "      <td>700c1815a2fa432aa5e18e46e45a59ccf9928aa8faa469...</td>\n",
       "      <td>[-0.45718825, -0.018084839, 0.46993467, -0.497...</td>\n",
       "      <td>Pat Kirkwood, Star of British Musical Theater,...</td>\n",
       "      <td>[LONDON (AP) - Pat Kirkwood, once a star of Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177295</th>\n",
       "      <td>20131231</td>\n",
       "      <td>Doctors behind ADHD study question drug treatm...</td>\n",
       "      <td>Doctors behind ADHD study question drug treatm...</td>\n",
       "      <td>80a6402c80a867d9dea1e1c708f0d0922ead75a18eb503...</td>\n",
       "      <td>[0.28165033, 0.3630367, 0.08441983, -0.0937929...</td>\n",
       "      <td>Doctors behind ADHD study question drug treatm...</td>\n",
       "      <td>[The co-authors of a 20-year-old study promoti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177296</th>\n",
       "      <td>20131226</td>\n",
       "      <td>'Egypt returns to pre-2011 situation' - RT Op-...</td>\n",
       "      <td>'Egypt returns to pre-2011 situation' - RT Op-...</td>\n",
       "      <td>c741f17b0e2c26644d0a541736c0478ff7135b81807d54...</td>\n",
       "      <td>[0.4883721, 0.3118963, -0.12314952, -0.2037451...</td>\n",
       "      <td>'Egypt returns to pre-2011 situation' - RT Op-...</td>\n",
       "      <td>[Egyptian people believe the labeling of the M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177297</th>\n",
       "      <td>20131220</td>\n",
       "      <td>First space robot asks Santa for rocket for Ch...</td>\n",
       "      <td>First space robot asks Santa for rocket for Ch...</td>\n",
       "      <td>7ca850d28ab68cccf51527f29f0240956a14c2eb368ca6...</td>\n",
       "      <td>[-0.12727721, 0.3181608, 0.73506653, 0.1760502...</td>\n",
       "      <td>First space robot asks Santa for rocket for Ch...</td>\n",
       "      <td>[Japanese astronaut Koichi Wakata (L) smiling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177298</th>\n",
       "      <td>20131223</td>\n",
       "      <td>Print - Freed Pussy Riot Rockers: Amnesty - Pu...</td>\n",
       "      <td>Print - Freed Pussy Riot Rockers: Amnesty - Pu...</td>\n",
       "      <td>df09e07549340cf4dd2edccec76b72c223c0196beaad5d...</td>\n",
       "      <td>[0.81098926, -0.04812907, 0.29949614, -0.00753...</td>\n",
       "      <td>Print - Freed Pussy Riot Rockers: Amnesty - Pu...</td>\n",
       "      <td>[The two members of Russian punk band Pussy Ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177299</th>\n",
       "      <td>20131218</td>\n",
       "      <td>Print - Ukraine's Yanukovych on Controversial ...</td>\n",
       "      <td>Print - Ukraine's Yanukovych on Controversial ...</td>\n",
       "      <td>0ea9024160fabb54122f2e7fa9990c70f141cc1b570ed6...</td>\n",
       "      <td>[0.78061146, 0.2172679, 0.17962663, 0.19410421...</td>\n",
       "      <td>Print - Ukraine's Yanukovych on Controversial ...</td>\n",
       "      <td>[Ukrainian President Viktor Yanukovych will me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177300 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                     sentence_split  \\\n",
       "0       20080101  Radiohead - Music - New York Times\\nLOS ANGELE...   \n",
       "1       20080101  Huckabee Shows Negative Spot After Pulling It ...   \n",
       "2       20080101  Gumbel Is Precisely the Problem for the NFL Ne...   \n",
       "3       20080101  Scoring Four in Second, Isles Beat the Hurrica...   \n",
       "4       20080101  Pat Kirkwood, Star of British Musical Theater,...   \n",
       "...          ...                                                ...   \n",
       "177295  20131231  Doctors behind ADHD study question drug treatm...   \n",
       "177296  20131226  'Egypt returns to pre-2011 situation' - RT Op-...   \n",
       "177297  20131220  First space robot asks Santa for rocket for Ch...   \n",
       "177298  20131223  Print - Freed Pussy Riot Rockers: Amnesty - Pu...   \n",
       "177299  20131218  Print - Ukraine's Yanukovych on Controversial ...   \n",
       "\n",
       "                                                non_split  \\\n",
       "0       Radiohead - Music - New York Times\\n\\nLOS ANGE...   \n",
       "1       Huckabee Shows Negative Spot After Pulling It ...   \n",
       "2       Gumbel Is Precisely the Problem for the NFL Ne...   \n",
       "3       Scoring Four in Second, Isles Beat the Hurrica...   \n",
       "4       Pat Kirkwood, Star of British Musical Theater,...   \n",
       "...                                                   ...   \n",
       "177295  Doctors behind ADHD study question drug treatm...   \n",
       "177296  'Egypt returns to pre-2011 situation' - RT Op-...   \n",
       "177297  First space robot asks Santa for rocket for Ch...   \n",
       "177298  Print - Freed Pussy Riot Rockers: Amnesty - Pu...   \n",
       "177299  Print - Ukraine's Yanukovych on Controversial ...   \n",
       "\n",
       "                                                     hash  \\\n",
       "0       3d6943d8ea557c6b60bd9b88474c2f68751e72d7993ff5...   \n",
       "1       88b7a7e093e77a3e401519a2563016e1284954b3e7bc40...   \n",
       "2       96fc64e2c3e274d3326079683aba277d7a366e0a72d55f...   \n",
       "3       9ef800f229069d1e8a8eb7f46883d47ba31fd1bc26b009...   \n",
       "4       700c1815a2fa432aa5e18e46e45a59ccf9928aa8faa469...   \n",
       "...                                                   ...   \n",
       "177295  80a6402c80a867d9dea1e1c708f0d0922ead75a18eb503...   \n",
       "177296  c741f17b0e2c26644d0a541736c0478ff7135b81807d54...   \n",
       "177297  7ca850d28ab68cccf51527f29f0240956a14c2eb368ca6...   \n",
       "177298  df09e07549340cf4dd2edccec76b72c223c0196beaad5d...   \n",
       "177299  0ea9024160fabb54122f2e7fa9990c70f141cc1b570ed6...   \n",
       "\n",
       "                                               embeddings  \\\n",
       "0       [0.36299476, -0.06389122, 0.35738632, 0.122280...   \n",
       "1       [0.24303254, 0.3653328, 0.056599963, 0.0806784...   \n",
       "2       [0.08627419, 0.2024003, -0.013621029, -0.34191...   \n",
       "3       [-0.16298355, -0.04860712, 0.37003276, 0.09193...   \n",
       "4       [-0.45718825, -0.018084839, 0.46993467, -0.497...   \n",
       "...                                                   ...   \n",
       "177295  [0.28165033, 0.3630367, 0.08441983, -0.0937929...   \n",
       "177296  [0.4883721, 0.3118963, -0.12314952, -0.2037451...   \n",
       "177297  [-0.12727721, 0.3181608, 0.73506653, 0.1760502...   \n",
       "177298  [0.81098926, -0.04812907, 0.29949614, -0.00753...   \n",
       "177299  [0.78061146, 0.2172679, 0.17962663, 0.19410421...   \n",
       "\n",
       "                                                    title  \\\n",
       "0                      Radiohead - Music - New York Times   \n",
       "1       Huckabee Shows Negative Spot After Pulling It ...   \n",
       "2       Gumbel Is Precisely the Problem for the NFL Ne...   \n",
       "3       Scoring Four in Second, Isles Beat the Hurricanes   \n",
       "4       Pat Kirkwood, Star of British Musical Theater,...   \n",
       "...                                                   ...   \n",
       "177295  Doctors behind ADHD study question drug treatm...   \n",
       "177296  'Egypt returns to pre-2011 situation' - RT Op-...   \n",
       "177297  First space robot asks Santa for rocket for Ch...   \n",
       "177298  Print - Freed Pussy Riot Rockers: Amnesty - Pu...   \n",
       "177299  Print - Ukraine's Yanukovych on Controversial ...   \n",
       "\n",
       "                                      sentence_split_list  \n",
       "0       [LOS ANGELES - \"In Rainbows,\" the latest album...  \n",
       "1       [DES MOINES - In a bizarre bit of political th...  \n",
       "2       [One of the risks the NFL Network faced by hav...  \n",
       "3       [Marc-Andre Bergeron had two goals and an assi...  \n",
       "4       [LONDON (AP) - Pat Kirkwood, once a star of Br...  \n",
       "...                                                   ...  \n",
       "177295  [The co-authors of a 20-year-old study promoti...  \n",
       "177296  [Egyptian people believe the labeling of the M...  \n",
       "177297  [Japanese astronaut Koichi Wakata (L) smiling ...  \n",
       "177298  [The two members of Russian punk band Pussy Ri...  \n",
       "177299  [Ukrainian President Viktor Yanukovych will me...  \n",
       "\n",
       "[177300 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3034846"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filterd = df[[\"date\",\"hash\",\"title\",\"sentence_split_list\"]]\n",
    "filtered = []\n",
    "for i in df_filterd.values:\n",
    "    for j in i[3]:\n",
    "        filtered.append([i[0],i[1],i[2],j])\n",
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filtered_df= pd.DataFrame(filtered, columns=[\"date\",\"hash\",\"title\",\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hash</th>\n",
       "      <th>title</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20080101</td>\n",
       "      <td>3d6943d8ea557c6b60bd9b88474c2f68751e72d7993ff5...</td>\n",
       "      <td>Radiohead - Music - New York Times</td>\n",
       "      <td>LOS ANGELES - \"In Rainbows,\" the latest album ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20080101</td>\n",
       "      <td>3d6943d8ea557c6b60bd9b88474c2f68751e72d7993ff5...</td>\n",
       "      <td>Radiohead - Music - New York Times</td>\n",
       "      <td>Starting on Tuesday, the album, in plastic dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20080101</td>\n",
       "      <td>3d6943d8ea557c6b60bd9b88474c2f68751e72d7993ff5...</td>\n",
       "      <td>Radiohead - Music - New York Times</td>\n",
       "      <td>Though hailed by critics, the album is seen as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20080101</td>\n",
       "      <td>3d6943d8ea557c6b60bd9b88474c2f68751e72d7993ff5...</td>\n",
       "      <td>Radiohead - Music - New York Times</td>\n",
       "      <td>Radiohead chose to release the CD through the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20080101</td>\n",
       "      <td>3d6943d8ea557c6b60bd9b88474c2f68751e72d7993ff5...</td>\n",
       "      <td>Radiohead - Music - New York Times</td>\n",
       "      <td>As a result, it is seen as a long shot that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034841</th>\n",
       "      <td>20131218</td>\n",
       "      <td>0ea9024160fabb54122f2e7fa9990c70f141cc1b570ed6...</td>\n",
       "      <td>Print - Ukraine's Yanukovych on Controversial ...</td>\n",
       "      <td>\"No one from the media or amongst the Ukrainia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034842</th>\n",
       "      <td>20131218</td>\n",
       "      <td>0ea9024160fabb54122f2e7fa9990c70f141cc1b570ed6...</td>\n",
       "      <td>Print - Ukraine's Yanukovych on Controversial ...</td>\n",
       "      <td>Russia is trying to lure Ukraine into its own ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034843</th>\n",
       "      <td>20131218</td>\n",
       "      <td>0ea9024160fabb54122f2e7fa9990c70f141cc1b570ed6...</td>\n",
       "      <td>Print - Ukraine's Yanukovych on Controversial ...</td>\n",
       "      <td>The opposition is planning another massive ral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034844</th>\n",
       "      <td>20131218</td>\n",
       "      <td>0ea9024160fabb54122f2e7fa9990c70f141cc1b570ed6...</td>\n",
       "      <td>Print - Ukraine's Yanukovych on Controversial ...</td>\n",
       "      <td>All rights reserved, 2001-2013 (c) Novinite Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034845</th>\n",
       "      <td>20131218</td>\n",
       "      <td>0ea9024160fabb54122f2e7fa9990c70f141cc1b570ed6...</td>\n",
       "      <td>Print - Ukraine's Yanukovych on Controversial ...</td>\n",
       "      <td>You are permitted to use any of the articles i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3034846 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date                                               hash  \\\n",
       "0        20080101  3d6943d8ea557c6b60bd9b88474c2f68751e72d7993ff5...   \n",
       "1        20080101  3d6943d8ea557c6b60bd9b88474c2f68751e72d7993ff5...   \n",
       "2        20080101  3d6943d8ea557c6b60bd9b88474c2f68751e72d7993ff5...   \n",
       "3        20080101  3d6943d8ea557c6b60bd9b88474c2f68751e72d7993ff5...   \n",
       "4        20080101  3d6943d8ea557c6b60bd9b88474c2f68751e72d7993ff5...   \n",
       "...           ...                                                ...   \n",
       "3034841  20131218  0ea9024160fabb54122f2e7fa9990c70f141cc1b570ed6...   \n",
       "3034842  20131218  0ea9024160fabb54122f2e7fa9990c70f141cc1b570ed6...   \n",
       "3034843  20131218  0ea9024160fabb54122f2e7fa9990c70f141cc1b570ed6...   \n",
       "3034844  20131218  0ea9024160fabb54122f2e7fa9990c70f141cc1b570ed6...   \n",
       "3034845  20131218  0ea9024160fabb54122f2e7fa9990c70f141cc1b570ed6...   \n",
       "\n",
       "                                                     title  \\\n",
       "0                       Radiohead - Music - New York Times   \n",
       "1                       Radiohead - Music - New York Times   \n",
       "2                       Radiohead - Music - New York Times   \n",
       "3                       Radiohead - Music - New York Times   \n",
       "4                       Radiohead - Music - New York Times   \n",
       "...                                                    ...   \n",
       "3034841  Print - Ukraine's Yanukovych on Controversial ...   \n",
       "3034842  Print - Ukraine's Yanukovych on Controversial ...   \n",
       "3034843  Print - Ukraine's Yanukovych on Controversial ...   \n",
       "3034844  Print - Ukraine's Yanukovych on Controversial ...   \n",
       "3034845  Print - Ukraine's Yanukovych on Controversial ...   \n",
       "\n",
       "                                                  sentence  \n",
       "0        LOS ANGELES - \"In Rainbows,\" the latest album ...  \n",
       "1        Starting on Tuesday, the album, in plastic dis...  \n",
       "2        Though hailed by critics, the album is seen as...  \n",
       "3        Radiohead chose to release the CD through the ...  \n",
       "4        As a result, it is seen as a long shot that th...  \n",
       "...                                                    ...  \n",
       "3034841  \"No one from the media or amongst the Ukrainia...  \n",
       "3034842  Russia is trying to lure Ukraine into its own ...  \n",
       "3034843  The opposition is planning another massive ral...  \n",
       "3034844   All rights reserved, 2001-2013 (c) Novinite Ltd.  \n",
       "3034845  You are permitted to use any of the articles i...  \n",
       "\n",
       "[3034846 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.07235e+05, 9.93601e+05, 7.44935e+05, 3.32173e+05, 1.32633e+05,\n",
       "        5.77870e+04, 3.00690e+04, 1.40610e+04, 9.56700e+03, 4.91800e+03,\n",
       "        2.70500e+03, 1.79000e+03, 1.08500e+03, 6.05000e+02, 4.05000e+02,\n",
       "        2.50000e+02, 1.99000e+02, 1.34000e+02, 1.01000e+02, 9.10000e+01,\n",
       "        5.60000e+01, 6.40000e+01, 3.70000e+01, 3.70000e+01, 2.70000e+01,\n",
       "        3.00000e+01, 1.90000e+01, 2.20000e+01, 2.00000e+01, 2.70000e+01,\n",
       "        2.00000e+01, 1.20000e+01, 1.80000e+01, 1.50000e+01, 6.00000e+00,\n",
       "        1.10000e+01, 1.00000e+01, 6.00000e+00, 4.00000e+00, 5.00000e+00,\n",
       "        3.00000e+00, 3.00000e+00, 6.00000e+00, 2.00000e+00, 5.00000e+00,\n",
       "        1.00000e+00, 3.00000e+00, 0.00000e+00, 2.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 3.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 2.00000e+00, 1.00000e+00, 2.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 2.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 2.00000e+00, 1.00000e+00,\n",
       "        2.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 2.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 1.00000e+00]),\n",
       " array([1.00000e+00, 1.36100e+01, 2.62200e+01, 3.88300e+01, 5.14400e+01,\n",
       "        6.40500e+01, 7.66600e+01, 8.92700e+01, 1.01880e+02, 1.14490e+02,\n",
       "        1.27100e+02, 1.39710e+02, 1.52320e+02, 1.64930e+02, 1.77540e+02,\n",
       "        1.90150e+02, 2.02760e+02, 2.15370e+02, 2.27980e+02, 2.40590e+02,\n",
       "        2.53200e+02, 2.65810e+02, 2.78420e+02, 2.91030e+02, 3.03640e+02,\n",
       "        3.16250e+02, 3.28860e+02, 3.41470e+02, 3.54080e+02, 3.66690e+02,\n",
       "        3.79300e+02, 3.91910e+02, 4.04520e+02, 4.17130e+02, 4.29740e+02,\n",
       "        4.42350e+02, 4.54960e+02, 4.67570e+02, 4.80180e+02, 4.92790e+02,\n",
       "        5.05400e+02, 5.18010e+02, 5.30620e+02, 5.43230e+02, 5.55840e+02,\n",
       "        5.68450e+02, 5.81060e+02, 5.93670e+02, 6.06280e+02, 6.18890e+02,\n",
       "        6.31500e+02, 6.44110e+02, 6.56720e+02, 6.69330e+02, 6.81940e+02,\n",
       "        6.94550e+02, 7.07160e+02, 7.19770e+02, 7.32380e+02, 7.44990e+02,\n",
       "        7.57600e+02, 7.70210e+02, 7.82820e+02, 7.95430e+02, 8.08040e+02,\n",
       "        8.20650e+02, 8.33260e+02, 8.45870e+02, 8.58480e+02, 8.71090e+02,\n",
       "        8.83700e+02, 8.96310e+02, 9.08920e+02, 9.21530e+02, 9.34140e+02,\n",
       "        9.46750e+02, 9.59360e+02, 9.71970e+02, 9.84580e+02, 9.97190e+02,\n",
       "        1.00980e+03, 1.02241e+03, 1.03502e+03, 1.04763e+03, 1.06024e+03,\n",
       "        1.07285e+03, 1.08546e+03, 1.09807e+03, 1.11068e+03, 1.12329e+03,\n",
       "        1.13590e+03, 1.14851e+03, 1.16112e+03, 1.17373e+03, 1.18634e+03,\n",
       "        1.19895e+03, 1.21156e+03, 1.22417e+03, 1.23678e+03, 1.24939e+03,\n",
       "        1.26200e+03]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "all_sizes = [len(i.split()) for i in filtered_df[\"sentence\"]]\n",
    "plt.hist(all_sizes, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "all_sizes = np.array(all_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1262"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sizes.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_sizes<256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 3034352, False: 494})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "Counter(all_sizes<256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 3034793, False: 53})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(all_sizes<512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t# nreimers/MiniLM-L6-H384-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# model = SentenceTransformer(\"facebook/dpr-ctx_encoder-single-nq-base\",device =\"cuda:0\")\n",
    "\n",
    "# #Our sentences we like to encode\n",
    "# sentences = filtered_df[\"sentence\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2',device =\"cuda:0\")\n",
    "\n",
    "# #Our sentences we like to encode\n",
    "# sentences = filtered_df[\"sentence\"]\n",
    "\n",
    "# #Sentences are encoded by calling model.encode()\n",
    "# embeddings = model.encode(sentences,show_progress_bar=True, batch_size=2096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df[\"embeddings\"] = embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset \n",
    "dataset = Dataset.from_pandas(filtered_df)\n",
    "# dataset.save_to_disk(\"/workspace/data/filtered_split_sentences_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['date', 'hash', 'title', 'sentence'],\n",
       "    num_rows: 3034846\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.weight', 'ctx_encoder.bert_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['date', 'hash', 'title', 'sentence'],\n",
       "    num_rows: 3034846\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_encoder.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPRContextEncoder(\n",
       "  (ctx_encoder): DPREncoder(\n",
       "    (bert_model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_encoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 295 ms, sys: 95.4 ms, total: 390 ms\n",
      "Wall time: 388 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.44872797e-01, -1.52787929e-02,  3.54400426e-01,\n",
       "         4.45680082e-01, -6.35469854e-02, -1.27723247e-01,\n",
       "        -1.85291767e-02,  3.10418874e-01, -3.99701893e-01,\n",
       "         1.32502764e-01, -1.29115395e-02,  7.22522795e-01,\n",
       "         9.84660983e-02, -1.31150603e-01, -2.49564394e-01,\n",
       "         2.52525777e-01,  9.86515582e-01,  3.12675476e-01,\n",
       "         1.09622650e-01, -4.38573062e-01, -2.45320529e-01,\n",
       "        -1.60926402e-01,  5.40736914e-01, -2.74301022e-01,\n",
       "        -2.49902420e-02, -6.26286343e-02, -2.01016903e-01,\n",
       "        -2.39415154e-01, -5.33686101e-01,  2.87955195e-01,\n",
       "        -2.47095525e-01,  8.03283811e-01,  1.85257137e-01,\n",
       "        -5.60272038e-01,  1.94067508e-01,  4.85906154e-02,\n",
       "         3.35175067e-01, -3.46531242e-01, -1.66713253e-01,\n",
       "        -3.66712600e-01,  1.61160707e-01, -2.66195476e-01,\n",
       "         2.22974807e-01,  3.96611452e-01, -1.82861283e-01,\n",
       "         3.07390898e-01, -1.05647564e+00,  3.29033375e-01,\n",
       "        -5.13433039e-01,  2.23564163e-01, -3.77120674e-01,\n",
       "         1.59540236e-01,  1.88453972e-01,  2.68049210e-01,\n",
       "         2.08528638e-01,  3.65085185e-01, -5.13505578e-01,\n",
       "         2.89914280e-01, -4.00273539e-02, -2.74227764e-02,\n",
       "         2.72786647e-01, -2.10574977e-02,  1.73848510e-01,\n",
       "        -2.65604913e-01, -4.77676541e-02,  2.50149798e-02,\n",
       "         5.31468749e-01,  2.06365898e-01,  2.36673817e-01,\n",
       "        -6.86527252e-01,  4.43620831e-01, -4.94424701e-01,\n",
       "        -2.46730909e-01, -4.43101794e-01, -8.13082457e-02,\n",
       "         7.89356008e-02, -2.00413734e-01,  5.12676015e-02,\n",
       "        -2.74756365e-03,  2.98938662e-01, -4.89943363e-02,\n",
       "         2.98758328e-01,  1.29442811e+00, -3.32770526e-01,\n",
       "         7.04677403e-01, -5.09216607e-01, -3.36255342e-01,\n",
       "         5.67885637e-01, -9.51465815e-02,  5.49429774e-01,\n",
       "        -2.40744084e-01, -5.45747995e-01,  6.64882004e-01,\n",
       "         2.00991392e-01,  6.04853630e-01, -5.20392716e-01,\n",
       "         2.50806242e-01,  5.05843639e-01, -1.84121862e-01,\n",
       "        -7.80634657e-02,  4.07309264e-01,  1.40914530e-01,\n",
       "        -3.72974351e-02, -2.66082346e-01, -1.70753479e-01,\n",
       "        -2.42190540e-01, -7.96428025e-02,  7.55368769e-02,\n",
       "         3.77767324e-01,  1.80966422e-01,  3.74058843e-01,\n",
       "         1.06059551e-01, -2.54286751e-02, -2.17948426e-02,\n",
       "         1.69344187e-01,  2.97130235e-02,  3.35606605e-01,\n",
       "         1.07668631e-01,  2.44710222e-01,  1.61892995e-01,\n",
       "         5.99803269e-01,  7.49993861e-01,  3.77461053e-02,\n",
       "        -1.14140488e-01, -7.77953565e-02, -2.87933260e-01,\n",
       "         6.22416377e-01,  1.53089479e-01, -7.01013356e-02,\n",
       "         8.29813704e-02, -5.96162796e-01,  4.96836036e-01,\n",
       "         1.55930385e-01, -4.72575486e-01,  2.38729298e-01,\n",
       "        -4.73795474e-01, -2.15614155e-01,  4.80665565e-01,\n",
       "         5.63144147e-01,  1.11890368e-01, -5.44362843e-01,\n",
       "         1.09080553e-01, -7.10098326e-01, -5.89805067e-01,\n",
       "         5.03257990e-01,  1.99410707e-01, -2.12080151e-01,\n",
       "        -3.07502210e-01, -3.65965992e-01, -2.30875924e-01,\n",
       "         1.21587187e-01,  8.60331953e-02, -1.96553946e-01,\n",
       "        -2.75909662e-01,  4.77190427e-02, -6.28612051e-03,\n",
       "         2.29658663e-01,  8.07044804e-02, -3.27639841e-03,\n",
       "         1.00255392e-01,  1.21094488e-01,  1.15309976e-01,\n",
       "         4.23249036e-01,  2.27786049e-01, -5.06551266e-01,\n",
       "         1.11408144e-01, -5.96585870e-01,  4.79530811e-01,\n",
       "         2.12456569e-01, -1.52833030e-01, -7.57418051e-02,\n",
       "         2.38727763e-01,  5.37868170e-03, -7.85042346e-02,\n",
       "         2.96885401e-01,  1.86714023e-01,  1.02636015e+00,\n",
       "         4.29999918e-01, -3.93900663e-01,  4.65855837e-01,\n",
       "        -6.51835918e-01,  3.42902616e-02, -1.94690883e-01,\n",
       "        -5.10503411e-01, -1.63947418e-02, -1.24009373e-03,\n",
       "         2.41086081e-01,  4.66656357e-01,  3.27744186e-01,\n",
       "         2.85593957e-01, -1.95354611e-01, -3.21352750e-01,\n",
       "        -1.55288830e-01, -3.94005775e-01,  3.98326159e-01,\n",
       "         3.25031340e-01, -8.99651498e-02,  5.86450577e-01,\n",
       "         3.90866399e-01,  1.13074020e-01,  4.47961362e-03,\n",
       "         5.28680623e-01,  8.67747128e-01, -3.85383368e-01,\n",
       "        -1.04572546e+00, -2.81706989e-01,  5.36953568e-01,\n",
       "        -2.31122330e-01, -1.82895526e-01,  2.42983133e-01,\n",
       "        -2.20270842e-01, -3.90074760e-01, -1.90175042e-01,\n",
       "         6.07624829e-01, -3.23185325e-01,  3.04975092e-01,\n",
       "        -3.13625872e-01, -1.45201087e-01,  3.78429890e-01,\n",
       "        -2.24709228e-01,  2.57898152e-01,  6.70125484e-02,\n",
       "         6.29472256e-01,  6.12643100e-02, -7.02082992e-01,\n",
       "         8.05334091e-01, -6.25095144e-02,  5.71430773e-02,\n",
       "         4.21062827e-01, -7.84574926e-01, -2.75539071e-03,\n",
       "         5.28641567e-02, -5.89928925e-01, -5.18988192e-01,\n",
       "        -6.55577630e-02,  7.37169325e-01,  6.23083636e-02,\n",
       "        -4.57879394e-01, -2.34448500e-02, -2.07412869e-01,\n",
       "         3.53972726e-02, -3.20191056e-01,  1.17780037e-01,\n",
       "         5.45923650e-01,  2.25774609e-02,  1.67159066e-01,\n",
       "         1.43909663e-01, -2.26453319e-01, -1.15084067e-01,\n",
       "        -1.44139007e-01,  5.74785471e-02,  3.26043874e-01,\n",
       "        -5.26824713e-01,  6.62970766e-02,  3.03860962e-01,\n",
       "         9.13818628e-02,  2.13875815e-01, -8.56319219e-02,\n",
       "         2.29391500e-01, -2.05327749e-01, -6.93000332e-02,\n",
       "        -3.04075666e-02,  1.74644422e-02,  3.77943605e-01,\n",
       "        -5.03769577e-01, -3.67296368e-01, -2.87101865e-01,\n",
       "        -4.57525790e-01,  2.80325890e-01,  5.03400564e-01,\n",
       "        -7.96801507e-01,  6.72690988e-01, -3.72806221e-01,\n",
       "         6.38087511e-01,  2.79568024e-02,  8.61553401e-02,\n",
       "        -4.34766859e-01,  5.33138812e-01,  5.13806403e-01,\n",
       "        -2.98552215e-01,  5.34373820e-01,  4.57819015e-01,\n",
       "         4.65630680e-01, -5.41661918e-01, -7.31051683e-01,\n",
       "        -1.55175030e-01,  4.45906848e-01, -5.26432216e-01,\n",
       "        -2.78426528e-01, -4.61634487e-01, -2.50229090e-01,\n",
       "        -5.49246430e-01,  1.36416972e-01,  3.35321397e-01,\n",
       "         2.16471665e-02, -5.59267759e-01,  6.42197669e-01,\n",
       "         3.86872768e-01,  1.15615256e-01, -1.07800908e-01,\n",
       "        -3.52907509e-01,  9.02734473e-02, -4.11311477e-01,\n",
       "        -3.49983603e-01,  4.43707407e-01, -2.10587740e-01,\n",
       "        -1.69497579e-01, -7.62196660e-01, -5.99612761e+00,\n",
       "         3.13529372e-01, -3.92928064e-01, -2.67562300e-01,\n",
       "        -2.36516610e-01, -2.85610110e-01, -1.26972243e-01,\n",
       "        -4.99659747e-01,  3.24137360e-02,  4.65111919e-02,\n",
       "        -4.96966809e-01,  5.59115648e-01, -3.32576931e-01,\n",
       "        -9.25018191e-02,  2.91969806e-01, -1.39998898e-01,\n",
       "        -8.44767690e-02,  2.33987644e-01, -4.84113485e-01,\n",
       "        -7.44937127e-03, -7.69050419e-01,  3.59323584e-02,\n",
       "         5.43588758e-01,  8.52928162e-01, -9.54163074e-02,\n",
       "         6.29128933e-01, -1.35468720e-02, -4.66114253e-01,\n",
       "        -3.04469109e-01, -1.74040079e-01, -3.87643278e-01,\n",
       "        -1.66299775e-01,  1.73882151e-03, -5.83371706e-02,\n",
       "         4.24955226e-02,  4.56887841e-01,  5.25596738e-01,\n",
       "        -3.69103432e-01, -2.78574407e-01, -1.45091280e-01,\n",
       "         3.34190786e-01, -1.32704988e-01,  5.08323014e-01,\n",
       "        -3.75904173e-01,  2.92340249e-01,  3.62511039e-01,\n",
       "        -3.36151540e-01, -1.95296470e-03, -3.92046690e-01,\n",
       "         1.01805449e+00,  5.17589152e-01, -5.78439236e-01,\n",
       "         2.42349118e-01, -4.29052040e-02, -1.82768591e-02,\n",
       "        -8.50819796e-02,  3.40245813e-01,  1.83899790e-01,\n",
       "        -1.51372492e-01, -2.50367314e-01,  2.55174696e-01,\n",
       "        -8.29797238e-02, -2.95311183e-01,  2.13901445e-01,\n",
       "         5.52527905e-02,  1.55423939e-01, -6.13348961e-01,\n",
       "         9.80462432e-02,  5.11342585e-01,  5.07733941e-01,\n",
       "        -6.22101650e-02,  4.25871052e-02, -2.56936193e-01,\n",
       "        -8.54338884e-01, -9.35337618e-02, -1.13696992e-01,\n",
       "        -6.06394053e-01,  4.05800879e-01, -1.44861490e-01,\n",
       "         4.69994515e-01, -6.10596180e-01,  1.54731885e-01,\n",
       "         4.02103662e-01, -6.13429844e-01,  1.97090313e-01,\n",
       "        -6.22559249e-01, -4.78391886e-01,  3.19000930e-01,\n",
       "        -2.84496605e-01,  3.10203314e-01,  2.51157641e-01,\n",
       "        -3.69772196e-01,  2.76199877e-01,  2.27336362e-02,\n",
       "         1.50293127e-01,  3.45526993e-01,  6.71665132e-01,\n",
       "         2.44949117e-01,  3.60260308e-01, -1.86889917e-01,\n",
       "         1.04943371e+00, -1.77116096e-01, -2.03813650e-02,\n",
       "        -6.33368433e-01, -8.26295793e-01, -1.23150364e-01,\n",
       "        -5.37534714e-01,  1.29403278e-01,  6.16462648e-01,\n",
       "        -8.22591126e-01, -1.71763182e-01, -4.74536419e-01,\n",
       "         6.09002076e-02, -3.32962126e-01,  8.69138002e-01,\n",
       "        -2.56557673e-01, -3.43845099e-01,  4.73008335e-01,\n",
       "         4.15183812e-01, -4.80953515e-01,  3.39404583e-01,\n",
       "        -1.70035977e-02,  4.18279976e-01,  2.57794410e-01,\n",
       "         6.34692609e-02,  3.30160409e-01, -1.72157273e-01,\n",
       "         1.09176956e-01,  4.38726321e-02,  5.63379884e-01,\n",
       "         1.86247543e-01, -3.74906868e-01,  2.66205221e-01,\n",
       "        -1.09415725e-01,  5.95624670e-02, -2.49439403e-01,\n",
       "        -7.26480246e-01, -1.54395267e-01,  1.95370108e-01,\n",
       "         2.49174371e-01,  5.10113001e-01, -1.57248508e-02,\n",
       "         4.79740053e-02,  6.06779635e-01,  5.73590934e-01,\n",
       "         3.76735389e-01, -9.13210139e-02, -3.64733070e-01,\n",
       "        -2.26380348e-01, -4.94195908e-01,  1.86791029e-02,\n",
       "         1.34660071e-02,  1.95771214e-02, -1.35617465e-01,\n",
       "         1.39889419e-02,  5.79834394e-02, -7.43967481e-03,\n",
       "        -1.12857625e-01, -5.90954535e-03,  1.37251019e-01,\n",
       "         2.42761731e-01, -4.29033190e-01, -5.96303284e-01,\n",
       "         4.67047632e-01,  3.07862937e-01, -3.28794390e-01,\n",
       "         3.29876947e-03,  5.48493564e-02, -3.43445867e-01,\n",
       "         4.67107773e-01,  2.53202558e-01,  8.38673338e-02,\n",
       "        -5.55987880e-02, -1.66938171e-01,  1.87343806e-01,\n",
       "         2.05552340e-01,  1.46243209e-02, -2.57524978e-02,\n",
       "         8.34365368e-01, -5.21234035e-01, -2.06688911e-01,\n",
       "        -5.83376169e-01,  7.31510818e-02,  5.27170077e-02,\n",
       "         4.68184412e-01, -7.89115727e-01, -5.83544746e-02,\n",
       "        -2.89437324e-01, -1.65311202e-01, -1.45593926e-01,\n",
       "         2.76318759e-01, -4.48176339e-02,  1.07606657e-01,\n",
       "         1.18476674e-01, -7.09982589e-02, -7.58033752e-01,\n",
       "        -1.44170478e-01,  2.19730556e-01, -5.81316352e-01,\n",
       "         1.50675982e-01, -6.08944714e-01, -2.25739107e-01,\n",
       "        -3.44215423e-01, -1.73040166e-01,  5.17617464e-01,\n",
       "        -2.66007483e-01,  1.86534107e-01,  6.34758234e-01,\n",
       "        -6.80031002e-01, -2.26431936e-01, -5.69184959e-01,\n",
       "        -1.54726371e-01,  4.12123293e-01,  3.77093911e-01,\n",
       "         1.62592545e-01,  9.75334719e-02, -4.75362912e-02,\n",
       "        -7.05190480e-01, -8.49750757e-01, -1.73352182e-01,\n",
       "         1.27786338e-01,  2.94758379e-01, -3.32815528e-01,\n",
       "        -3.46894294e-01,  1.16370417e-01,  3.95624518e-01,\n",
       "         1.02556497e-01, -7.95378864e-01, -4.54569161e-01,\n",
       "        -3.17877859e-01,  1.25813812e-01,  1.92210674e-01,\n",
       "        -2.36416891e-01,  1.93646163e-01, -6.43366203e-02,\n",
       "         1.93542391e-01, -4.05296564e-01, -1.58947065e-01,\n",
       "         1.81286603e-01,  2.75104582e-01,  6.20971560e-01,\n",
       "        -2.03578308e-01, -3.20983320e-01, -3.41096312e-01,\n",
       "        -7.83514142e-01,  1.50162831e-01, -1.62264884e-01,\n",
       "        -1.01506852e-01, -2.82766074e-01,  1.96518064e-01,\n",
       "         1.79320052e-01, -4.33613539e-01,  4.29093927e-01,\n",
       "        -1.70782745e-01,  5.17793596e-01, -4.61350977e-01,\n",
       "        -3.50260705e-01, -2.70406276e-01, -3.16396534e-01,\n",
       "         1.90869078e-01, -2.46872589e-01, -1.33459121e-01,\n",
       "        -1.86072528e-01,  2.38344781e-02,  5.37082016e-01,\n",
       "         3.02410364e-01, -1.44010186e-01, -7.84029841e-01,\n",
       "        -1.10719621e-01, -5.08228540e-01, -4.21994366e-03,\n",
       "        -4.65185829e-02,  1.66937515e-01, -3.99929993e-02,\n",
       "        -2.49294356e-01, -4.33992386e-01, -4.59349975e-02,\n",
       "        -2.48969018e-01, -1.63041055e-01, -1.13971077e-01,\n",
       "        -1.16403900e-01,  3.11383039e-01, -6.96174622e-01,\n",
       "        -1.70592278e-01,  3.78196448e-01, -3.66369903e-01,\n",
       "        -5.05349278e-01,  4.23356771e-01,  8.67562220e-02,\n",
       "         3.16207260e-01,  1.89601853e-01,  4.41145822e-02,\n",
       "         5.33334732e-01,  4.84252185e-01,  5.42761981e-01,\n",
       "         3.87314111e-01,  5.68664193e-01,  1.58203673e-02,\n",
       "        -4.44995284e-01, -5.82136661e-02, -6.39829636e-01,\n",
       "        -1.96689621e-01,  1.92896932e-01, -8.31735134e-01,\n",
       "         5.08700371e-01, -9.83566418e-02,  4.00800079e-01,\n",
       "         1.20800704e-01, -8.15004587e-01, -1.38265789e-02,\n",
       "         8.46404731e-01, -1.31270677e-01, -1.48868889e-01,\n",
       "         7.71082640e-01, -7.50665367e-01,  2.56537467e-01,\n",
       "         2.85912603e-01, -1.52637362e-01,  1.44040482e-02,\n",
       "         3.26336026e-01, -3.19974776e-03,  4.06990409e-01,\n",
       "         3.51296902e-01,  4.00487244e-01,  4.51254189e-01,\n",
       "        -3.71583588e-02,  2.59744793e-01,  2.74193645e-01,\n",
       "         1.58753976e-01,  2.51232207e-01,  7.12475002e-01,\n",
       "         2.07588598e-01, -4.06890213e-01,  2.30792448e-01,\n",
       "        -4.33036573e-02, -1.79260954e-01, -2.11958587e-01,\n",
       "        -2.86517143e-01, -9.83150899e-01, -2.20467284e-01,\n",
       "        -1.27252281e-01,  7.25820544e-04, -2.42407545e-01,\n",
       "         3.17697018e-01,  2.17920780e-01,  1.47605419e-01,\n",
       "         3.41114700e-01, -8.18215609e-02,  2.42364466e-01,\n",
       "        -2.18873203e-01,  2.60785639e-01,  2.59034514e-01,\n",
       "        -7.82520697e-02, -6.18792295e-01,  1.51995331e-01,\n",
       "        -1.59082219e-01,  2.27165185e-02,  9.63800326e-02,\n",
       "        -2.89476037e-01, -1.74886391e-01,  7.48438910e-02,\n",
       "         6.55881345e-01, -3.27311903e-01,  1.78466573e-01,\n",
       "         1.87865376e-01, -7.38340855e-01,  1.63133413e-01,\n",
       "         3.31343740e-01, -4.34607357e-01, -2.67050207e-01,\n",
       "        -1.98505700e-01,  3.94331962e-01, -4.99702543e-01,\n",
       "        -1.18444022e-02, -8.48310739e-02, -3.53369266e-01,\n",
       "         7.14981377e-01,  1.58869341e-01,  4.47767586e-01,\n",
       "         4.29030120e-01,  9.99435782e-02, -3.77641432e-02,\n",
       "        -2.08708927e-01,  9.17979404e-02,  2.17333347e-01,\n",
       "        -2.31922910e-01,  2.05083296e-01,  2.54024178e-01,\n",
       "        -4.26969886e-01, -7.98548162e-01,  2.54102677e-01,\n",
       "        -3.28736305e-01, -6.39259040e-01,  3.99413973e-01,\n",
       "        -2.18354449e-01, -5.68370938e-01, -1.52747139e-01,\n",
       "         5.05787849e-01, -5.62664755e-02,  1.21934921e-01,\n",
       "         3.01850319e-01, -3.87350231e-01, -7.41293281e-02,\n",
       "         6.37380064e-01, -1.71804905e-01,  7.47446239e-01,\n",
       "        -4.36728477e-01, -4.85439837e-01, -9.54166949e-01,\n",
       "         7.19844162e-01,  1.74386412e-01,  6.48202777e-01,\n",
       "        -2.42635801e-01,  2.49261528e-01, -4.09597605e-01,\n",
       "         3.49284232e-01,  5.19240558e-01,  9.86051932e-02,\n",
       "         3.70023280e-01, -5.73551059e-01,  2.83290178e-01,\n",
       "        -1.25443518e-01,  1.64539620e-01,  7.28340805e-01,\n",
       "         2.51488954e-01, -4.67850156e-02,  1.75410863e-02,\n",
       "         2.61831701e-01, -8.46973479e-01,  3.25518727e-01,\n",
       "         3.77144068e-02, -3.50478590e-01,  2.63329715e-01,\n",
       "         2.08433986e-01, -1.11702256e-01, -2.02094734e-01,\n",
       "        -2.79997051e-01, -4.87701297e-02,  1.34702757e-01,\n",
       "        -4.25580174e-01, -4.21911567e-01, -7.03046992e-02,\n",
       "        -3.77498627e-01,  1.66085362e-02,  3.67755978e-03,\n",
       "         4.63180423e-01, -3.82263124e-01, -2.14547783e-01,\n",
       "        -9.88712668e-01,  6.13148361e-02,  1.65597543e-01,\n",
       "        -5.71927726e-01, -9.23252851e-02, -2.52694964e-01,\n",
       "        -3.82005244e-01,  5.34283705e-02, -1.68693244e-01,\n",
       "         2.28858531e-01,  1.11000776e-01, -4.13223058e-01]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ctx_encoder(**ctx_tokenizer(dataset[0][\"sentence\"], return_tensors=\"pt\").to(device))[\"pooler_output\"].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPRContextEncoder(\n",
       "  (ctx_encoder): DPREncoder(\n",
       "    (bert_model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 184718/3034846 [16:58<4:34:56, 172.77ex/s]"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    ds_with_embeddings = dataset.map(lambda example: {'embeddings': ctx_encoder(**ctx_tokenizer(example[\"sentence\"], return_tensors=\"pt\",padding=True ,truncation=True).to(device))[\"pooler_output\"].detach().cpu().numpy()},num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_with_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1447/1448 [12:57<00:00,  1.86ba/s]\n"
     ]
    }
   ],
   "source": [
    "# dataset = dataset.map(lambda x: {\"embeddings\": np.array( model.encode(x[\"sentence\"]))}, batched=True, batch_size=2096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3035/3035 [00:06<00:00, 469.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['date', 'hash', 'title', 'sentence', 'embeddings'],\n",
       "    num_rows: 3034846\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset.add_faiss_index(column='embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['date', 'hash', 'title', 'sentence', 'embeddings'],\n",
       "    num_rows: 3034846\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.save_to_disk(\"/workspace/data/filtered_split_dprc_sentences_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "please remove all the indexes using `dataset.drop_index` before saving a dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset\u001b[39m.\u001b[39;49msave_to_disk(\u001b[39m\"\u001b[39;49m\u001b[39m/workspace/data/filtered_split_sentences_embeddings\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py:1209\u001b[0m, in \u001b[0;36mDataset.save_to_disk\u001b[0;34m(self, dataset_path, fs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[39mSaves a dataset to a dataset directory, or in a filesystem using either :class:`~filesystems.S3FileSystem` or\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m \u001b[39many implementation of ``fsspec.spec.AbstractFileSystem``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[1;32m   1207\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlist_indexes():\n\u001b[0;32m-> 1209\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mplease remove all the indexes using `dataset.drop_index` before saving a dataset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1211\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten_indices() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[39mif\u001b[39;00m is_remote_filesystem(fs):\n",
      "\u001b[0;31mValueError\u001b[0m: please remove all the indexes using `dataset.drop_index` before saving a dataset"
     ]
    }
   ],
   "source": [
    "ds_with_embeddings.save_to_disk(\"/workspace/data/filtered_split_sentences_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.weight', 'ctx_encoder.bert_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "# import torch\n",
    "# torch.set_grad_enabled(False)\n",
    "# ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "# ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
