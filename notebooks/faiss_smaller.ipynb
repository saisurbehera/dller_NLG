{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "ds =   load_from_disk(\"/workspace/data/filtered_small_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['date', 'sentence_split', 'non_split', 'hash', 'embeddings'],\n",
       "        num_rows: 177300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_examples(examples):\n",
    "    split_title = [ i.split(\"\\n\")[0] for i in examples[\"sentence_split\"]]\n",
    "    examples[\"title\"] = split_title\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02120685577392578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#0",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4390b06b05b49ec8aa576169067e36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017381906509399414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#1",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e423e37eaaf409bad31009e242f114c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02162480354309082,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#2",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b330a49bab9b46cf95937d4ecf1d482e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018629789352416992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#3",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20be4afefaaa4fb5adc236651677c576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01694464683532715,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#4",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847cd1be1cdb47209ee38c0210f652fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016704559326171875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#5",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6dd2aaa89042959f126925598979f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016887664794921875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#6",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d065274c237441f1a4068c1132ac7ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01714348793029785,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#7",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715a50529fbe48a8bd64a02f386081be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017277002334594727,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#8",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdba13cf5c14f55adf9b1212de54a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01744222640991211,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#9",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546d7ef34f02400f9b8ac73e7db92d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017781496047973633,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#10",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef5b747bb424bba9278af2587e05b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#10:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02350449562072754,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#11",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b721886355648c8912bf878565ed4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#11:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.024115324020385742,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#12",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3452bab159584eb3a56d9728e4674625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#12:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018957138061523438,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#13",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179ae9f38ddf42f586ceff2495f166ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#13:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02807021141052246,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#14",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4d586a7330422e9500d3033772488c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#14:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03852081298828125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#15",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2634c654fc43c39ddd3fc8905e2bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#15:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03653073310852051,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#16",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c57e859b074268b28ad660ac808a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#16:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.028974533081054688,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#17",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ebb7fdf867446d95635bfce302b002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#17:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.024137020111083984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#18",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5559f1b96dfe492b9878464f510467ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#18:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.025653600692749023,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#19",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c24c6e8c6449238f9f8c2298b3efe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#19:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.030698776245117188,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#20",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadafca7e74c44288214472b1a811997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#20:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.031035423278808594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#21",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78ab062ca3f4d549cdb8230c1e469d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#21:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03138160705566406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#22",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f9e42c5ab44773868ce33a92ccf3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#22:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.04096412658691406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#23",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27690f90c8b490f82e430ea3aa6ab4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#23:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.04658317565917969,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#24",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806eb9828e7e40aba70dd9aed385e41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#24:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.05651354789733887,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#25",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b6a99bc2b7458394064a8dcfdefb6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#25:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.09468793869018555,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#28",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133f3d2710cf44e09327038e864421d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#28:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.11959981918334961,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#26",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6cbed95b2c40caba77f94aae4efe03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#26:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.12774038314819336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#27",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65568f583fa4850aa3cba5ecf727402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#27:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.1425790786743164,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#29",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b0128892b94f16b46a26ee48ecc416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#29:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.08870887756347656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#30",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002c9b718dbc4744a93eb8d908b28c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#30:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0856783390045166,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#31",
       "rate": null,
       "total": 6,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48c78fba73b4c4381eed6f9d5a3b54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#31:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_title = ds.map(get_title_examples, batched=True, num_proc=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': 20080101,\n",
       " 'sentence_split': 'Gumbel Is Precisely the Problem for the NFL Network\\nOne of the risks the NFL Network faced by having CBS and NBC simulcast the Patriots-Giants game Saturday night was the exposure to a wider world it would give Bryant Gumbel, the channel\\'s play-by-play announcer.\\nThe NFL Network reaches 43 million cable and satellite subscribers, but the simulcast increased the viewing universe to 113 million TV homes.\\nIn all, an average of 34.5 million viewers watched on CBS, NBC, the NFL Network, Channel 9 in New York, WCVB-TV in Boston and WMUR-TV in Manchester, N.H. - the most for any regular-season N.F.L. broadcast since 1995.\\nLet\\'s put that number in perspective.\\nIt required six channels in prime time to surpass the 33.8 million who watched the Nov. 4 Patriots-Colts afternoon game on CBS.\\nFew among the 34.5 million could have been disappointed.\\nBut what could those viewers have thought of the usually well-spoken Gumbel, who said early in the game, \"The Patriots with their high-powered offense come back on the field for the first time this evening\"?\\nThey heard someone who shouldn\\'t be in this seat, not beside Cris Collinsworth, who has proved through his work on the NFL Network, NBC and HBO that he is the best N.F.L. analyst around.\\nBut Gumbel, one of the most talented studio personalities of the last 25 years, is struggling to learn what he should be doing after the network\\'s two seasons.\\nHe doesn\\'t see the field well, which leads him to be imprecise (or wrong) about yardage gained on a play or the yard line.\\nMore often than not, he will not even try to provide the yardage.\\nHis imprecision leads him to fall back on ambiguities like \"the ball is inside the 10\" or \"way short of the first-down marker,\" phrases that more experienced announcers only occasionally use.\\nGumbel uses them as crutches.\\nHe repeatedly locates a play as going to \"this side\" or the \"far side,\" when \"right\" or \"left\" will suffice.\\nHe too frequently uses \"stone\" as a verb to denote a runner gaining little or no yardage.\\nHow about \"stacked up\" or \"stopped\"?\\nWith the Giants ahead by 28-23, he said the Patriots were \"within one score.\"\\nWithin a touchdown, please.\\nWhen New England scored to make it 38-28, he said, \"They\\'ve moved ahead by two scores.\"\\nWhich two scores?\\nMost every fan knew, but his pattern of vagueness had long before set in.\\nGumbel says things that no experienced announcer would.\\nAfter Kevin Boss\\'s touchdown catch gave the Giants a 21-16 lead, Gumbel said a holding penalty on the Patriots was \"waved off.\"\\nThe Giants declined it; the referee didn\\'t declare the flag to be thrown in error.\\nWhen Randy Moss scored on a 4-yard pass in the second quarter, Gumbel crowed, \"How often do you get three N.F.L. records to fall on one play?\"\\nToo bad only one record, the one for team scoring, was broken on that touchdown; Moss tied Jerry Rice for most touchdown receptions and Tom Brady tied Peyton Manning for most touchdown passes.\\nOn Domenik Hixon\\'s 74-yard kickoff return for a touchdown for the Giants, Gumbel was behind at every point.\\nWhen Hixon was at his 42, Gumbel noted that he received the ball at his 26; when Gumbel said, \"He\\'s breaking past midfield,\" Hixon was already at the 35.\\nWhen Gumbel said, \"Only one more man to beat,\" he never said who that man was.\\nOn Moss\\'s 65-yard touchdown catch, which put the Patriots ahead for good, Gumbel\\'s call ignored James Butler, the defensive back Moss beat.\\nAnd the NFL Network\\'s replays were too close or at too low an angle to see how Moss came free.\\nGumbel\\'s lack of field vision meant that Collinsworth could have done the two-man job on his own.\\nAs for the importance of this game to the NFL Network, that is uncertain.\\nFans who receive the channel seemed to abandon it; on Nov. 29, 10.1 million watched Dallas beat Green Bay on the NFL Network, but only 4.5 million stayed loyal for New England\\'s history-making game.\\nWhere did they go?\\nTo CBS, which drew about 15.68 million; NBC (13.2 million); and Channel 9, WCVB and WMUR (about 1.2 million).\\nE-mail: sportsbiz@nytimes.com\\n',\n",
       " 'non_split': 'Gumbel Is Precisely the Problem for the NFL Network\\n\\nOne of the risks the NFL Network faced by having CBS and NBC simulcast the Patriots-Giants game Saturday night was the exposure to a wider world it would give Bryant Gumbel, the channel\\'s play-by-play announcer.\\n\\nThe NFL Network reaches 43 million cable and satellite subscribers, but the simulcast increased the viewing universe to 113 million TV homes.\\n\\nIn all, an average of 34.5 million viewers watched on CBS, NBC, the NFL Network, Channel 9 in New York, WCVB-TV in Boston and WMUR-TV in Manchester, N.H. - the most for any regular-season N.F.L. broadcast since 1995.\\n\\nLet\\'s put that number in perspective. It required six channels in prime time to surpass the 33.8 million who watched the Nov. 4 Patriots-Colts afternoon game on CBS.\\n\\nFew among the 34.5 million could have been disappointed. But what could those viewers have thought of the usually well-spoken Gumbel, who said early in the game, \"The Patriots with their high-powered offense come back on the field for the first time this evening\"?\\n\\nThey heard someone who shouldn\\'t be in this seat, not beside Cris Collinsworth, who has proved through his work on the NFL Network, NBC and HBO that he is the best N.F.L. analyst around.\\n\\nBut Gumbel, one of the most talented studio personalities of the last 25 years, is struggling to learn what he should be doing after the network\\'s two seasons.\\n\\nHe doesn\\'t see the field well, which leads him to be imprecise (or wrong) about yardage gained on a play or the yard line. More often than not, he will not even try to provide the yardage.\\n\\n\\nHis imprecision leads him to fall back on ambiguities like \"the ball is inside the 10\" or \"way short of the first-down marker,\" phrases that more experienced announcers only occasionally use. Gumbel uses them as crutches. He repeatedly locates a play as going to \"this side\" or the \"far side,\" when \"right\" or \"left\" will suffice. He too frequently uses \"stone\" as a verb to denote a runner gaining little or no yardage. How about \"stacked up\" or \"stopped\"?\\n\\nWith the Giants ahead by 28-23, he said the Patriots were \"within one score.\" Within a touchdown, please. When New England scored to make it 38-28, he said, \"They\\'ve moved ahead by two scores.\" Which two scores? Most every fan knew, but his pattern of vagueness had long before set in.\\n\\nGumbel says things that no experienced announcer would. After Kevin Boss\\'s touchdown catch gave the Giants a 21-16 lead, Gumbel said a holding penalty on the Patriots was \"waved off.\" The Giants declined it; the referee didn\\'t declare the flag to be thrown in error.\\n\\nWhen Randy Moss scored on a 4-yard pass in the second quarter, Gumbel crowed, \"How often do you get three N.F.L. records to fall on one play?\" Too bad only one record, the one for team scoring, was broken on that touchdown; Moss tied Jerry Rice for most touchdown receptions and Tom Brady tied Peyton Manning for most touchdown passes.\\n\\n\\nOn Domenik Hixon\\'s 74-yard kickoff return for a touchdown for the Giants, Gumbel was behind at every point. When Hixon was at his 42, Gumbel noted that he received the ball at his 26; when Gumbel said, \"He\\'s breaking past midfield,\" Hixon was already at the 35. When Gumbel said, \"Only one more man to beat,\" he never said who that man was.\\n\\nOn Moss\\'s 65-yard touchdown catch, which put the Patriots ahead for good, Gumbel\\'s call ignored James Butler, the defensive back Moss beat. And the NFL Network\\'s replays were too close or at too low an angle to see how Moss came free.\\n\\nGumbel\\'s lack of field vision meant that Collinsworth could have done the two-man job on his own.\\n\\nAs for the importance of this game to the NFL Network, that is uncertain. Fans who receive the channel seemed to abandon it; on Nov. 29, 10.1 million watched Dallas beat Green Bay on the NFL Network, but only 4.5 million stayed loyal for New England\\'s history-making game.\\n\\nWhere did they go? To CBS, which drew about 15.68 million; NBC (13.2 million); and Channel 9, WCVB and WMUR (about 1.2 million).\\n\\nE-mail: sportsbiz@nytimes.com\\n',\n",
       " 'hash': '96fc64e2c3e274d3326079683aba277d7a366e0a72d55f5256c41494d63cf533',\n",
       " 'embeddings': [0.08627419173717499,\n",
       "  0.2024002969264984,\n",
       "  -0.013621029444038868,\n",
       "  -0.34191352128982544,\n",
       "  -0.18945789337158203,\n",
       "  0.12711375951766968,\n",
       "  0.28443992137908936,\n",
       "  -0.14320939779281616,\n",
       "  -0.25311073660850525,\n",
       "  -0.7111242413520813,\n",
       "  0.022466054186224937,\n",
       "  0.9060071110725403,\n",
       "  -0.0929441824555397,\n",
       "  -0.35828226804733276,\n",
       "  0.0779537782073021,\n",
       "  0.7090550661087036,\n",
       "  0.4177390933036804,\n",
       "  0.34418824315071106,\n",
       "  -0.17631486058235168,\n",
       "  -0.51267409324646,\n",
       "  -0.4716074764728546,\n",
       "  -0.4188372790813446,\n",
       "  0.4078556001186371,\n",
       "  -0.542405903339386,\n",
       "  0.0015026460168883204,\n",
       "  0.19210362434387207,\n",
       "  0.04911218583583832,\n",
       "  0.31539198756217957,\n",
       "  -0.35020700097084045,\n",
       "  0.25330084562301636,\n",
       "  -0.10278245806694031,\n",
       "  0.10468662530183792,\n",
       "  -0.12101006507873535,\n",
       "  -0.356772243976593,\n",
       "  -0.3885418474674225,\n",
       "  -0.25272122025489807,\n",
       "  0.4484970271587372,\n",
       "  -0.09481003135442734,\n",
       "  0.3462268114089966,\n",
       "  0.04217088595032692,\n",
       "  0.3065469264984131,\n",
       "  -0.044480010867118835,\n",
       "  -0.45102226734161377,\n",
       "  0.04616010561585426,\n",
       "  -0.42472097277641296,\n",
       "  -0.16557584702968597,\n",
       "  -1.6422665119171143,\n",
       "  -0.08433573693037033,\n",
       "  -0.5010939240455627,\n",
       "  -0.17156586050987244,\n",
       "  0.09926477074623108,\n",
       "  0.13514482975006104,\n",
       "  -0.031217306852340698,\n",
       "  0.47873371839523315,\n",
       "  -0.27576571702957153,\n",
       "  -0.02971644140779972,\n",
       "  0.21417813003063202,\n",
       "  -0.33014971017837524,\n",
       "  0.4803179204463959,\n",
       "  -0.28114959597587585,\n",
       "  -0.10920259356498718,\n",
       "  -0.08010334521532059,\n",
       "  0.18079602718353271,\n",
       "  0.01841687597334385,\n",
       "  0.1341361552476883,\n",
       "  0.3147954046726227,\n",
       "  -0.44161537289619446,\n",
       "  0.11828933656215668,\n",
       "  -0.14547032117843628,\n",
       "  0.3405994176864624,\n",
       "  0.03782130405306816,\n",
       "  -0.7917042970657349,\n",
       "  -0.3103874623775482,\n",
       "  -0.0723094791173935,\n",
       "  0.6444255113601685,\n",
       "  0.0439184233546257,\n",
       "  0.22505362331867218,\n",
       "  0.028429515659809113,\n",
       "  0.3651537299156189,\n",
       "  0.27139556407928467,\n",
       "  -0.16235971450805664,\n",
       "  0.038024723529815674,\n",
       "  0.31788137555122375,\n",
       "  0.31823351979255676,\n",
       "  0.10358189791440964,\n",
       "  0.2994321584701538,\n",
       "  0.2898752987384796,\n",
       "  0.2933826446533203,\n",
       "  -0.0014655886916443706,\n",
       "  0.3276419937610626,\n",
       "  0.06979795545339584,\n",
       "  -1.0011390447616577,\n",
       "  -0.14829042553901672,\n",
       "  -0.3874686360359192,\n",
       "  -0.2679995894432068,\n",
       "  -0.2800290584564209,\n",
       "  0.6290721297264099,\n",
       "  0.20717212557792664,\n",
       "  -0.16693344712257385,\n",
       "  -0.021559175103902817,\n",
       "  -0.21131068468093872,\n",
       "  -0.3675437271595001,\n",
       "  0.5315449833869934,\n",
       "  0.24615733325481415,\n",
       "  -0.2688427269458771,\n",
       "  -0.16743288934230804,\n",
       "  0.101542167365551,\n",
       "  -0.44802549481391907,\n",
       "  -0.4769589602947235,\n",
       "  0.41865795850753784,\n",
       "  -0.35272830724716187,\n",
       "  0.4635799527168274,\n",
       "  0.6121540665626526,\n",
       "  -0.2201065570116043,\n",
       "  -0.44075122475624084,\n",
       "  -0.05244285613298416,\n",
       "  0.5329230427742004,\n",
       "  -0.6105116605758667,\n",
       "  -0.2781814634799957,\n",
       "  0.41335439682006836,\n",
       "  0.016818339005112648,\n",
       "  0.8112428188323975,\n",
       "  0.5248375535011292,\n",
       "  -0.04195820167660713,\n",
       "  -0.5468417406082153,\n",
       "  -0.5908753275871277,\n",
       "  0.06357134133577347,\n",
       "  0.6312568187713623,\n",
       "  -0.27920112013816833,\n",
       "  0.3722792863845825,\n",
       "  0.08432073891162872,\n",
       "  0.7422995567321777,\n",
       "  -0.20688505470752716,\n",
       "  0.0547100305557251,\n",
       "  -0.29653334617614746,\n",
       "  -0.19441723823547363,\n",
       "  -0.04981972649693489,\n",
       "  -0.2753136456012726,\n",
       "  -0.2747326195240021,\n",
       "  0.0927094966173172,\n",
       "  -0.1555732786655426,\n",
       "  -0.19383949041366577,\n",
       "  -0.6870051026344299,\n",
       "  -0.5148232579231262,\n",
       "  -0.15759466588497162,\n",
       "  -0.48398682475090027,\n",
       "  -0.27386927604675293,\n",
       "  0.653231143951416,\n",
       "  0.05417264997959137,\n",
       "  0.1168936938047409,\n",
       "  0.10413837432861328,\n",
       "  -0.17514416575431824,\n",
       "  -0.08475414663553238,\n",
       "  -0.14585521817207336,\n",
       "  -0.10323228687047958,\n",
       "  0.6280423402786255,\n",
       "  -0.0037456622812896967,\n",
       "  -0.28548872470855713,\n",
       "  0.09777451306581497,\n",
       "  0.4075629711151123,\n",
       "  0.06296992301940918,\n",
       "  -0.16647616028785706,\n",
       "  -0.28361770510673523,\n",
       "  -0.07780227065086365,\n",
       "  0.42462271451950073,\n",
       "  0.1321190744638443,\n",
       "  0.1516362428665161,\n",
       "  -0.46267324686050415,\n",
       "  -0.18307149410247803,\n",
       "  -0.19446836411952972,\n",
       "  0.3076780438423157,\n",
       "  0.22604252398014069,\n",
       "  0.11374873667955399,\n",
       "  -0.18742389976978302,\n",
       "  -0.007396876346319914,\n",
       "  0.30163711309432983,\n",
       "  0.6899356842041016,\n",
       "  0.19303391873836517,\n",
       "  -0.025711972266435623,\n",
       "  -0.294236958026886,\n",
       "  -0.6952047944068909,\n",
       "  -0.5708282589912415,\n",
       "  0.19841113686561584,\n",
       "  0.1374635100364685,\n",
       "  0.21370340883731842,\n",
       "  -0.04490995407104492,\n",
       "  0.2735391855239868,\n",
       "  -0.08993366360664368,\n",
       "  -0.17510387301445007,\n",
       "  -0.3588821291923523,\n",
       "  -0.18037599325180054,\n",
       "  -1.026841640472412,\n",
       "  0.49734216928482056,\n",
       "  -0.5290601253509521,\n",
       "  0.5128339529037476,\n",
       "  -0.2430858314037323,\n",
       "  0.08660959452390671,\n",
       "  0.2688775360584259,\n",
       "  0.6166781187057495,\n",
       "  -0.0992155373096466,\n",
       "  0.5277397632598877,\n",
       "  -0.6523657441139221,\n",
       "  0.2608475983142853,\n",
       "  -0.15428146719932556,\n",
       "  -0.3656315207481384,\n",
       "  0.7711829543113708,\n",
       "  0.41124728322029114,\n",
       "  -0.1563481241464615,\n",
       "  -0.2792220115661621,\n",
       "  0.18104177713394165,\n",
       "  0.9685592651367188,\n",
       "  -0.09196405857801437,\n",
       "  -0.4231097400188446,\n",
       "  -0.330980509519577,\n",
       "  -0.41277942061424255,\n",
       "  0.057934220880270004,\n",
       "  0.16386228799819946,\n",
       "  -0.18591520190238953,\n",
       "  0.05883941799402237,\n",
       "  -0.5156267285346985,\n",
       "  0.2569815516471863,\n",
       "  0.09912405163049698,\n",
       "  0.5119271278381348,\n",
       "  0.47779175639152527,\n",
       "  -0.07998712360858917,\n",
       "  0.08868876099586487,\n",
       "  -0.34868624806404114,\n",
       "  0.15759865939617157,\n",
       "  0.14075808227062225,\n",
       "  -0.7931858897209167,\n",
       "  0.2320307493209839,\n",
       "  0.012462068349123001,\n",
       "  -0.08641564846038818,\n",
       "  -0.9026763439178467,\n",
       "  -0.48425403237342834,\n",
       "  -0.19990181922912598,\n",
       "  0.03639218956232071,\n",
       "  -0.26363638043403625,\n",
       "  0.422927588224411,\n",
       "  -0.341702938079834,\n",
       "  0.22940489649772644,\n",
       "  0.0031884382478892803,\n",
       "  -0.21258790791034698,\n",
       "  0.18257145583629608,\n",
       "  -0.19619803130626678,\n",
       "  -0.5907460451126099,\n",
       "  -0.20919053256511688,\n",
       "  0.7456780672073364,\n",
       "  -0.461432546377182,\n",
       "  -0.1634165197610855,\n",
       "  -0.002310611307621002,\n",
       "  0.07266510277986526,\n",
       "  0.3113314211368561,\n",
       "  -0.3103213906288147,\n",
       "  -0.027897872030735016,\n",
       "  0.5258461236953735,\n",
       "  -0.023135216906666756,\n",
       "  0.15133877098560333,\n",
       "  0.47167739272117615,\n",
       "  -0.03069990687072277,\n",
       "  0.23204419016838074,\n",
       "  -0.15727056562900543,\n",
       "  -0.07460059970617294,\n",
       "  0.23233981430530548,\n",
       "  -0.737460196018219,\n",
       "  -0.1331789642572403,\n",
       "  -0.6474927663803101,\n",
       "  -0.015695316717028618,\n",
       "  -0.17357543110847473,\n",
       "  -0.11880285292863846,\n",
       "  0.06126299500465393,\n",
       "  0.40184837579727173,\n",
       "  -0.5580247044563293,\n",
       "  0.4504028558731079,\n",
       "  0.09666203707456589,\n",
       "  -0.452823281288147,\n",
       "  0.13142554461956024,\n",
       "  0.42380431294441223,\n",
       "  -0.30236026644706726,\n",
       "  -0.5761001706123352,\n",
       "  0.20441120862960815,\n",
       "  0.3105364739894867,\n",
       "  0.6443557143211365,\n",
       "  -0.030565908178687096,\n",
       "  -0.3400026261806488,\n",
       "  -0.7475519776344299,\n",
       "  0.476220041513443,\n",
       "  -0.08792142570018768,\n",
       "  -0.22760306298732758,\n",
       "  0.043517813086509705,\n",
       "  -0.03527383506298065,\n",
       "  0.2550618052482605,\n",
       "  0.49188432097435,\n",
       "  -0.024684220552444458,\n",
       "  0.4372623562812805,\n",
       "  0.6798137426376343,\n",
       "  0.4970577359199524,\n",
       "  -0.44736507534980774,\n",
       "  0.19361421465873718,\n",
       "  -0.39460116624832153,\n",
       "  -0.48523232340812683,\n",
       "  0.456798791885376,\n",
       "  0.18969787657260895,\n",
       "  -0.6336532235145569,\n",
       "  0.29220840334892273,\n",
       "  -0.42669156193733215,\n",
       "  -0.7856218218803406,\n",
       "  -0.17136922478675842,\n",
       "  -5.9801130294799805,\n",
       "  -0.043342527002096176,\n",
       "  -0.4510439932346344,\n",
       "  -0.31424492597579956,\n",
       "  0.36835914850234985,\n",
       "  -0.13991408050060272,\n",
       "  0.15563394129276276,\n",
       "  -0.853813886642456,\n",
       "  -0.22169145941734314,\n",
       "  0.6481783986091614,\n",
       "  0.20562827587127686,\n",
       "  0.2343187779188156,\n",
       "  0.28448691964149475,\n",
       "  0.21238525211811066,\n",
       "  0.8446696996688843,\n",
       "  -0.10695957392454147,\n",
       "  0.48489412665367126,\n",
       "  0.11215673387050629,\n",
       "  0.2885721027851105,\n",
       "  0.24861064553260803,\n",
       "  -0.1304606944322586,\n",
       "  -0.2259252518415451,\n",
       "  0.9197397828102112,\n",
       "  -0.2902165353298187,\n",
       "  0.19085919857025146,\n",
       "  0.8580963611602783,\n",
       "  -0.7775321006774902,\n",
       "  0.5167681574821472,\n",
       "  0.37471190094947815,\n",
       "  -0.6006858348846436,\n",
       "  0.4614567160606384,\n",
       "  -0.38336846232414246,\n",
       "  -0.12178201228380203,\n",
       "  0.6755570769309998,\n",
       "  0.07613684237003326,\n",
       "  -0.1596800535917282,\n",
       "  0.0829196497797966,\n",
       "  -0.5683380365371704,\n",
       "  0.04995928332209587,\n",
       "  -0.08121655881404877,\n",
       "  0.7281990051269531,\n",
       "  0.4213714599609375,\n",
       "  0.017731759697198868,\n",
       "  -0.4423291087150574,\n",
       "  0.3101397454738617,\n",
       "  -0.06424690783023834,\n",
       "  -0.3598259687423706,\n",
       "  -0.6640442609786987,\n",
       "  -0.26252424716949463,\n",
       "  0.7539947628974915,\n",
       "  0.2101348489522934,\n",
       "  0.20959842205047607,\n",
       "  -0.014981978572905064,\n",
       "  0.3941384255886078,\n",
       "  0.05188766121864319,\n",
       "  -0.7015561461448669,\n",
       "  0.7479495406150818,\n",
       "  -0.22505903244018555,\n",
       "  -0.3801361918449402,\n",
       "  0.12748873233795166,\n",
       "  0.154976487159729,\n",
       "  -0.6626855134963989,\n",
       "  -0.03591646999120712,\n",
       "  -0.3160345256328583,\n",
       "  0.16595470905303955,\n",
       "  -0.6280137300491333,\n",
       "  -0.4860552251338959,\n",
       "  0.07561507076025009,\n",
       "  0.29442882537841797,\n",
       "  -0.26233917474746704,\n",
       "  -0.3678908944129944,\n",
       "  -0.3118130564689636,\n",
       "  0.5881184935569763,\n",
       "  -0.6125075221061707,\n",
       "  0.1031186431646347,\n",
       "  -0.24017661809921265,\n",
       "  -0.09226975589990616,\n",
       "  0.4858815670013428,\n",
       "  -0.20229323208332062,\n",
       "  0.20356424152851105,\n",
       "  -0.5450848340988159,\n",
       "  -0.4143015146255493,\n",
       "  -0.015955399721860886,\n",
       "  0.22616179287433624,\n",
       "  0.3553214371204376,\n",
       "  -0.16845139861106873,\n",
       "  -0.08131837099790573,\n",
       "  0.28618595004081726,\n",
       "  0.3339035212993622,\n",
       "  0.36600860953330994,\n",
       "  0.3316982090473175,\n",
       "  -0.4957113564014435,\n",
       "  0.306955486536026,\n",
       "  0.18226061761379242,\n",
       "  -0.5091797113418579,\n",
       "  0.5239695310592651,\n",
       "  -0.0397786870598793,\n",
       "  0.7359495759010315,\n",
       "  0.7831988334655762,\n",
       "  0.05452951416373253,\n",
       "  0.8073353171348572,\n",
       "  -0.4262222647666931,\n",
       "  0.2504259943962097,\n",
       "  -0.5252792239189148,\n",
       "  0.10317934304475784,\n",
       "  0.03809504583477974,\n",
       "  -0.2879560589790344,\n",
       "  -0.018153715878725052,\n",
       "  0.8410308957099915,\n",
       "  -0.18175536394119263,\n",
       "  0.2186848372220993,\n",
       "  0.2875903248786926,\n",
       "  -0.2904200851917267,\n",
       "  -0.4603898525238037,\n",
       "  0.5069966316223145,\n",
       "  0.15172454714775085,\n",
       "  -0.10557316988706589,\n",
       "  0.32830601930618286,\n",
       "  0.5377454161643982,\n",
       "  -0.19484923779964447,\n",
       "  0.150476336479187,\n",
       "  -0.022070733830332756,\n",
       "  -0.01120645273476839,\n",
       "  -0.3491896986961365,\n",
       "  -0.7814943194389343,\n",
       "  0.10214443504810333,\n",
       "  0.14481502771377563,\n",
       "  0.2454172819852829,\n",
       "  -0.43502965569496155,\n",
       "  0.3887254595756531,\n",
       "  0.36841294169425964,\n",
       "  0.4326383173465729,\n",
       "  0.36035192012786865,\n",
       "  0.376872718334198,\n",
       "  -0.16734737157821655,\n",
       "  -0.12491777539253235,\n",
       "  -0.2763858735561371,\n",
       "  -0.39844441413879395,\n",
       "  0.09718196094036102,\n",
       "  -0.5094434022903442,\n",
       "  0.3086410462856293,\n",
       "  -0.06391354650259018,\n",
       "  0.07951647788286209,\n",
       "  0.3966773450374603,\n",
       "  0.08182647079229355,\n",
       "  -0.26566222310066223,\n",
       "  0.2980681359767914,\n",
       "  0.06808756291866302,\n",
       "  -0.773054838180542,\n",
       "  0.046882446855306625,\n",
       "  0.2455594539642334,\n",
       "  -0.17165906727313995,\n",
       "  0.12951672077178955,\n",
       "  -0.3698083758354187,\n",
       "  0.06023622304201126,\n",
       "  0.44204622507095337,\n",
       "  -0.3195933401584625,\n",
       "  -0.2979932427406311,\n",
       "  -0.047771502286195755,\n",
       "  -0.6326839327812195,\n",
       "  0.438371866941452,\n",
       "  0.4004366099834442,\n",
       "  -0.9725381731987,\n",
       "  -0.2009074091911316,\n",
       "  0.7745084762573242,\n",
       "  -0.35719141364097595,\n",
       "  -0.09125905483961105,\n",
       "  -0.4567161500453949,\n",
       "  -0.37949225306510925,\n",
       "  0.25358352065086365,\n",
       "  -0.1580103039741516,\n",
       "  -0.6244350671768188,\n",
       "  -0.534107506275177,\n",
       "  0.09632551670074463,\n",
       "  0.22820331156253815,\n",
       "  0.10556715726852417,\n",
       "  -0.3012412190437317,\n",
       "  0.07112955302000046,\n",
       "  0.31185922026634216,\n",
       "  0.18223677575588226,\n",
       "  -0.07308468222618103,\n",
       "  -0.08708921074867249,\n",
       "  -0.09583733975887299,\n",
       "  0.2075081616640091,\n",
       "  0.6373499631881714,\n",
       "  -0.19467833638191223,\n",
       "  -0.5351696014404297,\n",
       "  0.05155583471059799,\n",
       "  -1.029150366783142,\n",
       "  0.16368506848812103,\n",
       "  0.3833972215652466,\n",
       "  0.024916399270296097,\n",
       "  0.2126920372247696,\n",
       "  0.33009928464889526,\n",
       "  0.09588422626256943,\n",
       "  -0.2896471917629242,\n",
       "  0.34350189566612244,\n",
       "  0.03950056433677673,\n",
       "  -0.3130475878715515,\n",
       "  -0.32384058833122253,\n",
       "  -0.10539451241493225,\n",
       "  -0.12171901762485504,\n",
       "  -0.60750412940979,\n",
       "  0.1647336333990097,\n",
       "  0.6544548273086548,\n",
       "  -0.22620853781700134,\n",
       "  0.310680091381073,\n",
       "  0.3496665060520172,\n",
       "  -0.08095495402812958,\n",
       "  0.3602712154388428,\n",
       "  -0.09950212389230728,\n",
       "  -0.5922725200653076,\n",
       "  -0.038484569638967514,\n",
       "  0.2485230416059494,\n",
       "  0.020080700516700745,\n",
       "  -0.2895868122577667,\n",
       "  0.1204138770699501,\n",
       "  -0.12387403100728989,\n",
       "  -0.4940958619117737,\n",
       "  0.025481345131993294,\n",
       "  0.03387618437409401,\n",
       "  -0.43847498297691345,\n",
       "  -0.43661463260650635,\n",
       "  0.32529258728027344,\n",
       "  -0.11468078196048737,\n",
       "  -0.007818815298378468,\n",
       "  0.37781381607055664,\n",
       "  -0.3077971637248993,\n",
       "  0.49218714237213135,\n",
       "  0.18151146173477173,\n",
       "  0.002158737974241376,\n",
       "  -0.2449377030134201,\n",
       "  0.869907021522522,\n",
       "  0.9663330316543579,\n",
       "  -0.26710444688796997,\n",
       "  0.09279926121234894,\n",
       "  0.0274317879229784,\n",
       "  0.43104612827301025,\n",
       "  -0.40673723816871643,\n",
       "  0.17881275713443756,\n",
       "  0.5568308234214783,\n",
       "  0.34827423095703125,\n",
       "  -0.20849548280239105,\n",
       "  -0.21043717861175537,\n",
       "  -0.48476019501686096,\n",
       "  0.22090770304203033,\n",
       "  0.48626768589019775,\n",
       "  -0.048355624079704285,\n",
       "  -0.4948846399784088,\n",
       "  0.5572744607925415,\n",
       "  0.3612937331199646,\n",
       "  -0.0034003560431301594,\n",
       "  -0.3904474675655365,\n",
       "  0.30336058139801025,\n",
       "  0.7698736786842346,\n",
       "  -0.3805259168148041,\n",
       "  -0.27257034182548523,\n",
       "  -0.2176966369152069,\n",
       "  0.43720555305480957,\n",
       "  0.1349150389432907,\n",
       "  0.1527305543422699,\n",
       "  -0.6304667592048645,\n",
       "  -0.3359476327896118,\n",
       "  0.17811711132526398,\n",
       "  0.08603327721357346,\n",
       "  0.14905385673046112,\n",
       "  -0.27470630407333374,\n",
       "  -0.2479795515537262,\n",
       "  -0.25744882225990295,\n",
       "  -0.30281001329421997,\n",
       "  -0.8654767274856567,\n",
       "  0.12017237395048141,\n",
       "  0.4652298092842102,\n",
       "  0.04938248172402382,\n",
       "  -0.06431073695421219,\n",
       "  -0.08220034092664719,\n",
       "  -0.16425640881061554,\n",
       "  0.404707133769989,\n",
       "  0.008816377259790897,\n",
       "  -0.09858917444944382,\n",
       "  -0.36230576038360596,\n",
       "  -0.5521398782730103,\n",
       "  -0.4946458339691162,\n",
       "  -0.09929365664720535,\n",
       "  0.19033503532409668,\n",
       "  -0.3512626588344574,\n",
       "  0.11047469079494476,\n",
       "  0.4025692343711853,\n",
       "  0.09758514165878296,\n",
       "  0.06822434067726135,\n",
       "  -0.4826006591320038,\n",
       "  0.09158717095851898,\n",
       "  -0.7050943374633789,\n",
       "  -0.19181182980537415,\n",
       "  -0.3229430019855499,\n",
       "  0.09786107391119003,\n",
       "  0.6675723791122437,\n",
       "  0.08097284287214279,\n",
       "  0.40348854660987854,\n",
       "  0.06235404312610626,\n",
       "  -0.12707708775997162,\n",
       "  0.6782547235488892,\n",
       "  0.046441707760095596,\n",
       "  -0.3279012441635132,\n",
       "  0.11202672868967056,\n",
       "  0.34867456555366516,\n",
       "  -0.16853104531764984,\n",
       "  -0.2786714732646942,\n",
       "  -0.07707781344652176,\n",
       "  -0.2295716255903244,\n",
       "  -0.020363857969641685,\n",
       "  0.27950388193130493,\n",
       "  0.025351975113153458,\n",
       "  1.054611086845398,\n",
       "  -0.5886178016662598,\n",
       "  -0.4351782500743866,\n",
       "  0.7352513074874878,\n",
       "  0.3907974064350128,\n",
       "  -0.29521065950393677,\n",
       "  0.5423951745033264,\n",
       "  0.34281861782073975,\n",
       "  -0.19980008900165558,\n",
       "  0.47267448902130127,\n",
       "  -0.08811821788549423,\n",
       "  -0.46121248602867126,\n",
       "  1.1059197187423706,\n",
       "  0.0012410013005137444,\n",
       "  -0.031497012823820114,\n",
       "  0.4275362193584442,\n",
       "  0.3176867663860321,\n",
       "  0.5262054204940796,\n",
       "  0.4573543965816498,\n",
       "  -0.4182276725769043,\n",
       "  0.07237295061349869,\n",
       "  -0.1132250726222992,\n",
       "  -0.019987476989626884,\n",
       "  0.3060399889945984,\n",
       "  -0.09836767613887787,\n",
       "  -0.12081044167280197,\n",
       "  -0.2201981395483017,\n",
       "  -0.13895152509212494,\n",
       "  0.18272744119167328,\n",
       "  -0.01729167439043522,\n",
       "  0.1389816552400589,\n",
       "  -0.7878439426422119,\n",
       "  -0.13529889285564423,\n",
       "  0.3468102812767029,\n",
       "  -0.09848593920469284,\n",
       "  -0.14220529794692993,\n",
       "  0.38024500012397766,\n",
       "  -0.4795215427875519,\n",
       "  0.1018395870923996,\n",
       "  0.09618008136749268,\n",
       "  -0.27023550868034363,\n",
       "  -0.37890687584877014,\n",
       "  -0.19389833509922028,\n",
       "  0.5654674768447876,\n",
       "  -0.5470679998397827,\n",
       "  -0.6900427937507629,\n",
       "  0.04054699093103409,\n",
       "  0.12944726645946503,\n",
       "  -0.05924077332019806,\n",
       "  0.37058332562446594,\n",
       "  -0.1502360701560974,\n",
       "  -0.2835664451122284,\n",
       "  -0.1776217818260193,\n",
       "  0.6065212488174438,\n",
       "  -0.27363529801368713,\n",
       "  0.153972789645195,\n",
       "  0.3720279932022095,\n",
       "  -0.4008564352989197,\n",
       "  0.2915341854095459,\n",
       "  -0.2176261842250824,\n",
       "  0.09258728474378586,\n",
       "  -0.4319869875907898,\n",
       "  -0.45783528685569763,\n",
       "  0.8625906109809875,\n",
       "  -0.09894546121358871,\n",
       "  0.11188926547765732,\n",
       "  0.6798117756843567,\n",
       "  0.21153061091899872,\n",
       "  0.3787725269794464,\n",
       "  -0.44892290234565735,\n",
       "  -0.22222399711608887,\n",
       "  0.1903294175863266,\n",
       "  0.38742750883102417,\n",
       "  0.17960430681705475,\n",
       "  0.18797455728054047,\n",
       "  -0.27662619948387146,\n",
       "  -0.19232478737831116,\n",
       "  -0.21490232646465302,\n",
       "  -1.0473002195358276,\n",
       "  -0.9972308874130249,\n",
       "  0.3303288519382477,\n",
       "  0.440574049949646,\n",
       "  -0.7497715950012207,\n",
       "  -0.18122966587543488,\n",
       "  0.4884973466396332,\n",
       "  0.526136577129364,\n",
       "  0.25043824315071106,\n",
       "  0.07841084152460098,\n",
       "  0.10428442060947418,\n",
       "  -0.026355553418397903,\n",
       "  0.3343525528907776,\n",
       "  -0.34955382347106934,\n",
       "  -0.16658127307891846,\n",
       "  -0.292731910943985,\n",
       "  -0.5579319000244141,\n",
       "  -0.6521722674369812,\n",
       "  -0.17040583491325378,\n",
       "  0.6655441522598267,\n",
       "  0.44096308946609497,\n",
       "  -0.6688898801803589,\n",
       "  0.02881554700434208,\n",
       "  -0.25434741377830505,\n",
       "  -0.14131546020507812,\n",
       "  0.3526762127876282,\n",
       "  -0.19421149790287018,\n",
       "  0.11763036251068115,\n",
       "  -0.655664324760437,\n",
       "  0.3828680217266083,\n",
       "  -0.19358670711517334,\n",
       "  -0.041676025837659836,\n",
       "  0.4973320960998535,\n",
       "  0.38695505261421204,\n",
       "  0.012634720653295517,\n",
       "  0.0893268808722496,\n",
       "  0.08519355952739716,\n",
       "  -0.5217517018318176,\n",
       "  0.2991587221622467,\n",
       "  -0.27489423751831055,\n",
       "  -0.5030590891838074,\n",
       "  -0.5024738907814026,\n",
       "  -0.04875876009464264,\n",
       "  -0.21616633236408234,\n",
       "  -0.1817978471517563,\n",
       "  0.3847651779651642,\n",
       "  0.28731590509414673,\n",
       "  0.4952857196331024,\n",
       "  -0.6139789819717407,\n",
       "  0.1618201732635498,\n",
       "  0.026790423318743706,\n",
       "  0.17476384341716766,\n",
       "  0.4280726909637451,\n",
       "  0.04541677609086037,\n",
       "  0.7325254082679749,\n",
       "  -0.4468120336532593,\n",
       "  -0.4251113533973694,\n",
       "  -0.08266778290271759,\n",
       "  0.6127668619155884,\n",
       "  -0.2099246382713318,\n",
       "  0.04336319491267204,\n",
       "  0.54161536693573,\n",
       "  0.07936802506446838,\n",
       "  0.20270179212093353,\n",
       "  -0.1449456363916397,\n",
       "  -0.14518390595912933,\n",
       "  0.06642346829175949,\n",
       "  0.38937169313430786,\n",
       "  0.11674188077449799],\n",
       " 'title': 'Gumbel Is Precisely the Problem for the NFL Network'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_title[\"train\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016345739364624023,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 492,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82f7bfb1b8f4e97bf25e39b8cdc7718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/492 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019366741180419922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 437983985,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41b6dd6552a49aa8f1465a13a955b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017791748046875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 28,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96273357023a4470975b74e2fcd9b526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017500877380371094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 231508,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa4b231a2e64b37ab447f084919d24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01606440544128418,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 466062,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2857979abe4c939b97f28bf74e5ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DPRContextEncoder(\n",
       "  (ctx_encoder): DPREncoder(\n",
       "    (bert_model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "ctx_encoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['date', 'sentence_split', 'non_split', 'hash', 'embeddings'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-13364b69a2fa2f95.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-9852f2380fc67645.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-78f7c9f36cd03279.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-a6867ba315a2a7c0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-377ecaebcd72d143.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-925ceced10ae4e2e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-b56df9ecff22ce4b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-0d7f824c27217f05.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-d9648c51f1b12db2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-107e6bc02a2a42b2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-3a3f18913b6ae977.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-0ac1d13cc36dd05a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-d1e1f2af22f6c504.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-f9b1c24100c75272.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-67a8640d6468e985.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-771d68dad085de6b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-be3fd36b23732273.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-a55492a4668f08f4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-04e11df394c9a8c5.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-bf1f7055c235ed20.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-6b9af9f546dbff15.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-a8715c414274187f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-442f3657a97be460.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-2117768c3a4fed31.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-11a2ee39dd4fb794.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-3d6d867d9fb1d4c6.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-43341f1e7d3b7dd1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-854c56b6d8bd1890.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-42da4887017c105b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-ffaa6c23bda8f4bb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-581e240aadfe1074.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-88752dc4613bf853.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-41243ac51ca9a074.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-5a7357cc493967cf.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-a4dfb6a9b4275216.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-ab4e615767517a68.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-5522264321d3e94f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-ebf5f135f551167c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-4a9c517fea6b851c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-29ad5151ca82ced2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-84e89d9c997674f3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/filtered_small/train/cache-cdde4ccf86ee265f.arrow\n"
     ]
    }
   ],
   "source": [
    "# convert base64 string to string\n",
    "import base64\n",
    "# convert base64 string to string\n",
    "def clean_one(base64_string):\n",
    "    return base64.b64decode(base64_string).decode(\"utf-8\")\n",
    "\n",
    "def clean_list(base64_list):\n",
    "    return [clean_one(base64_string) for base64_string in base64_list]\n",
    "\n",
    "def clean_each(example):\n",
    "    example[\"non_split\"] = clean_list(example[\"non_split\"])\n",
    "    example[\"sentence_split\"] = clean_list(example[\"sentence_split\"])\n",
    "    return example\n",
    "\n",
    "# def clean_batch(examples):\n",
    "#     return [clean_each(example) for example in examples]\n",
    "\n",
    "ds = ds.map(clean_each, batched=True, num_proc=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['date', 'sentence_split', 'non_split', 'hash'],\n",
       "        num_rows: 177300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': 20080101,\n",
       " 'sentence_split': 'Radiohead - Music - New York Times\\nLOS ANGELES - \"In Rainbows,\" the latest album from the British rock band Radiohead, has been readily available to music fans for almost three months, first as a digital download in an unconventional tip-jar offering in which fans decided for themselves what to pay for it, and then, like most pop music today, as digital files circulating on free, unlicensed file-swapping networks.\\nOne matter remains: Will anyone buy the CD?\\nStarting on Tuesday, the album, in plastic disc form, is on sale in record shops (this time with a list price, $13.98, that is not subject to consumer whims).\\nThough hard-core fans almost surely have acquired the album, one way or another, Radiohead had plans to promote the CD release with a \"prerecording\" of the band performing songs from \"In Rainbows\" on the www.radiohead.tv Web site starting on Monday, according to the band\\'s Web site, radiohead.com.\\nIt is also to be shown on satellite and cable systems that carry the Current TV channel.\\nThough hailed by critics, the album is seen as an uncertain prospect commercially.\\nThat is because the band has declined to say how many copies have been distributed since October, when it diverged from industry custom and offered a digital download of \"In Rainbows\" for however much fans chose to pay - even nothing.\\nSince then the band\\'s representatives have described the offering as, among other things, a way of testing whether digital downloads eat into sales of CDs.\\nRadiohead chose to release the CD through the independent label ATO Records and its imprint TBD.\\nThe band\\'s 2003 album \"Hail to the Thief\" was the last one under its recording contract with the music giant EMI.\\nATO is shipping an estimated 400,000 copies of the album to record shops, said executives briefed on the label\\'s plans.\\nIt is not uncommon for shops to sell half of the shipment of a big album in its first week on sale.\\nBut Radiohead\\'s performance may differ; not only has the album been widely available online, but it is also hitting record shops in the traditionally slow post-holiday sales period.\\nAs a result, it is seen as a long shot that the band could match the performance of \"Hail to the Thief,\" which sold 300,000 copies in its first week after going on sale in June 2003, and went on to sell a total of roughly 1 million copies, according to Nielsen SoundScan data.\\nWill Botwin, the president of ATO, said that in spite of the availability of Radiohead\\'s music online, many fans might still have reason to pay for the CD version.\\n\"You\\'ve still got hard-core Radiohead fans that are very inclined to own anything they can from the band,\" he said.\\nHe added that the critical praise and international headlines generated by the band\\'s release plan may have drawn new fans.\\n\"I think you\\'re going to find a new buyer that might be more curious, that might\\'ve gotten turned on by all the attention,\" he said.\\nStill, he acknowledged, \"it\\'s faith on our part.\"\\nHe continued: \"There\\'s nothing normal here.\\nThere are not normal business principles.\\n',\n",
       " 'non_split': 'Radiohead - Music - New York Times\\n\\nLOS ANGELES - \"In Rainbows,\" the latest album from the British rock band Radiohead, has been readily available to music fans for almost three months, first as a digital download in an unconventional tip-jar offering in which fans decided for themselves what to pay for it, and then, like most pop music today, as digital files circulating on free, unlicensed file-swapping networks. One matter remains: Will anyone buy the CD?\\n\\nStarting on Tuesday, the album, in plastic disc form, is on sale in record shops (this time with a list price, $13.98, that is not subject to consumer whims). Though hard-core fans almost surely have acquired the album, one way or another, Radiohead had plans to promote the CD release with a \"prerecording\" of the band performing songs from \"In Rainbows\" on the www.radiohead.tv Web site starting on Monday, according to the band\\'s Web site, radiohead.com. It is also to be shown on satellite and cable systems that carry the Current TV channel.\\n\\nThough hailed by critics, the album is seen as an uncertain prospect commercially. That is because the band has declined to say how many copies have been distributed since October, when it diverged from industry custom and offered a digital download of \"In Rainbows\" for however much fans chose to pay - even nothing. Since then the band\\'s representatives have described the offering as, among other things, a way of testing whether digital downloads eat into sales of CDs.\\n\\nRadiohead chose to release the CD through the independent label ATO Records and its imprint TBD. (The band\\'s 2003 album \"Hail to the Thief\" was the last one under its recording contract with the music giant EMI.) ATO is shipping an estimated 400,000 copies of the album to record shops, said executives briefed on the label\\'s plans. It is not uncommon for shops to sell half of the shipment of a big album in its first week on sale. But Radiohead\\'s performance may differ; not only has the album been widely available online, but it is also hitting record shops in the traditionally slow post-holiday sales period.\\n\\nAs a result, it is seen as a long shot that the band could match the performance of \"Hail to the Thief,\" which sold 300,000 copies in its first week after going on sale in June 2003, and went on to sell a total of roughly 1 million copies, according to Nielsen SoundScan data.\\n\\nWill Botwin, the president of ATO, said that in spite of the availability of Radiohead\\'s music online, many fans might still have reason to pay for the CD version. \"You\\'ve still got hard-core Radiohead fans that are very inclined to own anything they can from the band,\" he said.\\n\\nHe added that the critical praise and international headlines generated by the band\\'s release plan may have drawn new fans. \"I think you\\'re going to find a new buyer that might be more curious, that might\\'ve gotten turned on by all the attention,\" he said. Still, he acknowledged, \"it\\'s faith on our part.\"\\n\\nHe continued: \"There\\'s nothing normal here. There are not normal business principles.\"\\n',\n",
       " 'hash': '3d6943d8ea557c6b60bd9b88474c2f68751e72d7993ff577db667d5b9c8df510',\n",
       " 'embeddings': [0.3629947602748871,\n",
       "  -0.0638912171125412,\n",
       "  0.3573863208293915,\n",
       "  0.12228073924779892,\n",
       "  -0.5844597220420837,\n",
       "  0.11395348608493805,\n",
       "  0.08220219612121582,\n",
       "  -0.0018845918821170926,\n",
       "  -0.43075838685035706,\n",
       "  0.2107701599597931,\n",
       "  0.06572393327951431,\n",
       "  0.7968987822532654,\n",
       "  0.1964932233095169,\n",
       "  0.14510896801948547,\n",
       "  0.1857457458972931,\n",
       "  0.5309956073760986,\n",
       "  0.6711416840553284,\n",
       "  0.22299078106880188,\n",
       "  -0.30523809790611267,\n",
       "  -0.7502462267875671,\n",
       "  -0.28618505597114563,\n",
       "  -0.23377671837806702,\n",
       "  0.5438740253448486,\n",
       "  -0.3756115436553955,\n",
       "  0.1885242760181427,\n",
       "  -0.13339731097221375,\n",
       "  0.21847984194755554,\n",
       "  0.12101232260465622,\n",
       "  -0.4243864119052887,\n",
       "  -0.07625902444124222,\n",
       "  -0.3269634246826172,\n",
       "  0.6685795187950134,\n",
       "  0.2914530634880066,\n",
       "  -0.49622249603271484,\n",
       "  0.4567045271396637,\n",
       "  0.12304673343896866,\n",
       "  0.08675222843885422,\n",
       "  -0.39868175983428955,\n",
       "  -0.01946919970214367,\n",
       "  -0.3993796706199646,\n",
       "  0.1146252453327179,\n",
       "  -0.18394698202610016,\n",
       "  -0.13878074288368225,\n",
       "  0.8996525406837463,\n",
       "  -0.4577716886997223,\n",
       "  0.33290547132492065,\n",
       "  -1.0285980701446533,\n",
       "  0.2654765248298645,\n",
       "  -0.1846664547920227,\n",
       "  0.37007057666778564,\n",
       "  -0.04835652932524681,\n",
       "  0.20891240239143372,\n",
       "  0.002238582819700241,\n",
       "  0.06421603262424469,\n",
       "  0.11665365844964981,\n",
       "  -0.0717373639345169,\n",
       "  -0.6954896450042725,\n",
       "  0.5284547209739685,\n",
       "  -0.17336584627628326,\n",
       "  -0.3226677477359772,\n",
       "  0.19214949011802673,\n",
       "  -0.26684898138046265,\n",
       "  0.13452154397964478,\n",
       "  -0.2754329442977905,\n",
       "  0.11674129962921143,\n",
       "  -0.010347237810492516,\n",
       "  -0.0032957762014120817,\n",
       "  0.674481987953186,\n",
       "  -0.23839052021503448,\n",
       "  -0.5446048974990845,\n",
       "  0.5095158219337463,\n",
       "  -0.8507760763168335,\n",
       "  -0.3776508569717407,\n",
       "  -0.09712151437997818,\n",
       "  0.1783619076013565,\n",
       "  -0.020933298394083977,\n",
       "  -0.20045319199562073,\n",
       "  -0.2581273317337036,\n",
       "  0.5811092853546143,\n",
       "  0.2469857633113861,\n",
       "  -0.08088335394859314,\n",
       "  0.3883126974105835,\n",
       "  0.9069449305534363,\n",
       "  -0.14424900710582733,\n",
       "  0.4714597463607788,\n",
       "  -0.12392740696668625,\n",
       "  -0.32304704189300537,\n",
       "  0.8275341391563416,\n",
       "  -0.3343818187713623,\n",
       "  0.42733392119407654,\n",
       "  0.1273137778043747,\n",
       "  -0.8243367671966553,\n",
       "  1.0097980499267578,\n",
       "  0.26426756381988525,\n",
       "  0.24432893097400665,\n",
       "  0.03614824637770653,\n",
       "  -0.016377879306674004,\n",
       "  0.5460677146911621,\n",
       "  -0.02597850374877453,\n",
       "  -0.11494605988264084,\n",
       "  0.6562431454658508,\n",
       "  -0.2243817299604416,\n",
       "  0.2854960262775421,\n",
       "  -0.6046887040138245,\n",
       "  -0.4159070551395416,\n",
       "  -0.28922799229621887,\n",
       "  -0.13799218833446503,\n",
       "  -0.857073187828064,\n",
       "  0.374271959066391,\n",
       "  7.032211578916758e-05,\n",
       "  -0.36043694615364075,\n",
       "  0.5480843186378479,\n",
       "  -0.22939540445804596,\n",
       "  0.11980534344911575,\n",
       "  0.31352847814559937,\n",
       "  0.13007192313671112,\n",
       "  -0.021600909531116486,\n",
       "  -0.1676374077796936,\n",
       "  -0.08125889301300049,\n",
       "  0.4872983396053314,\n",
       "  0.3224412202835083,\n",
       "  0.47213083505630493,\n",
       "  0.10626009851694107,\n",
       "  0.2566053867340088,\n",
       "  0.041188694536685944,\n",
       "  -0.15123410522937775,\n",
       "  0.3335443437099457,\n",
       "  0.42706313729286194,\n",
       "  -0.37750229239463806,\n",
       "  0.1380462795495987,\n",
       "  -0.3114379942417145,\n",
       "  0.8273692727088928,\n",
       "  0.15251491963863373,\n",
       "  -0.6506369709968567,\n",
       "  -0.10312378406524658,\n",
       "  -0.18471574783325195,\n",
       "  0.060402415692806244,\n",
       "  0.20480649173259735,\n",
       "  0.11184588819742203,\n",
       "  0.15259207785129547,\n",
       "  -0.6180152893066406,\n",
       "  -0.24276527762413025,\n",
       "  -0.8867291212081909,\n",
       "  -0.23261596262454987,\n",
       "  0.404693067073822,\n",
       "  0.16940796375274658,\n",
       "  -0.44390004873275757,\n",
       "  -0.0269133560359478,\n",
       "  -0.4093987047672272,\n",
       "  0.047358762472867966,\n",
       "  0.2616482675075531,\n",
       "  -0.22624041140079498,\n",
       "  -0.5313957333564758,\n",
       "  -0.36936211585998535,\n",
       "  -0.35410767793655396,\n",
       "  0.21241748332977295,\n",
       "  0.19714680314064026,\n",
       "  0.20556634664535522,\n",
       "  0.13231590390205383,\n",
       "  -0.3809569478034973,\n",
       "  0.43624570965766907,\n",
       "  0.3551972806453705,\n",
       "  -0.07768885046243668,\n",
       "  0.32739877700805664,\n",
       "  -0.3844435214996338,\n",
       "  0.3283056616783142,\n",
       "  -0.6257449984550476,\n",
       "  0.4187358319759369,\n",
       "  -0.002942298771813512,\n",
       "  -0.6024910807609558,\n",
       "  -0.4232683777809143,\n",
       "  0.24641922116279602,\n",
       "  -0.034246958792209625,\n",
       "  0.12668852508068085,\n",
       "  0.3888010084629059,\n",
       "  0.24780036509037018,\n",
       "  0.9395408034324646,\n",
       "  0.4465896189212799,\n",
       "  0.016598433256149292,\n",
       "  0.030088653787970543,\n",
       "  -0.721950888633728,\n",
       "  -0.10609577596187592,\n",
       "  0.41208383440971375,\n",
       "  -0.6749894022941589,\n",
       "  0.09039558470249176,\n",
       "  0.2627086341381073,\n",
       "  -0.2156984806060791,\n",
       "  0.14393842220306396,\n",
       "  0.3038315176963806,\n",
       "  0.22351396083831787,\n",
       "  -0.2310388833284378,\n",
       "  -0.5794498920440674,\n",
       "  0.06775325536727905,\n",
       "  -0.8317885398864746,\n",
       "  0.6808307766914368,\n",
       "  -0.0892680287361145,\n",
       "  0.13298900425434113,\n",
       "  0.9480094909667969,\n",
       "  0.1445886790752411,\n",
       "  0.048869360238313675,\n",
       "  -0.08030762523412704,\n",
       "  0.5333219170570374,\n",
       "  0.42911994457244873,\n",
       "  -0.44891226291656494,\n",
       "  -0.9352610111236572,\n",
       "  -0.16631704568862915,\n",
       "  0.20948490500450134,\n",
       "  -0.20334574580192566,\n",
       "  -0.20022006332874298,\n",
       "  -0.05420611798763275,\n",
       "  0.3401854634284973,\n",
       "  -0.5974912643432617,\n",
       "  0.5454955697059631,\n",
       "  0.3671548366546631,\n",
       "  -0.3740789592266083,\n",
       "  0.2675160765647888,\n",
       "  -0.19612835347652435,\n",
       "  0.085261769592762,\n",
       "  0.5038260221481323,\n",
       "  -0.4842153489589691,\n",
       "  0.6090874075889587,\n",
       "  0.4298655390739441,\n",
       "  0.3550451397895813,\n",
       "  0.09548875689506531,\n",
       "  -0.3568473756313324,\n",
       "  0.6995992064476013,\n",
       "  -0.3513375520706177,\n",
       "  0.23025564849376678,\n",
       "  0.2773495316505432,\n",
       "  -0.571690559387207,\n",
       "  0.046796929091215134,\n",
       "  0.6719573736190796,\n",
       "  -0.21599702537059784,\n",
       "  -0.276222825050354,\n",
       "  0.19669972360134125,\n",
       "  0.6494938731193542,\n",
       "  -0.1660425364971161,\n",
       "  -0.6082289814949036,\n",
       "  -0.060666196048259735,\n",
       "  -0.04981095716357231,\n",
       "  0.33085060119628906,\n",
       "  -0.38493961095809937,\n",
       "  -0.050600215792655945,\n",
       "  0.8452556729316711,\n",
       "  0.13274633884429932,\n",
       "  0.06509996205568314,\n",
       "  -0.03673679009079933,\n",
       "  0.10007734596729279,\n",
       "  -0.2718654274940491,\n",
       "  -0.2446345090866089,\n",
       "  0.5168257355690002,\n",
       "  0.3505474328994751,\n",
       "  -0.1421748846769333,\n",
       "  -0.014743235893547535,\n",
       "  0.08724384754896164,\n",
       "  0.07346650958061218,\n",
       "  -0.002840206027030945,\n",
       "  0.022248249500989914,\n",
       "  0.43862947821617126,\n",
       "  0.31493285298347473,\n",
       "  -0.14542800188064575,\n",
       "  -0.27117791771888733,\n",
       "  -0.1788875013589859,\n",
       "  0.6754530072212219,\n",
       "  -0.574246346950531,\n",
       "  -0.21799246966838837,\n",
       "  -0.41928043961524963,\n",
       "  -0.23222346603870392,\n",
       "  0.556201159954071,\n",
       "  0.633804202079773,\n",
       "  -0.292153924703598,\n",
       "  0.4854767620563507,\n",
       "  -0.8763091564178467,\n",
       "  0.4897157549858093,\n",
       "  -0.222117617726326,\n",
       "  -0.22706183791160583,\n",
       "  -0.15672916173934937,\n",
       "  0.4635235071182251,\n",
       "  0.22400535643100739,\n",
       "  -0.851606547832489,\n",
       "  -0.2436976581811905,\n",
       "  0.597425103187561,\n",
       "  0.7528436779975891,\n",
       "  -0.30266064405441284,\n",
       "  -0.5159659385681152,\n",
       "  -0.17608381807804108,\n",
       "  0.44331568479537964,\n",
       "  -0.2753695249557495,\n",
       "  -0.2944132685661316,\n",
       "  -0.2524493932723999,\n",
       "  -0.09687668085098267,\n",
       "  0.27018603682518005,\n",
       "  0.2920996844768524,\n",
       "  0.3273620307445526,\n",
       "  0.5307793617248535,\n",
       "  0.1847296804189682,\n",
       "  0.21380965411663055,\n",
       "  0.13952776789665222,\n",
       "  0.1142910048365593,\n",
       "  -0.16628704965114594,\n",
       "  -0.1382194608449936,\n",
       "  -0.3117334246635437,\n",
       "  0.06497077643871307,\n",
       "  -0.3720899224281311,\n",
       "  0.26404058933258057,\n",
       "  -0.4394150972366333,\n",
       "  0.160523921251297,\n",
       "  -0.5006622672080994,\n",
       "  -5.882648944854736,\n",
       "  0.3150767683982849,\n",
       "  -0.3950474262237549,\n",
       "  -0.29409968852996826,\n",
       "  -0.1724780648946762,\n",
       "  -0.06245587766170502,\n",
       "  0.26376980543136597,\n",
       "  -0.6054058074951172,\n",
       "  -0.04091151803731918,\n",
       "  0.40168076753616333,\n",
       "  -0.4739212989807129,\n",
       "  0.40960776805877686,\n",
       "  -0.02864333987236023,\n",
       "  -0.04722391813993454,\n",
       "  0.3655634820461273,\n",
       "  0.1667182296514511,\n",
       "  0.2659189701080322,\n",
       "  0.6708884835243225,\n",
       "  -0.23142987489700317,\n",
       "  -0.22317413985729218,\n",
       "  -0.5883662700653076,\n",
       "  -0.005734264850616455,\n",
       "  0.46712255477905273,\n",
       "  0.6726568937301636,\n",
       "  -0.05629173666238785,\n",
       "  0.26712119579315186,\n",
       "  -0.33776530623435974,\n",
       "  0.16759519279003143,\n",
       "  0.041374240070581436,\n",
       "  -0.2116137593984604,\n",
       "  0.1739770621061325,\n",
       "  0.03924780711531639,\n",
       "  0.14737190306186676,\n",
       "  -0.22271060943603516,\n",
       "  -0.026103395968675613,\n",
       "  -0.03928064927458763,\n",
       "  0.1996033787727356,\n",
       "  0.16989567875862122,\n",
       "  -0.16676990687847137,\n",
       "  -0.45809686183929443,\n",
       "  0.36779046058654785,\n",
       "  0.485212117433548,\n",
       "  0.4038253128528595,\n",
       "  -0.5459553003311157,\n",
       "  0.4516009986400604,\n",
       "  -0.19406747817993164,\n",
       "  -0.4082055687904358,\n",
       "  -0.17478448152542114,\n",
       "  -0.23450535535812378,\n",
       "  1.128406286239624,\n",
       "  0.5066405534744263,\n",
       "  -0.6804271936416626,\n",
       "  0.19716358184814453,\n",
       "  -0.0007884664228186011,\n",
       "  -0.10925350338220596,\n",
       "  -0.3712959587574005,\n",
       "  -0.06058648228645325,\n",
       "  0.38695788383483887,\n",
       "  0.17560701072216034,\n",
       "  0.37863779067993164,\n",
       "  -0.37424683570861816,\n",
       "  -0.31274914741516113,\n",
       "  -0.30753299593925476,\n",
       "  -0.28004804253578186,\n",
       "  -0.3659151494503021,\n",
       "  0.3249933421611786,\n",
       "  -0.7322583794593811,\n",
       "  0.001486391294747591,\n",
       "  0.7053311467170715,\n",
       "  0.5197349190711975,\n",
       "  -0.11565525084733963,\n",
       "  -0.05762813985347748,\n",
       "  -0.0515279546380043,\n",
       "  -0.8370893597602844,\n",
       "  0.2975319027900696,\n",
       "  -0.437579482793808,\n",
       "  -0.38491472601890564,\n",
       "  0.8206534385681152,\n",
       "  -0.1598876565694809,\n",
       "  0.21949616074562073,\n",
       "  -0.08617283403873444,\n",
       "  -0.0982571467757225,\n",
       "  0.18142728507518768,\n",
       "  -0.28972840309143066,\n",
       "  0.16623933613300323,\n",
       "  -0.8709158301353455,\n",
       "  -0.3158513605594635,\n",
       "  -0.003429108764976263,\n",
       "  -0.11165644228458405,\n",
       "  0.2281160056591034,\n",
       "  0.3057038486003876,\n",
       "  -0.07175770401954651,\n",
       "  0.35829830169677734,\n",
       "  0.3609504997730255,\n",
       "  -0.08265340328216553,\n",
       "  0.2695862352848053,\n",
       "  0.6132590174674988,\n",
       "  0.4715166985988617,\n",
       "  0.3993743658065796,\n",
       "  -0.020242078229784966,\n",
       "  0.6809458136558533,\n",
       "  0.05068986862897873,\n",
       "  0.18840183317661285,\n",
       "  -1.0649572610855103,\n",
       "  -0.670604944229126,\n",
       "  -0.3754218816757202,\n",
       "  -0.749150812625885,\n",
       "  -0.12186837941408157,\n",
       "  0.7053831219673157,\n",
       "  -0.7463858723640442,\n",
       "  -0.2406698763370514,\n",
       "  -0.9243783354759216,\n",
       "  -0.31352925300598145,\n",
       "  -0.592129647731781,\n",
       "  0.4522872567176819,\n",
       "  -0.02985842153429985,\n",
       "  -0.2439538687467575,\n",
       "  0.04716825112700462,\n",
       "  0.11769752949476242,\n",
       "  -0.4285793602466583,\n",
       "  0.3683716654777527,\n",
       "  -0.12666399776935577,\n",
       "  -0.3477640748023987,\n",
       "  -0.3454659581184387,\n",
       "  -0.26759639382362366,\n",
       "  0.43669503927230835,\n",
       "  0.22287650406360626,\n",
       "  0.2574237883090973,\n",
       "  -0.1348140388727188,\n",
       "  0.2969170808792114,\n",
       "  0.19166690111160278,\n",
       "  -0.03611785173416138,\n",
       "  -0.38297948241233826,\n",
       "  -0.35116592049598694,\n",
       "  0.4103659987449646,\n",
       "  -0.2831173539161682,\n",
       "  -0.42767077684402466,\n",
       "  -0.1734291911125183,\n",
       "  0.19390195608139038,\n",
       "  -0.08608917146921158,\n",
       "  0.49751806259155273,\n",
       "  -0.14576773345470428,\n",
       "  -0.0583626814186573,\n",
       "  0.4798711836338043,\n",
       "  -0.083484947681427,\n",
       "  0.5565248131752014,\n",
       "  0.08431036025285721,\n",
       "  0.16218602657318115,\n",
       "  -0.5225690603256226,\n",
       "  0.1635880172252655,\n",
       "  -0.08813445270061493,\n",
       "  0.26135990023612976,\n",
       "  0.2748611569404602,\n",
       "  -0.12196134775876999,\n",
       "  0.07610268145799637,\n",
       "  0.5920581817626953,\n",
       "  0.13933855295181274,\n",
       "  -0.025510074570775032,\n",
       "  -0.14220286905765533,\n",
       "  -0.623542070388794,\n",
       "  -0.07733970135450363,\n",
       "  -0.41976645588874817,\n",
       "  -0.5282222628593445,\n",
       "  0.10122153908014297,\n",
       "  0.4535241723060608,\n",
       "  0.10717517137527466,\n",
       "  -0.45223528146743774,\n",
       "  -0.29148441553115845,\n",
       "  -0.11789000034332275,\n",
       "  0.20546093583106995,\n",
       "  -0.26780131459236145,\n",
       "  -0.09682425856590271,\n",
       "  -0.17345379292964935,\n",
       "  -0.27353981137275696,\n",
       "  0.720604419708252,\n",
       "  0.08504986017942429,\n",
       "  -0.08020976185798645,\n",
       "  0.0897441878914833,\n",
       "  0.7520706057548523,\n",
       "  -0.3902125358581543,\n",
       "  -0.027689168229699135,\n",
       "  -0.4833109974861145,\n",
       "  -0.2593265771865845,\n",
       "  -0.19663631916046143,\n",
       "  0.48089805245399475,\n",
       "  -0.8443688750267029,\n",
       "  -0.26461732387542725,\n",
       "  -0.12995561957359314,\n",
       "  -0.3550039231777191,\n",
       "  -0.2577074468135834,\n",
       "  0.30930063128471375,\n",
       "  0.5297936201095581,\n",
       "  0.2811984717845917,\n",
       "  -0.19735591113567352,\n",
       "  0.3408680260181427,\n",
       "  -0.8569322824478149,\n",
       "  -0.10785149037837982,\n",
       "  -0.05305786058306694,\n",
       "  -0.34756630659103394,\n",
       "  -0.602580726146698,\n",
       "  -0.045713890343904495,\n",
       "  0.0010301225120201707,\n",
       "  -0.32511693239212036,\n",
       "  0.08160820603370667,\n",
       "  0.26456257700920105,\n",
       "  -0.07430632412433624,\n",
       "  0.4661501348018646,\n",
       "  0.09697822481393814,\n",
       "  -0.7711983919143677,\n",
       "  -0.2040558010339737,\n",
       "  -0.39462530612945557,\n",
       "  -0.1391756683588028,\n",
       "  0.15833665430545807,\n",
       "  0.35968321561813354,\n",
       "  -0.2209528237581253,\n",
       "  0.13016849756240845,\n",
       "  -0.040304481983184814,\n",
       "  -0.7796052098274231,\n",
       "  -0.5910563468933105,\n",
       "  0.29752829670906067,\n",
       "  -0.15713195502758026,\n",
       "  0.1036917045712471,\n",
       "  -0.4715002775192261,\n",
       "  0.29951801896095276,\n",
       "  -0.5003657341003418,\n",
       "  0.3127595782279968,\n",
       "  0.6800474524497986,\n",
       "  -0.7967060208320618,\n",
       "  -0.4497320055961609,\n",
       "  -0.3127997815608978,\n",
       "  0.353519469499588,\n",
       "  0.1773129105567932,\n",
       "  -0.03465074300765991,\n",
       "  0.03622659295797348,\n",
       "  -0.06819596886634827,\n",
       "  0.27209562063217163,\n",
       "  -0.09605730324983597,\n",
       "  0.2653042674064636,\n",
       "  -0.28513163328170776,\n",
       "  0.38968876004219055,\n",
       "  0.3441733717918396,\n",
       "  0.19994691014289856,\n",
       "  -0.1524551659822464,\n",
       "  -0.6035477519035339,\n",
       "  -0.5408400297164917,\n",
       "  0.030656723305583,\n",
       "  0.15242354571819305,\n",
       "  0.1179354265332222,\n",
       "  -0.7868011593818665,\n",
       "  0.083612360060215,\n",
       "  -0.040518444031476974,\n",
       "  0.029927734285593033,\n",
       "  -0.06530922651290894,\n",
       "  -0.29275572299957275,\n",
       "  0.33377525210380554,\n",
       "  -0.5697002410888672,\n",
       "  -0.3729909360408783,\n",
       "  -0.5114207863807678,\n",
       "  -0.35164880752563477,\n",
       "  0.2651519775390625,\n",
       "  0.1621318757534027,\n",
       "  0.06016809493303299,\n",
       "  -0.16553406417369843,\n",
       "  -0.11503138393163681,\n",
       "  0.6785639524459839,\n",
       "  0.662790834903717,\n",
       "  -0.3658425509929657,\n",
       "  -1.1058083772659302,\n",
       "  -0.4308299720287323,\n",
       "  -0.3559176027774811,\n",
       "  -0.13182280957698822,\n",
       "  0.056070782244205475,\n",
       "  0.41862988471984863,\n",
       "  0.0681372806429863,\n",
       "  0.2494204193353653,\n",
       "  -0.08015938848257065,\n",
       "  0.030428582802414894,\n",
       "  -0.5002285242080688,\n",
       "  -0.3882500231266022,\n",
       "  -0.019085247069597244,\n",
       "  -0.033110782504081726,\n",
       "  -0.32249805331230164,\n",
       "  -0.33635571599006653,\n",
       "  0.07008568197488785,\n",
       "  0.14567701518535614,\n",
       "  -0.6607041954994202,\n",
       "  -0.31743887066841125,\n",
       "  0.10992761701345444,\n",
       "  0.5141311287879944,\n",
       "  0.07900667190551758,\n",
       "  0.17504465579986572,\n",
       "  0.23708610236644745,\n",
       "  0.17027786374092102,\n",
       "  0.056206610053777695,\n",
       "  0.43749988079071045,\n",
       "  0.3196287453174591,\n",
       "  0.7193570137023926,\n",
       "  -0.34693098068237305,\n",
       "  -0.040604256093502045,\n",
       "  0.08833092451095581,\n",
       "  -0.44803452491760254,\n",
       "  0.10662222653627396,\n",
       "  0.5106798410415649,\n",
       "  -0.46148762106895447,\n",
       "  0.504898726940155,\n",
       "  0.4063225984573364,\n",
       "  0.15800458192825317,\n",
       "  0.16609536111354828,\n",
       "  -0.6451624631881714,\n",
       "  0.22505106031894684,\n",
       "  0.8679395318031311,\n",
       "  -0.08824538439512253,\n",
       "  0.00539631862193346,\n",
       "  0.836204469203949,\n",
       "  -0.39513444900512695,\n",
       "  0.06585418432950974,\n",
       "  0.5810233354568481,\n",
       "  -0.30792036652565,\n",
       "  0.19153538346290588,\n",
       "  0.12929219007492065,\n",
       "  0.10909998416900635,\n",
       "  0.5692660212516785,\n",
       "  0.5445466041564941,\n",
       "  0.8838728666305542,\n",
       "  -0.39056286215782166,\n",
       "  -0.1173362284898758,\n",
       "  -0.09867875277996063,\n",
       "  0.08046741038560867,\n",
       "  0.392017126083374,\n",
       "  -0.21335048973560333,\n",
       "  0.6565588116645813,\n",
       "  0.7238698601722717,\n",
       "  -0.3775467872619629,\n",
       "  0.7473868727684021,\n",
       "  -0.3125423789024353,\n",
       "  -0.04722636565566063,\n",
       "  -0.38962748646736145,\n",
       "  -0.2399858683347702,\n",
       "  -0.729880690574646,\n",
       "  0.45234179496765137,\n",
       "  -0.028185749426484108,\n",
       "  -0.18703608214855194,\n",
       "  -0.31150129437446594,\n",
       "  0.12997984886169434,\n",
       "  0.07136229425668716,\n",
       "  0.5994930267333984,\n",
       "  0.03561186045408249,\n",
       "  -0.20744366943836212,\n",
       "  0.26344677805900574,\n",
       "  0.31935665011405945,\n",
       "  0.12873034179210663,\n",
       "  0.03128466382622719,\n",
       "  -0.20083944499492645,\n",
       "  -0.5535563230514526,\n",
       "  -0.27122873067855835,\n",
       "  -0.07432102411985397,\n",
       "  0.1708492636680603,\n",
       "  -0.2890799045562744,\n",
       "  -0.12446796894073486,\n",
       "  0.037850186228752136,\n",
       "  0.1923302263021469,\n",
       "  0.7793125510215759,\n",
       "  -0.7313520908355713,\n",
       "  0.30539900064468384,\n",
       "  0.17033743858337402,\n",
       "  -0.3780655562877655,\n",
       "  0.23162613809108734,\n",
       "  0.15000295639038086,\n",
       "  0.06368564069271088,\n",
       "  0.19049696624279022,\n",
       "  -0.29516929388046265,\n",
       "  0.0684550330042839,\n",
       "  -0.3539268970489502,\n",
       "  0.11996632069349289,\n",
       "  -0.5430553555488586,\n",
       "  -0.3062500059604645,\n",
       "  0.5552465319633484,\n",
       "  0.5785440802574158,\n",
       "  0.5701794624328613,\n",
       "  0.4595126807689667,\n",
       "  -0.4745117723941803,\n",
       "  0.28846490383148193,\n",
       "  -0.22918571531772614,\n",
       "  -0.17855042219161987,\n",
       "  0.10847552865743637,\n",
       "  -0.4261380136013031,\n",
       "  -0.03514539450407028,\n",
       "  0.17803068459033966,\n",
       "  -0.37390702962875366,\n",
       "  -0.25825536251068115,\n",
       "  0.025422055274248123,\n",
       "  -0.4997657537460327,\n",
       "  -0.6831518411636353,\n",
       "  0.33335602283477783,\n",
       "  -0.3479909598827362,\n",
       "  -0.9929839968681335,\n",
       "  0.09636572003364563,\n",
       "  0.6724090576171875,\n",
       "  0.04139450564980507,\n",
       "  0.13699857890605927,\n",
       "  -0.12853427231311798,\n",
       "  -0.1436784863471985,\n",
       "  -0.22302064299583435,\n",
       "  0.4297930896282196,\n",
       "  -0.06081702560186386,\n",
       "  1.0093432664871216,\n",
       "  -0.8078113198280334,\n",
       "  -0.4631909132003784,\n",
       "  -1.024032473564148,\n",
       "  0.36907893419265747,\n",
       "  0.3150014281272888,\n",
       "  0.7910348176956177,\n",
       "  -0.12040229886770248,\n",
       "  0.33834534883499146,\n",
       "  -0.208429217338562,\n",
       "  -0.42454686760902405,\n",
       "  0.35377413034439087,\n",
       "  -0.20832513272762299,\n",
       "  -0.0009209240670315921,\n",
       "  -0.17390675842761993,\n",
       "  0.09597066789865494,\n",
       "  0.06828338652849197,\n",
       "  0.3434377908706665,\n",
       "  0.654339075088501,\n",
       "  0.03226165473461151,\n",
       "  -0.3329550623893738,\n",
       "  0.2841196060180664,\n",
       "  0.1771123856306076,\n",
       "  -0.8709765076637268,\n",
       "  0.22511409223079681,\n",
       "  0.2480810433626175,\n",
       "  -0.046389270573854446,\n",
       "  -0.42607271671295166,\n",
       "  -0.19362056255340576,\n",
       "  -0.550951361656189,\n",
       "  0.20431308448314667,\n",
       "  -0.16470365226268768,\n",
       "  0.3032981753349304,\n",
       "  0.27925217151641846,\n",
       "  -0.1805877834558487,\n",
       "  -0.29602938890457153,\n",
       "  -0.134221613407135,\n",
       "  0.07631009817123413,\n",
       "  0.399730384349823,\n",
       "  -0.17364506423473358,\n",
       "  0.3783809244632721,\n",
       "  0.06689473241567612,\n",
       "  -0.1383810043334961,\n",
       "  -1.3005726337432861,\n",
       "  0.522148609161377,\n",
       "  0.12395081669092178,\n",
       "  -0.5086460113525391,\n",
       "  0.3116554319858551,\n",
       "  -0.17161189019680023,\n",
       "  -0.18070591986179352,\n",
       "  -0.08340167254209518,\n",
       "  0.20837055146694183,\n",
       "  0.30564042925834656,\n",
       "  -0.2492176592350006,\n",
       "  -0.5237057209014893]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ctx_encoder(**ctx_tokenizer(ds[\"train\"][0][\"non_split\"], return_tensors=\"pt\", padding=True, truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(example):\n",
    "    examples_tokenized = ctx_tokenizer(example[\"non_split\"],return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    examples_tokenized = examples_tokenized.to(device)\n",
    "    embeddings = ctx_encoder(**examples_tokenized)[\"pooler_output\"].detach().cpu().numpy()\n",
    "    # print(embeddings.size())\n",
    "    example[\"embeddings\"] = embeddings\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 494 ms, sys: 289 ms, total: 783 ms\n",
      "Wall time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = get_embedding(ds[\"train\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"embeddings\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2364fb36733941d3be9a853653f5ee44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-34019ecf6e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    788\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 )\n\u001b[0;32m--> 790\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m             }\n\u001b[1;32m    792\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    788\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 )\n\u001b[0;32m--> 790\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m             }\n\u001b[1;32m    792\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2403\u001b[0m                 \u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2404\u001b[0m                 \u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2405\u001b[0;31m                 \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2406\u001b[0m             )\n\u001b[1;32m   2407\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m         }\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2777\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m                                 \u001b[0mcheck_same_num_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2779\u001b[0;31m                                 \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2780\u001b[0m                             )\n\u001b[1;32m   2781\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mNumExamplesMismatchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   2653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2654\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2655\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2656\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;31m# Check if the function returns updated examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(item, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2345\u001b[0m                 )\n\u001b[1;32m   2346\u001b[0m                 \u001b[0;31m# Use the LazyDict internally, while mapping the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2347\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecorated_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m                 \u001b[0;31m# Return a standard dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-1374e2d6bff8>\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mexamples_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"non_split\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mexamples_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexamples_tokenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mexamples_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pooler_output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# print(embeddings.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embeddings\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds = ds.map(get_embedding, batched=True, batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7ab4c1e138f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/root/filtered_small_embeddings\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "ds.save_to_disk(\"/root/filtered_small_embeddings\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
