{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96faf178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md    build_index.ipynb  build_split_meta.py      \u001b[0m\u001b[01;34mmetadata\u001b[0m/\r\n",
      "api.py       build_index.py     config_IVF1024PQ48.json  \u001b[01;34mshards\u001b[0m/\r\n",
      "build_db.py  build_shard.py     \u001b[01;34mdb\u001b[0m/                      \u001b[01;34msplits\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e61f7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import ray\n",
    "import faiss \n",
    "import lmdb\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f66fbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 12:44:35,293\tWARNING utils.py:595 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.\n",
      "2022-11-26 12:44:35,294\tWARNING utils.py:607 -- Ray currently does not support initializing Raywith fractional cpus. Your num_cpus will be truncated from 46.08 to 46.\n",
      "2022-11-26 12:44:35,467\tINFO worker.py:1518 -- Started a local Ray instance.\n",
      "2022-11-26 12:44:36,998\tWARNING read_api.py:281 -- ⚠️  The blocks of this dataset are estimated to be 70.0x larger than the target block size of 512 MiB. This may lead to out-of-memory errors during processing. Consider reducing the size of input files or using `.repartition(n)` to increase the number of dataset blocks.\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=18175)\u001b[0m /opt/conda/envs/mengzi-retrieval-fit/lib/python3.7/site-packages/ray/data/datasource/parquet_datasource.py:220: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=18175)\u001b[0m   self._metadata = meta_provider.prefetch_file_metadata(pq_ds.pieces) or []\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=18175)\u001b[0m /opt/conda/envs/mengzi-retrieval-fit/lib/python3.7/site-packages/ray/data/datasource/parquet_datasource.py:247: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=18175)\u001b[0m   np.array_split(self._pq_ds.pieces, parallelism),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Data count: 2107181\n",
      "Building index...\n",
      "starting faiss\n",
      "Using FP16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rank = 0\n",
    "\n",
    "print('Loading data...')\n",
    "ds = ray.data.read_parquet(f'./shards/{rank}.parquet')\n",
    "print('Data loaded!')\n",
    "print('Data count:', ds.count())\n",
    "\n",
    "print('Building index...')\n",
    "res = faiss.StandardGpuResources()\n",
    "print(\"starting faiss\")\n",
    "res.setTempMemory(1024 * 1024 * 64)\n",
    "co = faiss.GpuClonerOptions()\n",
    "co.useFloat16 = True\n",
    "print(\"Using FP16\")\n",
    "cpu_index = faiss.index_factory(384, 'IVF1024,PQ64')\n",
    "index = faiss.index_cpu_to_gpu(res, 0, cpu_index, co)\n",
    "#index = faiss.IndexFlatL2(384)\n",
    "train_data = ds.take(1048576)\n",
    "xt = np.stack([x['embedding'] for x in train_data]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b687d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048576, 384)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e003d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded!\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "print('Training data loaded!')\n",
    "index.train(xt)\n",
    "print('Training finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35c4a652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "515it [02:02,  4.20it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index built!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error in faiss::FileIOWriter::FileIOWriter(const char*) at /home/conda/feedstock_root/build_artifacts/faiss-split_1644327822094/work/faiss/impl/io.cpp:97: Error: 'f' failed: could not open ./indexes_IVF1024PQ64/0 for writing: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17975/1702012742.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Index built!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_gpu_to_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'./indexes_IVF1024PQ64/{rank}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Index written!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/mengzi-retrieval-fit/lib/python3.7/site-packages/faiss/swigfaiss_avx2.py\u001b[0m in \u001b[0;36mwrite_index\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   9841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9842\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrite_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9843\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_swigfaiss_avx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9845\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrite_index_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error in faiss::FileIOWriter::FileIOWriter(const char*) at /home/conda/feedstock_root/build_artifacts/faiss-split_1644327822094/work/faiss/impl/io.cpp:97: Error: 'f' failed: could not open ./indexes_IVF1024PQ64/0 for writing: No such file or directory"
     ]
    }
   ],
   "source": [
    "\n",
    "bs = 4096\n",
    "for batch in tqdm(ds.iter_batches(batch_size=bs), total=ds.count()//bs):\n",
    "    xb = np.stack(batch.embedding.values).astype('float32')\n",
    "    index.add(xb)\n",
    "print('Index built!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01a50dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index written!\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "faiss.write_index(faiss.index_gpu_to_cpu(index), f'./indexes_IVF1024PQ64/{rank}')\n",
    "print('Index written!')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dac76323",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb1aa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of GPUs: 2\n",
      "100000\n",
      "[[ 381  207  210  477]\n",
      " [ 526  911  142   72]\n",
      " [ 838  527 1290  425]\n",
      " [ 196  184  164  359]\n",
      " [ 526  377  120  425]]\n",
      "[[ 9900 10500  9309  9831]\n",
      " [11055 10895 10812 11321]\n",
      " [11353 11103 10164  9787]\n",
      " [10571 10664 10632  9638]\n",
      " [ 9628  9554 10036  9582]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "d = 64                           # dimension\n",
    "nb = 100000                      # database size\n",
    "nq = 10000                       # nb of queries\n",
    "np.random.seed(1234)             # make reproducible\n",
    "xb = np.random.random((nb, d)).astype('float32')\n",
    "xb[:, 0] += np.arange(nb) / 1000.\n",
    "xq = np.random.random((nq, d)).astype('float32')\n",
    "xq[:, 0] += np.arange(nq) / 1000.\n",
    "\n",
    "import faiss                     # make faiss available\n",
    "\n",
    "ngpus = faiss.get_num_gpus()\n",
    "\n",
    "print(\"number of GPUs:\", ngpus)\n",
    "\n",
    "cpu_index = faiss.IndexFlatL2(d)\n",
    "\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(  # build the index\n",
    "    cpu_index\n",
    ")\n",
    "\n",
    "gpu_index.add(xb)              # add vectors to the index\n",
    "print(gpu_index.ntotal)\n",
    "\n",
    "k = 4                          # we want to see 4 nearest neighbors\n",
    "D, I = gpu_index.search(xq, k) # actual search\n",
    "print(I[:5])                   # neighbors of the 5 first queries\n",
    "print(I[-5:])                  # neighbors of the 5 last queries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac90d182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
