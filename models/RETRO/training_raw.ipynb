{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0fde9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from retro_pytorch import RETRO, RETRODataset\n",
    "import os\n",
    "from torch import optim, nn, utils, Tensor\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class RETRO_pl(pl.LightningModule):\n",
    "    def __init__(self, retro):\n",
    "        super().__init__()\n",
    "        self.model = retro\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        seq, retrieved = batch\n",
    "        loss = retro(\n",
    "            seq,\n",
    "            retrieved,\n",
    "            return_loss = True\n",
    "        )\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-5)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "665cfb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found to be previously processed at processed-stats.json\n",
      "preprocessed knn found at ../all_d/train.chunks.knn.dat, faiss index reconstituted from .tmp/.index/knn.index\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from retro_pytorch import RETRO, TrainingWrapper\n",
    "# instantiate RETRO, fit it into the TrainingWrapper with correct settings\n",
    "\n",
    "retro = RETRO(\n",
    "    max_seq_len = 512,                      # max sequence length\n",
    "    enc_dim = 896,                           # encoder model dimension\n",
    "    enc_depth = 3,                           # encoder depth\n",
    "    dec_dim = 768,                           # decoder model dimensions\n",
    "    dec_depth = 12,                          # decoder depth\n",
    "    dec_cross_attn_layers = (1, 3, 6, 9),    # decoder cross attention layers (with causal chunk cross attention)\n",
    "    heads = 8,                               # attention heads\n",
    "    dim_head = 64,                           # dimension per head\n",
    "    dec_attn_dropout = 0.25,                 # decoder attention dropout\n",
    "    dec_ff_dropout = 0.25                    # decoder feedforward dropout\n",
    ")\n",
    "\n",
    "wrapper = TrainingWrapper(\n",
    "    retro = retro,                                 # path to retro instance\n",
    "    knn = 2,                                       # knn (2 in paper was sufficient)\n",
    "    chunk_size = 64,                               # chunk size (64 in paper)\n",
    "    documents_path = '../text_files',              # path to folder of text\n",
    "    glob = '../**/*.txt',                             # text glob\n",
    "    chunks_memmap_path = '../all_d/train.chunks.dat',     # path to chunks\n",
    "    seqs_memmap_path = '../all_d/train.seq.dat',          # path to sequence data\n",
    "    doc_ids_memmap_path = '../all_d/train.doc_ids.dat',   # path to document ids per chunk (used for filtering neighbors belonging to same document)\n",
    "    max_chunks = 1_000_000,                        # maximum cap to chunks\n",
    "    max_seqs = 300_000,                            # maximum seqs\n",
    "    knn_extra_neighbors = 100,                     # num extra neighbors to fetch\n",
    "    max_index_memory_usage = '10G',\n",
    "    current_memory_available = '100G',\n",
    "    reprocess= True\n",
    ")\n",
    "\n",
    "# get the dataloader and optimizer (AdamW with all the correct settings)\n",
    "\n",
    "train_dl = wrapper.get_dataloader(batch_size = 2, shuffle = True)\n",
    "optim = wrapper.get_optimizer(lr = 3e-4, wd = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9acc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = RETRO_pl(wrapper.retro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9084d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = wrapper.get_dataloader(batch_size = 16, shuffle = True)\n",
    "# ds_torch = DataLoader(train_dl, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2324c4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7efd477bbb50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa0e3848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaisam1\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20221215_234813-ldevp8gc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/saisam1/retro-finetuning/runs/ldevp8gc\" target=\"_blank\">magic-wood-40</a></strong> to <a href=\"https://wandb.ai/saisam1/retro-finetuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"retro-finetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ede7906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=10,\n",
    "                     accelerator=\"gpu\",\n",
    "                     logger=wandb_logger,\n",
    "                     precision=16,\n",
    "                     default_root_dir=\"../run_no_mod\",\n",
    "                     accumulate_grad_batches=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6c7b48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RETRO_pl(\n",
       "  (model): RETRO(\n",
       "    (token_emb): Embedding(28996, 896)\n",
       "    (pos_emb): Embedding(512, 896)\n",
       "    (to_decoder_model_dim): Linear(in_features=896, out_features=768, bias=True)\n",
       "    (encoder): Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_q): Linear(in_features=896, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=896, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=896, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=896, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_q): Linear(in_features=896, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=896, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (2): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Linear(in_features=896, out_features=3584, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=3584, out_features=896, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_q): Linear(in_features=896, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=896, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=896, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=896, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_q): Linear(in_features=896, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=896, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (2): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Linear(in_features=896, out_features=3584, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=3584, out_features=896, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_q): Linear(in_features=896, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=896, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=896, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=896, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_q): Linear(in_features=896, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=896, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (2): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Linear(in_features=896, out_features=3584, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=3584, out_features=896, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rotary_pos_emb): RotaryEmbedding()\n",
       "      (norm_out): RMSNorm()\n",
       "      (project_out): Linear(in_features=896, out_features=768, bias=True)\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): PreNorm(\n",
       "            (fn): ChunkedCrossAttention(\n",
       "              (cross_attn): Attention(\n",
       "                (dropout): Dropout(p=0.25, inplace=False)\n",
       "                (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "                (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (2): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): Dropout(p=0.25, inplace=False)\n",
       "                (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): None\n",
       "          (2): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): Dropout(p=0.25, inplace=False)\n",
       "                (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): PreNorm(\n",
       "            (fn): ChunkedCrossAttention(\n",
       "              (cross_attn): Attention(\n",
       "                (dropout): Dropout(p=0.25, inplace=False)\n",
       "                (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "                (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (2): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): Dropout(p=0.25, inplace=False)\n",
       "                (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): None\n",
       "          (2): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): Dropout(p=0.25, inplace=False)\n",
       "                (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (4): ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): None\n",
       "          (2): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): Dropout(p=0.25, inplace=False)\n",
       "                (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (5): ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): PreNorm(\n",
       "            (fn): ChunkedCrossAttention(\n",
       "              (cross_attn): Attention(\n",
       "                (dropout): Dropout(p=0.25, inplace=False)\n",
       "                (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "                (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (2): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): Dropout(p=0.25, inplace=False)\n",
       "                (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (6): ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): None\n",
       "          (2): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): Dropout(p=0.25, inplace=False)\n",
       "                (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (7): ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): None\n",
       "          (2): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): Dropout(p=0.25, inplace=False)\n",
       "                (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (8): ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): PreNorm(\n",
       "            (fn): ChunkedCrossAttention(\n",
       "              (cross_attn): Attention(\n",
       "                (dropout): Dropout(p=0.25, inplace=False)\n",
       "                (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "                (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (2): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): Dropout(p=0.25, inplace=False)\n",
       "                (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (9): ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): None\n",
       "          (2): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): Dropout(p=0.25, inplace=False)\n",
       "                (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (10): ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): None\n",
       "          (2): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): Dropout(p=0.25, inplace=False)\n",
       "                (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (11): ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): None\n",
       "          (2): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): Dropout(p=0.25, inplace=False)\n",
       "                (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rotary_pos_emb): RotaryEmbedding()\n",
       "      (norm_out): RMSNorm()\n",
       "    )\n",
       "    (to_logits): Linear(in_features=768, out_features=28996, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9abbedc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_PATH = \"/workspace/RETRO/retro-finetuning/pwiqzvvr/checkpoints/epoch=4-step=4135.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad787acd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Restoring states from the checkpoint path at /workspace/RETRO/retro-finetuning/pwiqzvvr/checkpoints/epoch=4-step=4135.ckpt\n",
      "/opt/conda/envs/py38/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:346: UserWarning: The dirpath has changed from './retro-finetuning/pwiqzvvr/checkpoints' to './retro-finetuning/ldevp8gc/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "  warnings.warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/opt/conda/envs/py38/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:346: UserWarning: The dirpath has changed from './retro-finetuning/pwiqzvvr/checkpoints' to './retro-finetuning/ldevp8gc/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "  warnings.warn(\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type  | Params\n",
      "--------------------------------\n",
      "0 | model | RETRO | 161 M \n",
      "--------------------------------\n",
      "161 M     Trainable params\n",
      "0         Non-trainable params\n",
      "161 M     Total params\n",
      "323.801   Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint file at /workspace/RETRO/retro-finetuning/pwiqzvvr/checkpoints/epoch=4-step=4135.ckpt\n",
      "/opt/conda/envs/py38/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:217: UserWarning: strategy=ddp_spawn and num_workers=0 may result in data loading bottlenecks. Consider setting num_workers>0 and persistent_workers=True\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:   0%|          | 6/5783 [00:03<1:00:07,  1.60it/s, loss=5.74, v_num=p8gc]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5783/5783 [49:30<00:00,  1.95it/s, loss=5.35, v_num=p8gc]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5783/5783 [49:32<00:00,  1.95it/s, loss=5.35, v_num=p8gc]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.fit(model=model, train_dataloaders=train_dl,ckpt_path=CKPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "604d5495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved at 64 / 512\n",
      "retrieved at 128 / 512\n",
      "retrieved at 192 / 512\n",
      "In Rainbows, the latest album from the British rock band and American - Ts. Reporting until million on it. For personalves's'politicians he had always gczher's's healthding of She showing as he was moving for holiday had a claim in Iran with a good and dressed. The last reports who are named Brad contracts in outside five years, 6, Vicurita - year - old who really their players of £10Vulse ; a statement. Thereh is the coach Court used while directed first's oil Aification \" The field \" for the players loan, \" and trulyist said. Theyly make it Mike a two health hat. It will go down the Senior by ] State treatments and St announcing a sustainable as a The DaCmp. Melania a halt ji Updated : 44z Dan a title, the main Department could be in the couple's trying to diaper in the Glasgow's NiL to take after being held down club. J. 75 million War. Any software in the U. St.. June 2017 [SEP]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# encode prompt\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "prompt_str = \"In Rainbows,the latest album from the British rock band \"\n",
    "\n",
    "prompt_ids = tokenizer(prompt_str)['input_ids'][1:-1]\n",
    "\n",
    "prompt = torch.tensor([prompt_ids])\n",
    "\n",
    "sampled = wrapper.generate(prompt, filter_thres = 0.9, temperature = 1.0)\n",
    "\n",
    "# decode sample\n",
    "decoded = tokenizer.decode(sampled.tolist()[0])\n",
    "\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c021c179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416a82a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retro_pytorch import RETRO, TrainingWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb37324e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found to be previously processed at processed-stats.json\n",
      "preprocessed knn found at ../all_d/train.chunks.knn.dat, faiss index reconstituted from .tmp/.index/knn.index\n"
     ]
    }
   ],
   "source": [
    "wrapper = TrainingWrapper(\n",
    "    retro = wrapper.retro,                                 # path to retro instance\n",
    "    knn = 2,                                       # knn (2 in paper was sufficient)\n",
    "    chunk_size = 64,                               # chunk size (64 in paper)\n",
    "    documents_path = '../text_files',              # path to folder of text\n",
    "    glob = '../**/*.txt',                             # text glob\n",
    "    chunks_memmap_path = '../all_d/train.chunks.dat',     # path to chunks\n",
    "    seqs_memmap_path = '../all_d/train.seq.dat',          # path to sequence data\n",
    "    doc_ids_memmap_path = '../all_d/train.doc_ids.dat',   # path to document ids per chunk (used for filtering neighbors belonging to same document)\n",
    "    max_chunks = 1_000_000,                        # maximum cap to chunks\n",
    "    max_seqs = 300_000,                            # maximum seqs\n",
    "    knn_extra_neighbors = 100,                     # num extra neighbors to fetch\n",
    "    max_index_memory_usage = '10G',\n",
    "    current_memory_available = '100G',\n",
    "    reprocess= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7384121",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate() got an unexpected keyword argument 'seq_len_max'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m prompt_ids \u001b[38;5;241m=\u001b[39m tokenizer(prompt_str)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     10\u001b[0m prompt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([prompt_ids])\n\u001b[0;32m---> 12\u001b[0m sampled \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_thres\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# decode sample\u001b[39;00m\n\u001b[1;32m     15\u001b[0m decoded \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(sampled\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/envs/py38/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/RETRO/retro_pytorch/training.py:28\u001b[0m, in \u001b[0;36meval_decorator.<locals>.inner\u001b[0;34m(model, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m was_training \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 28\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(was_training)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mTypeError\u001b[0m: generate() got an unexpected keyword argument 'seq_len_max'"
     ]
    }
   ],
   "source": [
    "\n",
    "# encode prompt\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "prompt_str = \"In Rainbows,the latest album from the British rock band \"\n",
    "\n",
    "prompt_ids = tokenizer(prompt_str)['input_ids'][1:-1]\n",
    "\n",
    "prompt = torch.tensor([prompt_ids])\n",
    "\n",
    "sampled = wrapper.generate(prompt, filter_thres = 0.9, temperature = 1.0, seq_len_max=30)\n",
    "\n",
    "# decode sample\n",
    "decoded = tokenizer.decode(sampled.tolist()[0])\n",
    "\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d0adbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
