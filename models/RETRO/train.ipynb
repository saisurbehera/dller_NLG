{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "train.chunks.dat  train.chunks.knn.dat  train.doc_ids.dat  train.seq.dat\r\n"
     ]
    }
   ],
   "source": [
    "ls ../all_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from retro_pytorch import RETRO, RETRODataset\n",
    "\n",
    "# mock data constants\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "NUM_CHUNKS = 1000\n",
    "CHUNK_SIZE = 64\n",
    "NUM_SEQS = 100\n",
    "NUM_NEIGHBORS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = RETRODataset(\n",
    "    num_sequences = NUM_SEQS,\n",
    "    num_chunks = NUM_CHUNKS,\n",
    "    num_neighbors = NUM_NEIGHBORS,\n",
    "    chunk_size = CHUNK_SIZE,\n",
    "    seq_len = 512,\n",
    "    chunk_memmap_path = '/workspace/all_d/train.chunks.dat',\n",
    "    chunk_nn_memmap_path = '/workspace/all_d/train.chunks.knn.dat',\n",
    "    seq_memmap_path = '/workspace/all_d/train.seq.dat'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = iter(DataLoader(train_ds, batch_size = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retro = RETRO(\n",
    "    max_seq_len = 512,                      # max sequence length\n",
    "    enc_dim = 768,                           # encoder model dimension\n",
    "    enc_depth = 3,                           # encoder depth\n",
    "    dec_dim = 768,                           # decoder model dimensions\n",
    "    dec_depth = 12,                          # decoder depth\n",
    "    dec_cross_attn_layers = ( 6, 9),    # decoder cross attention layers (with causal chunk cross attention)\n",
    "    heads = 8,                               # attention heads\n",
    "    dim_head = 64,                           # dimension per head\n",
    "    dec_attn_dropout = 0.25,                 # decoder attention dropout\n",
    "    dec_ff_dropout = 0.25                    # decoder feedforward dropout\n",
    ")\n",
    "\n",
    "seq, retrieved = map(lambda t: t.cuda(), next(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 513]), torch.Size([2, 8, 2, 128]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.shape, retrieved.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss = retro(\n",
    "    seq,\n",
    "    retrieved,\n",
    "    return_loss = True\n",
    ")\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.4309, device='cuda:0', grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found to be previously processed at processed-stats.json\n",
      "preprocessed knn found at /workspace/all_d/train.chunks.knn.dat, faiss index reconstituted from .tmp/.index/knn.index\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from retro_pytorch import RETRO, TrainingWrapper\n",
    "\n",
    "# instantiate RETRO, fit it into the TrainingWrapper with correct settings\n",
    "\n",
    "retro = RETRO(\n",
    "    max_seq_len = 512,                      # max sequence length\n",
    "    enc_dim = 896,                           # encoder model dimension\n",
    "    enc_depth = 3,                           # encoder depth\n",
    "    dec_dim = 768,                           # decoder model dimensions\n",
    "    dec_depth = 12,                          # decoder depth\n",
    "    dec_cross_attn_layers = (1, 3, 6, 9),    # decoder cross attention layers (with causal chunk cross attention)\n",
    "    heads = 8,                               # attention heads\n",
    "    dim_head = 64,                           # dimension per head\n",
    "    dec_attn_dropout = 0.25,                 # decoder attention dropout\n",
    "    dec_ff_dropout = 0.25                    # decoder feedforward dropout\n",
    ").cuda()\n",
    "\n",
    "wrapper = TrainingWrapper(\n",
    "    retro = retro,                                 # path to retro instance\n",
    "    knn = 2,                                       # knn (2 in paper was sufficient)\n",
    "    chunk_size = 64,                               # chunk size (64 in paper)\n",
    "    documents_path = '/workspace/text_files',              # path to folder of text\n",
    "    glob = '/workspace/**/*.txt',                             # text glob\n",
    "    chunks_memmap_path = '/workspace/all_d/train.chunks.dat',     # path to chunks\n",
    "    seqs_memmap_path = '/workspace/train.seq.dat',          # path to sequence data\n",
    "    doc_ids_memmap_path = '/workspace/train.doc_ids.dat',   # path to document ids per chunk (used for filtering neighbors belonging to same document)\n",
    "    max_chunks = 1_000_000,                        # maximum cap to chunks\n",
    "    max_seqs = 100_000,                            # maximum seqs\n",
    "    knn_extra_neighbors = 100,                     # num extra neighbors to fetch\n",
    "    max_index_memory_usage = '100m',\n",
    "    current_memory_available = '1G',\n",
    "    reprocess= True\n",
    ")\n",
    "\n",
    "# get the dataloader and optimizer (AdamW with all the correct settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dl = iter(wrapper.get_dataloader(batch_size = 2, shuffle = True))\n",
    "optim = wrapper.get_optimizer(lr = 3e-4, wd = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RETRO(\n",
       "  (token_emb): Embedding(28996, 896)\n",
       "  (pos_emb): Embedding(512, 896)\n",
       "  (to_decoder_model_dim): Linear(in_features=896, out_features=768, bias=True)\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (to_q): Linear(in_features=896, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=896, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=896, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=896, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (to_q): Linear(in_features=896, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=896, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (fn): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=896, out_features=3584, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=3584, out_features=896, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (to_q): Linear(in_features=896, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=896, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=896, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=896, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (to_q): Linear(in_features=896, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=896, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (fn): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=896, out_features=3584, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=3584, out_features=896, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (to_q): Linear(in_features=896, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=896, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=896, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=896, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (to_q): Linear(in_features=896, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=896, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (fn): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=896, out_features=3584, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=3584, out_features=896, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rotary_pos_emb): RotaryEmbedding()\n",
       "    (norm_out): RMSNorm()\n",
       "    (project_out): Linear(in_features=896, out_features=768, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "            (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (fn): ChunkedCrossAttention(\n",
       "            (cross_attn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (fn): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.25, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "            (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): None\n",
       "        (2): PreNorm(\n",
       "          (fn): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.25, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "            (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (fn): ChunkedCrossAttention(\n",
       "            (cross_attn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (fn): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.25, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "            (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): None\n",
       "        (2): PreNorm(\n",
       "          (fn): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.25, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "            (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): None\n",
       "        (2): PreNorm(\n",
       "          (fn): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.25, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (5): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "            (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (fn): ChunkedCrossAttention(\n",
       "            (cross_attn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (fn): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.25, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (6): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "            (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): None\n",
       "        (2): PreNorm(\n",
       "          (fn): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.25, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (7): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "            (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): None\n",
       "        (2): PreNorm(\n",
       "          (fn): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.25, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (8): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "            (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (fn): ChunkedCrossAttention(\n",
       "            (cross_attn): Attention(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (fn): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.25, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (9): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "            (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): None\n",
       "        (2): PreNorm(\n",
       "          (fn): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.25, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (10): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "            (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): None\n",
       "        (2): PreNorm(\n",
       "          (fn): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.25, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (11): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "            (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): None\n",
       "        (2): PreNorm(\n",
       "          (fn): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.25, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rotary_pos_emb): RotaryEmbedding()\n",
       "    (norm_out): RMSNorm()\n",
       "  )\n",
       "  (to_logits): Linear(in_features=768, out_features=28996, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.retro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import optim, nn, utils, Tensor\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from retro_pytorch import RETRO, RETRODataset\n",
    "\n",
    "class RETRO_pl(pl.LightningModule):\n",
    "    def __init__(self, retro):\n",
    "        super().__init__()\n",
    "        self.model = retro\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        seq, retrieved = batch\n",
    "        loss = retro(\n",
    "            seq,\n",
    "            retrieved,\n",
    "            return_loss = True\n",
    "        )\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-5)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "# init the autoencoder\n",
    "model = RETRO_pl(retro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from retro_pytorch import RETRO, RETRODataset\n",
    "\n",
    "# mock data constants\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "NUM_CHUNKS = 1000\n",
    "CHUNK_SIZE = 64\n",
    "NUM_SEQS = 100\n",
    "NUM_NEIGHBORS = 2\n",
    "\n",
    "train_ds = RETRODataset(\n",
    "    num_sequences = NUM_SEQS,\n",
    "    num_chunks = NUM_CHUNKS,\n",
    "    num_neighbors = NUM_NEIGHBORS,\n",
    "    chunk_size = CHUNK_SIZE,\n",
    "    seq_len = 512,\n",
    "    chunk_memmap_path = '/workspace/all_d/train.chunks.dat',\n",
    "    chunk_nn_memmap_path = '/workspace/all_d/train.chunks.knn.dat',\n",
    "    seq_memmap_path = '/workspace/all_d/train.seq.dat'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_torch = DataLoader(train_ds, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type  | Params\n",
      "--------------------------------\n",
      "0 | model | RETRO | 147 M \n",
      "--------------------------------\n",
      "147 M     Trainable params\n",
      "0         Non-trainable params\n",
      "147 M     Total params\n",
      "591.561   Total estimated model params size (MB)\n",
      "/opt/conda/envs/py38/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:217: UserWarning: strategy=ddp_spawn and num_workers=0 may result in data loading bottlenecks. Consider setting num_workers>0 and persistent_workers=True\n",
      "  rank_zero_warn(\n",
      "/opt/conda/envs/py38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1595: PossibleUserWarning: The number of training batches (25) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/25 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 25/25 [00:05<00:00,  4.35it/s, loss=6.39, v_num=2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 25/25 [00:08<00:00,  3.12it/s, loss=6.39, v_num=2]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=20,accelerator=\"gpu\")\n",
    "trainer.fit(model=model, train_dataloaders=ds_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode prompt\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "prompt_str = \"With a 102-96 victory Friday night against Charlotte at the Izod Center, they put the finishing touch on their first four-game winning streak and climbed back to\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_ids = tokenizer(prompt_str)['input_ids'][1:-1]\n",
    "\n",
    "prompt = torch.tensor([prompt_ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def top_k(logits, thres = 0.9):\n",
    "    num_logits = logits.shape[-1]\n",
    "    k = max(int((1 - thres) * num_logits), 1)\n",
    "    val, ind = torch.topk(logits, k)\n",
    "    probs = torch.full_like(logits, float('-inf'))\n",
    "    probs.scatter_(1, ind, val)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = prompt\n",
    "retrieved = None\n",
    "filter_fn = top_k\n",
    "filter_thres = 0.9\n",
    "temperature = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert filter_fn in {top_k}, 'filter function must be either top-k or nucleus'\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "if not exists(start):\n",
    "    start = torch.full((1, 1), SOS_ID, device = device).long()\n",
    "    \n",
    "b, start_seq_len = start.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = start.to(device)\n",
    "\n",
    "if start_seq_len >= CHUNK_SIZE:\n",
    "            seq_index = (start_seq_len // CHUNK_SIZE) * CHUNK_SIZE\n",
    "            past_seq_chunks = rearrange(start[:, :seq_index], 'b (n c) -> (b n) c', c = CHUNK_SIZE)\n",
    "\n",
    "            retrieved = fetch_knn_chunks_fn(past_seq_chunks)\n",
    "            retrieved = rearrange(retrieved, '(b n) k c -> b n k c', b = b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.cuda()\n",
    "# retrieved = retrieved.to(device)\n",
    "out = out.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(t, eps = 1e-20):\n",
    "    return torch.log(t.clamp(min = eps))\n",
    "from einops import rearrange\n",
    "def gumbel_noise(t):\n",
    "    noise = torch.zeros_like(t).uniform_(0, 1)\n",
    "    return -log(-log(noise))\n",
    "def gumbel_sample(t, temperature = 1., dim = -1):\n",
    "    return ((t / temperature) + gumbel_noise(t)).argmax(dim = dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from retro_pytorch import RETRO, RETRODataset\n",
    "from retro_pytorch.data import knn_to_retrieved_chunks\n",
    "from retro_pytorch.optimizer import get_optimizer\n",
    "from retro_pytorch.retrieval import text_folder_to_chunks_, chunks_to_precalculated_knn_, bert_embed, SOS_ID, EOS_ID\n",
    "from retro_pytorch.utils import memmap, is_true_env_flag\n",
    "\n",
    "from einops import rearrange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_main\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'search'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(curr_seq_len)\n\u001b[1;32m     33\u001b[0m last_chunk \u001b[38;5;241m=\u001b[39m rearrange(out, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb (c n) -> b c n\u001b[39m\u001b[38;5;124m'\u001b[39m, n \u001b[38;5;241m=\u001b[39m CHUNK_SIZE)[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 35\u001b[0m knn_chunks \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_knn_chunks_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_chunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# concat retrieved knn chunks to all retrieved\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# to be sent to Retro for chunked cross attention at the next iteration\u001b[39;00m\n\u001b[1;32m     40\u001b[0m knn_chunks \u001b[38;5;241m=\u001b[39m rearrange(knn_chunks, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb k r -> b 1 k r\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/workspace/RETRO/retro_pytorch/training.py:102\u001b[0m, in \u001b[0;36mknn_chunks_from_seq_chunks\u001b[0;34m(seq_chunks, knn, faiss_index, num_chunks, chunk_size, chunks_memmap_path)\u001b[0m\n\u001b[1;32m     98\u001b[0m embeds \u001b[38;5;241m=\u001b[39m bert_embed(seq_chunks\u001b[38;5;241m.\u001b[39mcpu()) \u001b[38;5;66;03m# fetch embeds on CPU for now\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# retrieval of knn with faiss\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m _, knn_indices \u001b[38;5;241m=\u001b[39m \u001b[43mfaiss_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m(embeds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), k \u001b[38;5;241m=\u001b[39m knn)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# numpy to torch\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m memmap(chunks_memmap_path, dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint32, shape \u001b[38;5;241m=\u001b[39m (num_chunks \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, chunk_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m chunk_memmap:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'search'"
     ]
    }
   ],
   "source": [
    "max_seq_len =512\n",
    "for i in range(start_seq_len - 1, max_seq_len):\n",
    "\n",
    "            logits =model.model( out, retrieved)\n",
    "            logits = logits[:, i]\n",
    "\n",
    "            logits = filter_fn(logits, thres = filter_thres)\n",
    "            sampled = gumbel_sample(logits, temperature = temperature, dim = -1)\n",
    "            sampled = rearrange(sampled, 'b -> b 1')\n",
    "\n",
    "            out = torch.cat((out, sampled), dim = 1)\n",
    "\n",
    "            # early terminate if all EOS\n",
    "\n",
    "            is_eos_tokens = (out == EOS_ID)\n",
    "\n",
    "            if is_eos_tokens.any(dim = -1).all():\n",
    "\n",
    "                # mask out everything after the eos tokens\n",
    "\n",
    "                shifted_is_eos_tokens = F.pad(is_eos_tokens, (1, -1))\n",
    "                mask = shifted_is_eos_tokens.float().cumsum(dim = -1) >= 1\n",
    "                out = out.masked_fill(mask, model.model.pad_id)\n",
    "                break\n",
    "\n",
    "            # when the sequence length is a multiple of the chunk size\n",
    "            # retrieve the next set of knns\n",
    "\n",
    "            curr_seq_len = out.shape[-1]\n",
    "            print(curr_seq_len)\n",
    "            if (curr_seq_len % CHUNK_SIZE) == 0:\n",
    "                print(curr_seq_len)\n",
    "                last_chunk = rearrange(out, 'b (c n) -> b c n', n = CHUNK_SIZE)[:, -1]\n",
    "\n",
    "                knn_chunks = fetch_knn_chunks_fn(last_chunk)\n",
    "\n",
    "                # concat retrieved knn chunks to all retrieved\n",
    "                # to be sent to Retro for chunked cross attention at the next iteration\n",
    "\n",
    "                knn_chunks = rearrange(knn_chunks, 'b k r -> b 1 k r')\n",
    "                retrieved = safe_cat(retrieved, knn_chunks, dim = 1)\n",
    "\n",
    "                print(f'retrieved at {curr_seq_len} / {max_seq_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed knn found at /workspace/all_d/train.chunks.knn.dat, faiss index reconstituted from /workspace/all_d/train.chunks.knn.dat\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error in faiss::Index* faiss::read_index(faiss::IOReader*, int) at /project/faiss/faiss/impl/index_read.cpp:796: Index type 0x0000000b (\"\\x0b\\x00\\x00\\x00\") not recognized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m knn_memmap_path, faiss_index \u001b[38;5;241m=\u001b[39m \u001b[43mchunks_to_precalculated_knn_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_chunks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_memmap_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/workspace/all_d/train.chunks.dat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunks_memmap_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/workspace/all_d/train.chunks.dat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# path to chunks\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseqs_memmap_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/workspace/train.seq.dat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# path to sequence data\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdoc_ids_memmap_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/workspace/train.doc_ids.dat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_nearest_neighbors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_extra_neighbors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/workspace/all_d/train.chunks.knn.dat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_reprocess\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/RETRO/retro_pytorch/retrieval.py:374\u001b[0m, in \u001b[0;36mchunks_to_precalculated_knn_\u001b[0;34m(num_nearest_neighbors, num_chunks, chunk_size, chunk_memmap_path, doc_ids_memmap_path, use_cls_repr, max_rows_per_file, chunks_to_embeddings_batch_size, embed_dim, num_extra_neighbors, force_reprocess, index_file, **index_kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_path\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;129;01mand\u001b[39;00m knn_path\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force_reprocess:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessed knn found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(knn_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, faiss index reconstituted from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(index_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 374\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mfaiss_read_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m knn_path, index\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# fetch the faiss index and calculated embeddings for the chunks\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/RETRO/retro_pytorch/retrieval.py:44\u001b[0m, in \u001b[0;36mfaiss_read_index\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfaiss_read_index\u001b[39m(path):\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIO_FLAG_MMAP\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIO_FLAG_READ_ONLY\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py38/lib/python3.8/site-packages/faiss/swigfaiss.py:9849\u001b[0m, in \u001b[0;36mread_index\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   9848\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_index\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 9849\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_swigfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error in faiss::Index* faiss::read_index(faiss::IOReader*, int) at /project/faiss/faiss/impl/index_read.cpp:796: Index type 0x0000000b (\"\\x0b\\x00\\x00\\x00\") not recognized"
     ]
    }
   ],
   "source": [
    "knn_memmap_path, faiss_index = chunks_to_precalculated_knn_(\n",
    "            num_chunks = 1000,\n",
    "            chunk_size = 64,\n",
    "        chunk_memmap_path = '/workspace/all_d/train.chunks.dat',\n",
    "            chunks_memmap_path = '/workspace/all_d/train.chunks.dat',    # path to chunks\n",
    "            seqs_memmap_path = '/workspace/train.seq.dat',          # path to sequence data\n",
    "            doc_ids_memmap_path = '/workspace/train.doc_ids.dat', \n",
    "            num_nearest_neighbors = 2,\n",
    "            num_extra_neighbors = 100,\n",
    "            index_file = \"/workspace/all_d/train.chunks.knn.dat\",\n",
    "            force_reprocess = False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retro_pytorch.data import knn_to_retrieved_chunks\n",
    "from functools import partial\n",
    "from retro_pytorch.training import knn_chunks_from_seq_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_knn_chunks_fn = partial(\n",
    "            knn_chunks_from_seq_chunks,\n",
    "            knn = 2,\n",
    "            chunk_size = 64,\n",
    "            num_chunks = NUM_CHUNKS,\n",
    "            chunks_memmap_path = '/workspace/all_d/train.chunks.dat',\n",
    "            faiss_index = \"/workspace/all_d/train.chunks.knn.dat\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, start_seq_len = start.shape\n",
    "\n",
    "        # move onto same device as RETRO\n",
    "\n",
    "        start = start.to(device)\n",
    "\n",
    "        # prepare retrieval related variables\n",
    "\n",
    "        if start_seq_len >= CHUNK_SIZE:\n",
    "            seq_index = (start_seq_len // self.chunk_size) * self.chunk_size\n",
    "            past_seq_chunks = rearrange(start[:, :seq_index], 'b (n c) -> (b n) c', c = self.chunk_size)\n",
    "\n",
    "            retrieved = self.fetch_knn_chunks_fn(past_seq_chunks)\n",
    "            retrieved = rearrange(retrieved, '(b n) k c -> b n k c', b = b)\n",
    "\n",
    "        # get starting sequence index\n",
    "\n",
    "        out = start\n",
    "\n",
    "        # sampling loop\n",
    "\n",
    "        for i in range(start_seq_len - 1, self.max_seq_len):\n",
    "\n",
    "            logits = self.retro(out, retrieved = retrieved)\n",
    "            logits = logits[:, i]\n",
    "\n",
    "            logits = filter_fn(logits, thres = filter_thres)\n",
    "            sampled = gumbel_sample(logits, temperature = temperature, dim = -1)\n",
    "            sampled = rearrange(sampled, 'b -> b 1')\n",
    "\n",
    "            out = torch.cat((out, sampled), dim = 1)\n",
    "\n",
    "            # early terminate if all EOS\n",
    "\n",
    "            is_eos_tokens = (out == EOS_ID)\n",
    "\n",
    "            if is_eos_tokens.any(dim = -1).all():\n",
    "\n",
    "                # mask out everything after the eos tokens\n",
    "\n",
    "                shifted_is_eos_tokens = F.pad(is_eos_tokens, (1, -1))\n",
    "                mask = shifted_is_eos_tokens.float().cumsum(dim = -1) >= 1\n",
    "                out = out.masked_fill(mask, self.retro.pad_id)\n",
    "                break\n",
    "\n",
    "            # when the sequence length is a multiple of the chunk size\n",
    "            # retrieve the next set of knns\n",
    "\n",
    "            curr_seq_len = out.shape[-1]\n",
    "\n",
    "            if (curr_seq_len % self.chunk_size) == 0:\n",
    "                last_chunk = rearrange(out, 'b (c n) -> b c n', n = self.chunk_size)[:, -1]\n",
    "\n",
    "                knn_chunks = self.fetch_knn_chunks_fn(last_chunk)\n",
    "\n",
    "                # concat retrieved knn chunks to all retrieved\n",
    "                # to be sent to Retro for chunked cross attention at the next iteration\n",
    "\n",
    "                knn_chunks = rearrange(knn_chunks, 'b k r -> b 1 k r')\n",
    "                retrieved = safe_cat(retrieved, knn_chunks, dim = 1)\n",
    "\n",
    "                print(f'retrieved at {curr_seq_len} / {self.max_seq_len}')\n",
    "\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ea19d11efa7602c1f12500925a974ed4f31fcf847bd6f694bd5180da2602ded"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
