{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Model \n",
    "\n",
    "The implementation fo the RAG model for the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "# import torch\n",
    "# from datasets import load_from_disk\n",
    "# device = torch.device(\"cuda:0\")\n",
    "\n",
    "# ds = load_from_disk(\"/workspace/data/filtered_small_embeddings\")[\"train\"]\n",
    "# def get_title_examples(examples):\n",
    "#     split_title = [ i.split(\"\\n\")[0] for i in examples[\"sentence_split\"]]\n",
    "#     examples[\"title\"] = split_title\n",
    "#     return examples\n",
    "# ds = ds.map(get_title_examples, batched=True, num_proc=32)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['date', 'hash', 'title', 'sentence', 'embeddings'],\n",
       "    num_rows: 3034846\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "ds = load_from_disk(\"/workspace/data/filtered_split_sentences_embeddings\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "ds = datasets.DatasetDict({\"train\":ds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds[\"train\"][0][\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds[0][\"embeddings\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_title_examples(examples):\n",
    "#     split_title = [ i.split(\"\\n\")[0] for i in examples[\"sentence_split\"]]\n",
    "#     examples[\"title\"] = split_title\n",
    "#     return examples\n",
    "# ds = ds.map(get_title_examples, batched=True, num_proc=32)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3035/3035 [00:12<00:00, 246.35it/s]\n"
     ]
    }
   ],
   "source": [
    "ds[\"train\"] = ds[\"train\"].add_faiss_index(column='embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['date', 'hash', 'title', 'sentence', 'embeddings'],\n",
       "        num_rows: 3034846\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.rename_column(\"sentence\",\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['date', 'hash', 'title', 'text', 'embeddings'],\n",
       "        num_rows: 3034846\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetDict' object has no attribute 'get_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m faiss_index \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39;49mget_index(\u001b[39m'\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mfaiss_index\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatasetDict' object has no attribute 'get_index'"
     ]
    }
   ],
   "source": [
    "faiss_index = ds.get_index('embeddings').faiss_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import RagConfig\n",
    "# config = RagConfig.from_pretrained(\n",
    "#     \"facebook/rag-sequence-nq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "import torch\n",
    "\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-sequence-nq\")\n",
    "retriever = RagRetriever.from_pretrained(\n",
    "    \"facebook/rag-sequence-nq\", indexed_dataset=ds[\"train\"],retrieval_vector_size=364\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/models/bart/configuration_bart.py:179: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/rag-token-nq were not used when initializing RagSequenceForGeneration: ['rag.question_encoder.question_encoder.bert_model.pooler.dense.bias', 'rag.question_encoder.question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RagSequenceForGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RagSequenceForGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RagSequenceForGeneration were not initialized from the model checkpoint at facebook/rag-token-nq and are newly initialized: ['rag.generator.lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-nq\", retriever=retriever,retrieval_vector_size=364)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RagConfig {\n",
       "  \"_commit_hash\": \"af32fa164f774a532dfb63c94b2e898e80434643\",\n",
       "  \"_name_or_path\": \"facebook/rag-token-nq\",\n",
       "  \"architectures\": [\n",
       "    \"RagTokenForGeneration\"\n",
       "  ],\n",
       "  \"bad_words_ids\": [\n",
       "    [\n",
       "      0,\n",
       "      0\n",
       "    ]\n",
       "  ],\n",
       "  \"bos_token_id\": 0,\n",
       "  \"dataset\": \"wiki_dpr\",\n",
       "  \"dataset_split\": \"train\",\n",
       "  \"decoder_start_token_id\": 2,\n",
       "  \"do_deduplication\": true,\n",
       "  \"do_marginalize\": false,\n",
       "  \"doc_sep\": \" // \",\n",
       "  \"eos_token_id\": 2,\n",
       "  \"exclude_bos_score\": false,\n",
       "  \"forced_eos_token_id\": 2,\n",
       "  \"generator\": {\n",
       "    \"_name_or_path\": \"\",\n",
       "    \"_num_labels\": 3,\n",
       "    \"activation_dropout\": 0.0,\n",
       "    \"activation_function\": \"gelu\",\n",
       "    \"add_bias_logits\": false,\n",
       "    \"add_cross_attention\": false,\n",
       "    \"add_final_layer_norm\": false,\n",
       "    \"architectures\": [\n",
       "      \"BartForConditionalGeneration\"\n",
       "    ],\n",
       "    \"attention_dropout\": 0.0,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": 0,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"classif_dropout\": 0.0,\n",
       "    \"classifier_dropout\": 0.0,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"d_model\": 1024,\n",
       "    \"decoder_attention_heads\": 16,\n",
       "    \"decoder_ffn_dim\": 4096,\n",
       "    \"decoder_layerdrop\": 0.0,\n",
       "    \"decoder_layers\": 12,\n",
       "    \"decoder_start_token_id\": 2,\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"dropout\": 0.1,\n",
       "    \"early_stopping\": false,\n",
       "    \"encoder_attention_heads\": 16,\n",
       "    \"encoder_ffn_dim\": 4096,\n",
       "    \"encoder_layerdrop\": 0.0,\n",
       "    \"encoder_layers\": 12,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": 2,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"extra_pos_embeddings\": 2,\n",
       "    \"finetuning_task\": null,\n",
       "    \"force_bos_token_to_be_generated\": true,\n",
       "    \"forced_bos_token_id\": 0,\n",
       "    \"forced_eos_token_id\": 2,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\",\n",
       "      \"2\": \"LABEL_2\"\n",
       "    },\n",
       "    \"init_std\": 0.02,\n",
       "    \"is_decoder\": false,\n",
       "    \"is_encoder_decoder\": true,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1,\n",
       "      \"LABEL_2\": 2\n",
       "    },\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"max_position_embeddings\": 1024,\n",
       "    \"min_length\": 0,\n",
       "    \"model_type\": \"bart\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"normalize_before\": false,\n",
       "    \"normalize_embedding\": true,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_hidden_layers\": 12,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_past\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": 1,\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"scale_embedding\": false,\n",
       "    \"sep_token_id\": null,\n",
       "    \"static_position_embeddings\": false,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": {\n",
       "      \"summarization\": {\n",
       "        \"early_stopping\": true,\n",
       "        \"length_penalty\": 2.0,\n",
       "        \"max_length\": 142,\n",
       "        \"min_length\": 56,\n",
       "        \"no_repeat_ngram_size\": 3,\n",
       "        \"num_beams\": 4\n",
       "      }\n",
       "    },\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": null,\n",
       "    \"torchscript\": false,\n",
       "    \"transformers_version\": \"4.24.0\",\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"use_cache\": true,\n",
       "    \"vocab_size\": 50265\n",
       "  },\n",
       "  \"index_name\": \"legacy\",\n",
       "  \"index_path\": null,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label_smoothing\": 0.0,\n",
       "  \"max_combined_length\": 300,\n",
       "  \"max_length\": 50,\n",
       "  \"min_length\": 1,\n",
       "  \"model_type\": \"rag\",\n",
       "  \"n_docs\": 5,\n",
       "  \"num_beams\": 4,\n",
       "  \"output_retrieved\": false,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"passages_path\": null,\n",
       "  \"question_encoder\": {\n",
       "    \"_name_or_path\": \"\",\n",
       "    \"add_cross_attention\": false,\n",
       "    \"architectures\": [\n",
       "      \"DPRQuestionEncoder\"\n",
       "    ],\n",
       "    \"attention_probs_dropout_prob\": 0.1,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": null,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"early_stopping\": false,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": null,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": null,\n",
       "    \"gradient_checkpointing\": false,\n",
       "    \"hidden_act\": \"gelu\",\n",
       "    \"hidden_dropout_prob\": 0.1,\n",
       "    \"hidden_size\": 768,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"intermediate_size\": 3072,\n",
       "    \"is_decoder\": false,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"layer_norm_eps\": 1e-12,\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"max_position_embeddings\": 512,\n",
       "    \"min_length\": 0,\n",
       "    \"model_type\": \"dpr\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_attention_heads\": 12,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_hidden_layers\": 12,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": 0,\n",
       "    \"position_embedding_type\": \"absolute\",\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"projection_dim\": 0,\n",
       "    \"pruned_heads\": {},\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": false,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": null,\n",
       "    \"torchscript\": false,\n",
       "    \"transformers_version\": \"4.24.0\",\n",
       "    \"type_vocab_size\": 2,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"use_cache\": true,\n",
       "    \"vocab_size\": 30522\n",
       "  },\n",
       "  \"reduce_loss\": false,\n",
       "  \"retrieval_batch_size\": 8,\n",
       "  \"retrieval_vector_size\": 364,\n",
       "  \"title_sep\": \" / \",\n",
       "  \"transformers_version\": null,\n",
       "  \"use_cache\": true,\n",
       "  \"use_dummy_dataset\": false,\n",
       "  \"vocab_size\": null\n",
       "}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [32], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m question_hidden_states \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mquestion_encoder(input_ids)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[39m# 2. Retrieve\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m docs_dict \u001b[39m=\u001b[39m retriever(input_ids\u001b[39m.\u001b[39;49mnumpy(), question_hidden_states\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mnumpy(), return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m doc_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbmm(\n\u001b[1;32m      7\u001b[0m     question_hidden_states\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m), docs_dict[\u001b[39m\"\u001b[39m\u001b[39mretrieved_doc_embeds\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m      8\u001b[0m )\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[39m# 3. Forward to generator\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/rag/retrieval_rag.py:607\u001b[0m, in \u001b[0;36mRagRetriever.__call__\u001b[0;34m(self, question_input_ids, question_hidden_states, prefix, n_docs, return_tensors)\u001b[0m\n\u001b[1;32m    605\u001b[0m n_docs \u001b[39m=\u001b[39m n_docs \u001b[39mif\u001b[39;00m n_docs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_docs\n\u001b[1;32m    606\u001b[0m prefix \u001b[39m=\u001b[39m prefix \u001b[39mif\u001b[39;00m prefix \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mgenerator\u001b[39m.\u001b[39mprefix\n\u001b[0;32m--> 607\u001b[0m retrieved_doc_embeds, doc_ids, docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve(question_hidden_states, n_docs)\n\u001b[1;32m    609\u001b[0m input_strings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquestion_encoder_tokenizer\u001b[39m.\u001b[39mbatch_decode(question_input_ids, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    610\u001b[0m context_input_ids, context_attention_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess_docs(\n\u001b[1;32m    611\u001b[0m     docs, input_strings, prefix, n_docs, return_tensors\u001b[39m=\u001b[39mreturn_tensors\n\u001b[1;32m    612\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/rag/retrieval_rag.py:556\u001b[0m, in \u001b[0;36mRagRetriever.retrieve\u001b[0;34m(self, question_hidden_states, n_docs)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mretrieve\u001b[39m(\u001b[39mself\u001b[39m, question_hidden_states: np\u001b[39m.\u001b[39mndarray, n_docs: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, List[\u001b[39mdict\u001b[39m]]:\n\u001b[1;32m    538\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[39m    Retrieves documents for specified `question_hidden_states`.\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[39m        - **doc_dicts** (`List[dict]`): The `retrieved_doc_embeds` examples per query.\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 556\u001b[0m     doc_ids, retrieved_doc_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_main_retrieve(question_hidden_states, n_docs)\n\u001b[1;32m    557\u001b[0m     \u001b[39mreturn\u001b[39;00m retrieved_doc_embeds, doc_ids, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_doc_dicts(doc_ids)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/rag/retrieval_rag.py:526\u001b[0m, in \u001b[0;36mRagRetriever._main_retrieve\u001b[0;34m(self, question_hidden_states, n_docs)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[39mfor\u001b[39;00m question_hidden_states \u001b[39min\u001b[39;00m question_hidden_states_batched:\n\u001b[1;32m    525\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 526\u001b[0m     ids, vectors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_top_docs(question_hidden_states, n_docs)\n\u001b[1;32m    527\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    528\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mindex search time: \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\u001b[39m}\u001b[39;00m\u001b[39m sec, batch size \u001b[39m\u001b[39m{\u001b[39;00mquestion_hidden_states\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    530\u001b[0m     ids_batched\u001b[39m.\u001b[39mextend(ids)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/rag/retrieval_rag.py:216\u001b[0m, in \u001b[0;36mHFIndexBase.get_top_docs\u001b[0;34m(self, question_hidden_states, n_docs)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_top_docs\u001b[39m(\u001b[39mself\u001b[39m, question_hidden_states: np\u001b[39m.\u001b[39mndarray, n_docs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mndarray]:\n\u001b[0;32m--> 216\u001b[0m     _, ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49msearch_batch(\u001b[39m\"\u001b[39;49m\u001b[39membeddings\u001b[39;49m\u001b[39m\"\u001b[39;49m, question_hidden_states, n_docs)\n\u001b[1;32m    217\u001b[0m     docs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m indices \u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m]] \u001b[39mfor\u001b[39;00m indices \u001b[39min\u001b[39;00m ids]\n\u001b[1;32m    218\u001b[0m     vectors \u001b[39m=\u001b[39m [doc[\u001b[39m\"\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/search.py:694\u001b[0m, in \u001b[0;36mIndexableMixin.search_batch\u001b[0;34m(self, index_name, queries, k)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[39m\"\"\"Find the nearest examples indices in the dataset to the query.\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \n\u001b[1;32m    684\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[39m    total_indices (:obj:`List[List[int]]`): The indices of the retrieved examples per query.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_index_is_initialized(index_name)\n\u001b[0;32m--> 694\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indexes[index_name]\u001b[39m.\u001b[39;49msearch_batch(queries, k)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/search.py:375\u001b[0m, in \u001b[0;36mFaissIndex.search_batch\u001b[0;34m(self, queries, k)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m queries\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mc_contiguous:\n\u001b[1;32m    374\u001b[0m     queries \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(queries, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 375\u001b[0m scores, indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfaiss_index\u001b[39m.\u001b[39;49msearch(queries, k)\n\u001b[1;32m    376\u001b[0m \u001b[39mreturn\u001b[39;00m BatchedSearchResults(scores, indices\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/faiss/__init__.py:308\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_search\u001b[0;34m(self, x, k, D, I)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39m\"\"\"Find the k nearest neighbors of the set of vectors x in the index.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \n\u001b[1;32m    285\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39m    When not enough results are found, the label is set to -1\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    307\u001b[0m n, d \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n\u001b[0;32m--> 308\u001b[0m \u001b[39massert\u001b[39;00m d \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md\n\u001b[1;32m    310\u001b[0m \u001b[39massert\u001b[39;00m k \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    312\u001b[0m \u001b[39mif\u001b[39;00m D \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs = tokenizer('Who was the Labour candidate in Norwich South?', return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "question_hidden_states = model.question_encoder(input_ids)[0]\n",
    "# 2. Retrieve\n",
    "docs_dict = retriever(input_ids.numpy(), question_hidden_states.detach().numpy(), return_tensors=\"pt\")\n",
    "doc_scores = torch.bmm(\n",
    "    question_hidden_states.unsqueeze(1), docs_dict[\"retrieved_doc_embeds\"].float().transpose(1, 2)\n",
    ").squeeze(1)\n",
    "# 3. Forward to generator\n",
    "outputs = model(\n",
    "    context_input_ids=docs_dict[\"context_input_ids\"],\n",
    "    context_attention_mask=docs_dict[\"context_attention_mask\"],\n",
    "    doc_scores=doc_scores,\n",
    "    decoder_input_ids=labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[39;49mfaiss_index\u001b[39m.\u001b[39;49msearch(queries, k)\n",
      "\u001b[1;32m    376\u001b[0m \u001b[39mreturn\u001b[39;00m BatchedSearchResults(scores, indices\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m))\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/faiss/__init__.py:308\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_search\u001b[0;34m(self, x, k, D, I)\u001b[0m\n",
      "\u001b[1;32m    283\u001b[0m \u001b[39m\"\"\"Find the k nearest neighbors of the set of vectors x in the index.\u001b[39;00m\n",
      "\u001b[1;32m    284\u001b[0m \n",
      "\u001b[1;32m    285\u001b[0m \u001b[39mParameters\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    304\u001b[0m \u001b[39m    When not enough results are found, the label is set to -1\u001b[39;00m\n",
      "\u001b[1;32m    305\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m    307\u001b[0m n, d \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;32m--> 308\u001b[0m \u001b[39massert\u001b[39;00m d \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md\n",
      "\u001b[1;32m    310\u001b[0m \u001b[39massert\u001b[39;00m k \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;32m    312\u001b[0m \u001b[39mif\u001b[39;00m D \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[0;31mAssertionError\u001b[0m: \n"
     ]
    }
   ],
   "source": [
    "print(\" \\u001b[39;49mfaiss_index\\u001b[39m.\\u001b[39;49msearch(queries, k)\\n\\u001b[1;32m    376\\u001b[0m \\u001b[39mreturn\\u001b[39;00m BatchedSearchResults(scores, indices\\u001b[39m.\\u001b[39mastype(\\u001b[39mint\\u001b[39m))\\n\\nFile \\u001b[0;32m/opt/conda/lib/python3.8/site-packages/faiss/__init__.py:308\\u001b[0m, in \\u001b[0;36mhandle_Index.<locals>.replacement_search\\u001b[0;34m(self, x, k, D, I)\\u001b[0m\\n\\u001b[1;32m    283\\u001b[0m \\u001b[39m\\\"\\\"\\\"Find the k nearest neighbors of the set of vectors x in the index.\\u001b[39;00m\\n\\u001b[1;32m    284\\u001b[0m \\n\\u001b[1;32m    285\\u001b[0m \\u001b[39mParameters\\u001b[39;00m\\n\\u001b[0;32m   (...)\\u001b[0m\\n\\u001b[1;32m    304\\u001b[0m \\u001b[39m    When not enough results are found, the label is set to -1\\u001b[39;00m\\n\\u001b[1;32m    305\\u001b[0m \\u001b[39m\\\"\\\"\\\"\\u001b[39;00m\\n\\u001b[1;32m    307\\u001b[0m n, d \\u001b[39m=\\u001b[39m x\\u001b[39m.\\u001b[39mshape\\n\\u001b[0;32m--> 308\\u001b[0m \\u001b[39massert\\u001b[39;00m d \\u001b[39m==\\u001b[39m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39md\\n\\u001b[1;32m    310\\u001b[0m \\u001b[39massert\\u001b[39;00m k \\u001b[39m>\\u001b[39m \\u001b[39m0\\u001b[39m\\n\\u001b[1;32m    312\\u001b[0m \\u001b[39mif\\u001b[39;00m D \\u001b[39mis\\u001b[39;00m \\u001b[39mNone\\u001b[39;00m:\\n\\n\\u001b[0;31mAssertionError\\u001b[0m: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer('Who was the Labour candidate in Norwich South?', return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "question_hidden_states = model.question_encoder(input_ids.to(device))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 2. Retrieve\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m docs_dict \u001b[39m=\u001b[39m retriever(input_ids\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mnumpy(), question_hidden_states\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mnumpy(), return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m doc_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbmm(\n\u001b[1;32m      4\u001b[0m     question_hidden_states\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m), docs_dict[\u001b[39m\"\u001b[39m\u001b[39mretrieved_doc_embeds\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m      5\u001b[0m )\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# 3. Forward to generator\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/rag/retrieval_rag.py:607\u001b[0m, in \u001b[0;36mRagRetriever.__call__\u001b[0;34m(self, question_input_ids, question_hidden_states, prefix, n_docs, return_tensors)\u001b[0m\n\u001b[1;32m    605\u001b[0m n_docs \u001b[39m=\u001b[39m n_docs \u001b[39mif\u001b[39;00m n_docs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_docs\n\u001b[1;32m    606\u001b[0m prefix \u001b[39m=\u001b[39m prefix \u001b[39mif\u001b[39;00m prefix \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mgenerator\u001b[39m.\u001b[39mprefix\n\u001b[0;32m--> 607\u001b[0m retrieved_doc_embeds, doc_ids, docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve(question_hidden_states, n_docs)\n\u001b[1;32m    609\u001b[0m input_strings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquestion_encoder_tokenizer\u001b[39m.\u001b[39mbatch_decode(question_input_ids, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    610\u001b[0m context_input_ids, context_attention_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess_docs(\n\u001b[1;32m    611\u001b[0m     docs, input_strings, prefix, n_docs, return_tensors\u001b[39m=\u001b[39mreturn_tensors\n\u001b[1;32m    612\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/rag/retrieval_rag.py:556\u001b[0m, in \u001b[0;36mRagRetriever.retrieve\u001b[0;34m(self, question_hidden_states, n_docs)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mretrieve\u001b[39m(\u001b[39mself\u001b[39m, question_hidden_states: np\u001b[39m.\u001b[39mndarray, n_docs: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, List[\u001b[39mdict\u001b[39m]]:\n\u001b[1;32m    538\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[39m    Retrieves documents for specified `question_hidden_states`.\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[39m        - **doc_dicts** (`List[dict]`): The `retrieved_doc_embeds` examples per query.\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 556\u001b[0m     doc_ids, retrieved_doc_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_main_retrieve(question_hidden_states, n_docs)\n\u001b[1;32m    557\u001b[0m     \u001b[39mreturn\u001b[39;00m retrieved_doc_embeds, doc_ids, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_doc_dicts(doc_ids)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/rag/retrieval_rag.py:526\u001b[0m, in \u001b[0;36mRagRetriever._main_retrieve\u001b[0;34m(self, question_hidden_states, n_docs)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[39mfor\u001b[39;00m question_hidden_states \u001b[39min\u001b[39;00m question_hidden_states_batched:\n\u001b[1;32m    525\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 526\u001b[0m     ids, vectors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_top_docs(question_hidden_states, n_docs)\n\u001b[1;32m    527\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    528\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mindex search time: \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\u001b[39m}\u001b[39;00m\u001b[39m sec, batch size \u001b[39m\u001b[39m{\u001b[39;00mquestion_hidden_states\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    530\u001b[0m     ids_batched\u001b[39m.\u001b[39mextend(ids)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/rag/retrieval_rag.py:216\u001b[0m, in \u001b[0;36mHFIndexBase.get_top_docs\u001b[0;34m(self, question_hidden_states, n_docs)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_top_docs\u001b[39m(\u001b[39mself\u001b[39m, question_hidden_states: np\u001b[39m.\u001b[39mndarray, n_docs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mndarray]:\n\u001b[0;32m--> 216\u001b[0m     _, ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49msearch_batch(\u001b[39m\"\u001b[39;49m\u001b[39membeddings\u001b[39;49m\u001b[39m\"\u001b[39;49m, question_hidden_states, n_docs)\n\u001b[1;32m    217\u001b[0m     docs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m indices \u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m]] \u001b[39mfor\u001b[39;00m indices \u001b[39min\u001b[39;00m ids]\n\u001b[1;32m    218\u001b[0m     vectors \u001b[39m=\u001b[39m [doc[\u001b[39m\"\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/search.py:694\u001b[0m, in \u001b[0;36mIndexableMixin.search_batch\u001b[0;34m(self, index_name, queries, k)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[39m\"\"\"Find the nearest examples indices in the dataset to the query.\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \n\u001b[1;32m    684\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[39m    total_indices (:obj:`List[List[int]]`): The indices of the retrieved examples per query.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_index_is_initialized(index_name)\n\u001b[0;32m--> 694\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indexes[index_name]\u001b[39m.\u001b[39;49msearch_batch(queries, k)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/search.py:375\u001b[0m, in \u001b[0;36mFaissIndex.search_batch\u001b[0;34m(self, queries, k)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m queries\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mc_contiguous:\n\u001b[1;32m    374\u001b[0m     queries \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(queries, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 375\u001b[0m scores, indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfaiss_index\u001b[39m.\u001b[39;49msearch(queries, k)\n\u001b[1;32m    376\u001b[0m \u001b[39mreturn\u001b[39;00m BatchedSearchResults(scores, indices\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/faiss/__init__.py:308\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_search\u001b[0;34m(self, x, k, D, I)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39m\"\"\"Find the k nearest neighbors of the set of vectors x in the index.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \n\u001b[1;32m    285\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39m    When not enough results are found, the label is set to -1\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    307\u001b[0m n, d \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n\u001b[0;32m--> 308\u001b[0m \u001b[39massert\u001b[39;00m d \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md\n\u001b[1;32m    310\u001b[0m \u001b[39massert\u001b[39;00m k \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    312\u001b[0m \u001b[39mif\u001b[39;00m D \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 2. Retrieve\n",
    "docs_dict = retriever(input_ids.detach().cpu().numpy(), question_hidden_states.detach().cpu().numpy(), return_tensors=\"pt\")\n",
    "doc_scores = torch.bmm(\n",
    "    question_hidden_states.detach().cpu().unsqueeze(1), docs_dict[\"retrieved_doc_embeds\"].float().transpose(1, 2)\n",
    ").squeeze(1)\n",
    "# 3. Forward to generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 45918,  24516,  19557, 173082,  95305]], device='cuda:0')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_dict[\"doc_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[59.8145, 57.2421, 61.1528, 59.3711, 58.7865]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Warner Bros open nationwide search for Peter Pan actor\\nOne rising star could get their lucky break later this month at Wembley Arena, when a nationwide casting call will be taking place to find the new star of Pan.\\nThe film, which is directed by Atonement director Joe Wright, will be a live-action remake of JM Barrie\\'s classic novel Peter Pan.\\nWarner Bros Pictures has extended an invitation to \"boys of all ethnicities, aged 11 to 13\" to audition for the main role of Peter Pan, the boy who would never grow up.\\nThe role is described as \"a courageous and adventurous orphaned boy living in a world of fantasy and dreams, which sometimes leads him into trouble.\"\\nThe studio has specified that the aspiring actor must be no taller than 5ft 4inches and must be accompanied by an adult in order to audition.\\nThere will be fierce competition for a space in the line on February 23, as queing begins at 9am and closes at 11am, and there is no allowance for overnight queuing or camping.\\n'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[45918][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_dict = docs_dict.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_scores = doc_scores.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/dller_NLG/.conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "generated = model.generate(\n",
    "    context_input_ids=docs_dict[\"context_input_ids\"],\n",
    "    context_attention_mask=docs_dict[\"context_attention_mask\"],\n",
    "    doc_scores=doc_scores,\n",
    ")\n",
    "generated_string = tokenizer.batch_decode(generated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 980']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hercules crash inquest to resume\\nLow-level flying\\nThe Wiltshire coroner, David Masters, has laid out the main areas for investigation .\\nHe will ask whether or not the plane from RAF Lyneham should have been fitted with anti-explosive fuel tanks, what the RAF tactics are for low-level flying during daylight and the availability of intelligence about the threat to aircraft from ground attack.\\nExplosive-suppressant foam (ESF) which prevents fuel tanks exploding if they are hit, has been fitted to American Hercules aircraft since the 1960s and Australian Hercules also have it.\\nSarah Chapman, sister of Sgt Bob O\\'Connor, one of those killed, wrote to Defence Secretary Des Browne in May 2006 to ask why the craft had not been fitted with ESF.\\n\"The men and women of the British armed forces are not expendable assets who have forfeited their right to life because they chose to take the Queen\\'s shilling,\" she said.\\nLegal aid\\nIt is therefore not acceptable to deny them any duty of care from the government, especially based on no other reasonable factor other than cost.\\nAlso in May 2006, the Under-Secretary of State for Defence, Lord Drayson, said the initial program to fit ESF to Hercules would cost £600,000 per aircraft.\\nA military Board of Inquiry into the crash recommended that ESF be fitted to RAF Hercules aircraft as a matter of urgency, but some are still without.\\nA previous hearing was told how the crash site was left insecure for 60 hours after the crash, allowing insurgents to pick through the bodies.\\nVideo footage of Australian RAF Flight Lieutenant Paul Pardoel\\'s naked body was later touted for sale on auction website eBay, to the distress of his widow Kellie Merritt, who is the only relative to have been granted legal aid.\\nThe remaining nine families have been refused aid with which to hire counsel at the inquest.\\n'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[9399][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/raw/streaminqa_valid.jsonl', '../data/raw/streaminqa_train.jsonl', '../data/raw/streaminqa_eval.jsonl']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d244b28f1b15863e\n",
      "Found cached dataset json (/root/.cache/huggingface/datasets/json/default-d244b28f1b15863e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "100%|██████████| 1/1 [00:00<00:00, 301.06it/s]\n",
      "Using custom data configuration default-f0b49b41b445f076\n",
      "Found cached dataset json (/root/.cache/huggingface/datasets/json/default-f0b49b41b445f076/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "100%|██████████| 1/1 [00:00<00:00, 175.79it/s]\n",
      "Using custom data configuration default-886a77e275fbf5b2\n",
      "Found cached dataset json (/root/.cache/huggingface/datasets/json/default-886a77e275fbf5b2/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "100%|██████████| 1/1 [00:00<00:00, 413.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from datasets import load_dataset\n",
    "files = glob(\"../data/raw/*.jsonl\")\n",
    "print(files)\n",
    "ds_l = [load_dataset(\"json\",data_files=i) for i in files]\n",
    "ds_sm = ds_l[1]\n",
    "ds_sm[\"test\"] = ds_l[0][\"train\"]\n",
    "ds_sm[\"validation\"] = ds_l[2][\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['qa_id', 'question', 'answers', 'answers_additional', 'question_ts', 'evidence_ts', 'evidence_id', 'recent_or_past', 'written_or_generated', 'toxicity_identity_attack', 'toxicity_insult', 'toxicity_profanity', 'toxicity_severe_toxicity', 'toxicity_sexually_explicit', 'toxicity_threat'],\n",
       "        num_rows: 99402\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['qa_id', 'question', 'answers', 'answers_additional', 'question_ts', 'evidence_ts', 'evidence_id', 'recent_or_past', 'written_or_generated', 'toxicity_identity_attack', 'toxicity_insult', 'toxicity_profanity', 'toxicity_severe_toxicity', 'toxicity_sexually_explicit', 'toxicity_threat'],\n",
       "        num_rows: 9939\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['qa_id', 'question', 'answers', 'answers_additional', 'question_ts', 'evidence_ts', 'evidence_id', 'recent_or_past', 'written_or_generated', 'toxicity_identity_attack', 'toxicity_insult', 'toxicity_profanity', 'toxicity_severe_toxicity', 'toxicity_sexually_explicit', 'toxicity_threat'],\n",
       "        num_rows: 36378\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#0: 100%|██████████| 49701/49701 [00:03<00:00, 13282.04ex/s]\n",
      "#1: 100%|██████████| 49701/49701 [00:03<00:00, 13236.15ex/s]\n",
      "#0: 100%|██████████| 4970/4970 [00:00<00:00, 13200.86ex/s]\n",
      "#1: 100%|██████████| 4969/4969 [00:00<00:00, 12772.91ex/s]\n",
      "#0: 100%|██████████| 18189/18189 [00:01<00:00, 12922.34ex/s]\n",
      "#1: 100%|██████████| 18189/18189 [00:01<00:00, 12775.29ex/s]\n"
     ]
    }
   ],
   "source": [
    "ds_sm = ds_sm.map(lambda examples: {\"hash_cleaned\": examples[\"evidence_id\"].split(\"\\x00\\x01\")[1]} , num_proc=2, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['qa_id', 'question', 'answers', 'answers_additional', 'question_ts', 'evidence_ts', 'evidence_id', 'recent_or_past', 'written_or_generated', 'toxicity_identity_attack', 'toxicity_insult', 'toxicity_profanity', 'toxicity_severe_toxicity', 'toxicity_sexually_explicit', 'toxicity_threat', 'hash_cleaned'],\n",
       "        num_rows: 99402\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['qa_id', 'question', 'answers', 'answers_additional', 'question_ts', 'evidence_ts', 'evidence_id', 'recent_or_past', 'written_or_generated', 'toxicity_identity_attack', 'toxicity_insult', 'toxicity_profanity', 'toxicity_severe_toxicity', 'toxicity_sexually_explicit', 'toxicity_threat', 'hash_cleaned'],\n",
       "        num_rows: 9939\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['qa_id', 'question', 'answers', 'answers_additional', 'question_ts', 'evidence_ts', 'evidence_id', 'recent_or_past', 'written_or_generated', 'toxicity_identity_attack', 'toxicity_insult', 'toxicity_profanity', 'toxicity_severe_toxicity', 'toxicity_sexually_explicit', 'toxicity_threat', 'hash_cleaned'],\n",
       "        num_rows: 36378\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who was the Labour candidate in Norwich South?'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_sm[\"train\"][1000][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b4715d9b0e42a6b3217076f40252c5ab701eb85ba3e72f6abb58e4ab3d5564a4'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_sm[\"train\"][1000][\"hash_cleaned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{str}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([type(i) for i in  ds_sm[\"train\"][\"evidence_id\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"b4715d9b0e42a6b3217076f40252c5ab701eb85ba3e72f6abb58e4ab3d5564a4\" in ds[\"hash\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If the aim is not just to deny Boris Johnson a majority, but to get rid of the Conservatives as the party of government altogether, the best scenario would be Labour polling high, having created a solid anti-Brexit, anti-hard right, anti-austerity tripod.',\n",
       " 'The fundamental block is the Labour party - obsessed with vote share, it has always opposed alliances of any kind.',\n",
       " 'In 2017, if it had stood aside in the Isle of Wight - bear in mind that this seat has never returned a Labour MP - the Greens would have repaid them in 12 other constituencies.',\n",
       " \"While Labour frontbenchers talk constantly to Liberal Democrats - indeed, last week's parliamentary victories couldn't have been won without a fair amount of talking to Tories - nobody at shadow cabinet level is talking about pacts.\",\n",
       " 'The Lib Dems have erected their own barriers, mainly in the form of their performative hostility towards Labour.',\n",
       " \"Rather, it's designed to underscore their superiority over the Labour party, in the eyes of hard remainers; entirely speciously, since they know they'll never be called out on it.\",\n",
       " 'Taken together with the much friendlier noises they make to Tory defectors than to anyone in the Labour hierarchy, it is hard to perceive much warmth between the two blocs.',\n",
       " \"However, this is mostly strategic; it will help both the Lib Dems and Labour if remainer Tories - has any group ever been so politically homeless? - find somewhere to cast their votes, otherwise that's a 4 million-strong army of silence.\",\n",
       " \"It would be much harder for them to vote for Jo Swinson's party were it seen to be chummy with Corbyn's, and the smarter elements of Labour take their catcalls with a pinch of salt.\",\n",
       " 'A large, formal pact between the major remain forces - Labour, the Lib Dems, the Greens, Plaid Cymru and the SNP - is off the table.',\n",
       " 'In 111 of these, the numbers strongly implore Lib Dems, Greens and Plaid to swing behind Labour (in 30 seats, even a 5% shift from Labour to the Lib Dems would deliver the seat to the Conservatives).',\n",
       " \"Seats such as Portsmouth South, Battersea, Bermondsey and Old Southwark, and Kensington and Chelsea are tantalising for the Lib Dems - either because they're the strongest second party and could leverage their bolder Brexit position, or because they've had a recent surge - but the best bet for a progressive MP in those seats is for everyone to campaign for Labour.\",\n",
       " 'The Labour candidate, Fleur Anderson, is strong and well liked, but the numbers - Tories 34%, Lab 22%, Lib Dems 30%, with a 7% Green showing - mean that anyone putting together tactical voting cribsheets would go Lib Dem.',\n",
       " \"But they're vital - the Greens in Norwich South would not have swung behind Labour's Clive Lewis in 2017 if the red-green candidates in neighbouring constituencies had been savaging each other.\"]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in ds[ds[\"hash\"].index(ds_sm[\"train\"][1000][\"hash_cleaned\"])][\"text\"].split(\"\\n\")  if \"labour\" in i.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
